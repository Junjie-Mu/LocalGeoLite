[
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the area of a polygon in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file('path_to_file.shp')\ngdf['area'] = gdf.geometry.area\nprint(gdf[['geometry', 'area']])\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert latitude and longitude to UTM coordinates using Pyproj.",
        "output": "```python\nfrom pyproj import Proj\n\ndef latlon_to_utm(lat, lon):\n    utm_proj = Proj(proj='utm', zone=10, ellps='WGS84')\n    easting, northing = utm_proj(lon, lat)\n    return easting, northing\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Find the nearest neighbor for each point in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\nfrom scipy.spatial import cKDTree\n\ndef find_nearest_neighbors(gdf):\n    gdf = gdf.to_crs(epsg=3857)\n    coords = list(zip(gdf.geometry.x, gdf.geometry.y))\n    tree = cKDTree(coords)\n    distances, indices = tree.query(coords, k=2)\n    gdf['nearest_neighbor'] = indices[:, 1]\n    gdf['nearest_distance'] = distances[:, 1]\n    return gdf\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Clip a raster file using a shapefile boundary.",
        "output": "```python\nimport rasterio\nfrom rasterio.mask import mask\nimport geopandas as gpd\n\n# Load the shapefile\nshapefile_path = 'boundary.shp'\nshapes = gpd.read_file(shapefile_path)\n\n# Load the raster file\nraster_path = 'input_raster.tif'\nwith rasterio.open(raster_path) as src:\n    out_image, out_transform = mask(src, shapes.geometry, crop=True)\n    out_meta = src.meta\n\n# Update the metadata for the clipped raster\nout_meta.update({\n    \"driver\": \"GTiff\",\n    \"height\": out_image.shape[1],\n    \"width\": out_image.shape[2],\n    \"transform\": out_transform\n})\n\n# Save the clipped raster\noutput_path = 'clipped_raster.tif'\nwith rasterio.open(output_path, \"w\", **out_meta) as dest:\n    dest.write(out_image)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Reproject a vector layer to EPSG:4326.",
        "output": "```python\nfrom qgis.core import QgsVectorLayer, QgsCoordinateReferenceSystem, QgsProject\n\nvector_layer_path = \"path_to_your_vector_layer.shp\"\nlayer = QgsVectorLayer(vector_layer_path, \"input_layer\", \"ogr\")\n\nif layer.isValid():\n    target_crs = QgsCoordinateReferenceSystem(\"EPSG:4326\")\n    output_path = \"path_to_save_reprojected_layer.shp\"\n    \n    processing.run(\"native:reprojectlayer\", {\n        'INPUT': layer,\n        'TARGET_CRS': target_crs,\n        'OUTPUT': output_path\n    })\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial join between two GeoDataFrames.",
        "output": "```python\nimport geopandas as gpd\n\n# Assume gdf1 and gdf2 are your GeoDataFrames\nresult = gpd.sjoin(gdf1, gdf2, how=\"inner\", predicate=\"intersects\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract values from a raster at specific point locations.",
        "output": "```python\nimport rasterio\nfrom rasterio.transform import rowcol\n\ndef extract_raster_values_at_points(raster_path, points):\n    with rasterio.open(raster_path) as src:\n        transform = src.transform\n        values = []\n        for point in points:\n            col, row = rowcol(transform, point[0], point[1])\n            value = src.read(1)[row, col]\n            values.append(value)\n    return values\n\n# Example usage:\nraster_file = \"path_to_your_raster.tif\"\npoints = [(x1, y1), (x2, y2), (x3, y3)]  # Replace with your point coordinates\nextracted_values = extract_raster_values_at_points(raster_file, points)\nprint(extracted_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Buffer geometries in a GeoDataFrame by 100 meters.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gdf.to_crs(epsg=3857)\ngdf['geometry'] = gdf['geometry'].buffer(100)\ngdf = gdf.to_crs(epsg=4326)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Dissolve polygons based on an attribute column.",
        "output": "```python\nimport geopandas as gpd\n\n# Load the shapefile or GeoJSON file\ngdf = gpd.read_file(\"input_file.shp\")\n\n# Dissolve polygons based on an attribute column\ndissolved = gdf.dissolve(by='attribute_column')\n\n# Save the result to a new file\ndissolved.to_file(\"output_dissolved.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the centroid of each geometry in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file('your_file.shp')\ngdf['centroid'] = gdf.geometry.centroid\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Intersect two polygon layers and retain attributes.",
        "output": "```python\nfrom shapely.geometry import shape, mapping\nfrom shapely.ops import unary_union\nimport fiona\nimport geopandas as gpd\n\n# Load the polygon layers\nlayer1 = gpd.read_file(\"layer1.shp\")\nlayer2 = gpd.read_file(\"layer2.shp\")\n\n# Perform intersection and retain attributes\nintersected = gpd.overlay(layer1, layer2, how='intersection')\n\n# Save the result to a new shapefile\nintersected.to_file(\"intersected_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Count the number of points within each polygon.",
        "output": "```python\nimport geopandas as gpd\n\npoints = gpd.read_file('points.shp')\npolygons = gpd.read_file('polygons.shp')\n\npoints_in_polygons = gpd.sjoin(points, polygons, how='inner', predicate='within')\ncount = points_in_polygons.groupby('index_right').size()\npolygons['count'] = count\npolygons.to_file('polygons_with_count.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a heatmap from a set of point geometries.",
        "output": "```python\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\nimport numpy as np\n\n# Load point geometries from a shapefile or create a GeoDataFrame\ngdf = gpd.read_file(\"points.shp\")\n\n# Extract coordinates\ncoords = np.vstack([gdf.geometry.x, gdf.geometry.y])\n\n# Compute kernel density estimate\nkde = gaussian_kde(coords)\ndensity = kde(coords)\n\n# Plot heatmap\nplt.scatter(coords[0], coords[1], c=density, cmap='Reds', s=50, edgecolor='none')\nplt.colorbar(label='Density')\nplt.title('Heatmap of Point Geometries')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the length of LineString geometries.",
        "output": "```python\nfrom shapely.geometry import LineString\n\ndef calculate_length(line):\n    return line.length\n\n# Example usage\nline = LineString([(0, 0), (1, 1), (2, 2)])\nlength = calculate_length(line)\nprint(length)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Merge multiple shapefiles into one GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\nimport os\n\ndef merge_shapefiles(shapefile_dir):\n    shapefiles = [gpd.read_file(os.path.join(shapefile_dir, f)) for f in os.listdir(shapefile_dir) if f.endswith('.shp')]\n    merged_gdf = gpd.GeoDataFrame(pd.concat(shapefiles, ignore_index=True))\n    return merged_gdf\n\n# Example usage:\n# merged = merge_shapefiles('/path/to/shapefiles')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Rasterize a vector layer using geocube.",
        "output": "```python\nfrom geocube.api.core import make_geocube\nimport geopandas as gpd\nimport rasterio\n\nvector_data = gpd.read_file(\"path_to_vector_file.shp\")\nrasterized_cube = make_geocube(\n    vector_data=vector_data,\n    measurements=[\"attribute_column\"],\n    resolution=(-10, 10),\n    fill=-9999,\n)\nrasterized_cube[\"attribute_column\"].rio.to_raster(\"output_raster.tif\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Create a Voronoi diagram from a set of points.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\npoints = np.random.rand(10, 2)\nvor = Voronoi(points)\nvoronoi_plot_2d(vor)\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform zonal statistics on a raster dataset.",
        "output": "```python\nimport rasterio\nfrom rasterio.mask import mask\nimport geopandas as gpd\nimport numpy as np\nfrom shapely.geometry import mapping\n\ndef zonal_statistics(raster_path, vector_path, statistic=\"mean\"):\n    with rasterio.open(raster_path) as src:\n        raster_data = src.read(1)\n        affine = src.transform\n\n    vector_data = gpd.read_file(vector_path)\n    stats = []\n\n    for geometry in vector_data.geometry:\n        geo_mask = [mapping(geometry)]\n        out_image, out_transform = mask(src=src, shapes=geo_mask, crop=True, filled=False)\n        data = out_image[0]\n        data = data[~np.isnan(data)]\n\n        if statistic == \"mean\":\n            result = np.mean(data) if data.size > 0 else np.nan\n        elif statistic == \"sum\":\n            result = np.sum(data) if data.size > 0 else np.nan\n        elif statistic == \"min\":\n            result = np.min(data) if data.size > 0 else np.nan\n        elif statistic == \"max\":\n            result = np.max(data) if data.size > 0 else np.nan\n        else:\n            raise ValueError(\"Unsupported statistic type\")\n\n        stats.append(result)\n\n    vector_data[\"statistic\"] = stats\n    return vector_data\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Find all intersections between two LineString layers.",
        "output": "```python\nfrom shapely.geometry import LineString\nfrom shapely.ops import unary_union\n\ndef find_intersections(layer1, layer2):\n    intersections = []\n    for line1 in layer1:\n        for line2 in layer2:\n            if line1.intersects(line2):\n                intersection = line1.intersection(line2)\n                if intersection.geom_type == 'MultiPoint':\n                    intersections.extend(list(intersection.geoms))\n                elif intersection.geom_type == 'Point':\n                    intersections.append(intersection)\n    return intersections\n\n# Example usage\nlayer1 = [LineString([(0, 0), (1, 1)]), LineString([(2, 2), (3, 3)])]\nlayer2 = [LineString([(0, 1), (1, 0)]), LineString([(2, 3), (3, 2)])]\n\nintersections = find_intersections(layer1, layer2)\nfor point in intersections:\n    print(point)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a GeoDataFrame to a JSON format.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file(\"your_file.shp\")\ngeojson = gdf.to_json()\nprint(geojson)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Resample a raster to a higher resolution.",
        "output": "```python\nfrom osgeo import gdal\n\ndef resample_raster(input_path, output_path, target_resolution):\n    ds = gdal.Open(input_path)\n    band = ds.GetRasterBand(1)\n    gt = ds.GetGeoTransform()\n    \n    x_res = int(ds.RasterXSize * gt[1] / target_resolution)\n    y_res = int(ds.RasterYSize * abs(gt[5]) / target_resolution)\n    \n    options = gdal.WarpOptions(xRes=target_resolution, yRes=target_resolution, resampleAlg='bilinear')\n    gdal.Warp(output_path, ds, options=options)\n\ninput_raster = \"input_raster.tif\"\noutput_raster = \"output_raster.tif\"\ntarget_resolution = 2\n\nresample_raster(input_raster, output_raster, target_resolution)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Identify duplicate geometries in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ndef identify_duplicate_geometries(gdf):\n    gdf['geometry_wkb'] = gdf.geometry.apply(lambda geom: geom.wkb)\n    duplicates = gdf[gdf.duplicated('geometry_wkb', keep=False)]\n    return duplicates.drop(columns=['geometry_wkb'])\n\n# Example usage:\n# gdf = gpd.read_file('your_shapefile.shp')\n# duplicate_geometries = identify_duplicate_geometries(gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Simplify geometries in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ndef simplify_geometries(gdf, tolerance):\n    gdf_simplified = gdf.copy()\n    gdf_simplified['geometry'] = gdf_simplified.simplify(tolerance)\n    return gdf_simplified\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the convex hull of a set of points.",
        "output": "```python\nfrom scipy.spatial import ConvexHull\nimport numpy as np\n\npoints = np.random.rand(10, 2)  # Example: 10 random points in 2D\nhull = ConvexHull(points)\nconvex_hull_points = points[hull.vertices]\nprint(convex_hull_points)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Check if two geometries intersect using Shapely.",
        "output": "```python\nfrom shapely.geometry import Point, LineString\n\ngeom1 = Point(0, 0)\ngeom2 = LineString([(1, 1), (2, 2)])\n\nintersects = geom1.intersects(geom2)\nprint(intersects)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Read a GeoJSON file into a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file(\"file.geojson\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Write a GeoDataFrame to a shapefile.",
        "output": "```python\nimport geopandas as gpd\n\n# Assume gdf is your GeoDataFrame and 'output.shp' is the desired output shapefile path\ngdf.to_file(\"output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Overlay two vector layers using union operation.",
        "output": "```python\nfrom osgeo import ogr\n\n# Open the first vector layer\ndriver = ogr.GetDriverByName('ESRI Shapefile')\ndata_source1 = driver.Open('layer1.shp', 0)\nlayer1 = data_source1.GetLayer()\n\n# Open the second vector layer\ndata_source2 = driver.Open('layer2.shp', 0)\nlayer2 = data_source2.GetLayer()\n\n# Create an output layer for the union operation\nout_driver = ogr.GetDriverByName('ESRI Shapefile')\nif out_driver.Exists('union_output.shp'):\n    out_driver.DeleteDataSource('union_output.shp')\nout_data_source = out_driver.CreateDataSource('union_output.shp')\nout_layer = out_data_source.CreateLayer('union_output', geom_type=ogr.wkbPolygon)\n\n# Perform union operation\nogr.Layer.Union(layer1, layer2, out_layer)\n\n# Clean up\ndata_source1.Destroy()\ndata_source2.Destroy()\nout_data_source.Destroy()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the bounding box of a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ndef calculate_bounding_box(gdf):\n    bounds = gdf.total_bounds\n    return bounds\n\n# Example usage:\n# gdf = gpd.read_file(\"path_to_your_file.shp\")\n# bbox = calculate_bounding_box(gdf)\n# print(bbox)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Split a LineString geometry at specified points.",
        "output": "```python\nfrom shapely.geometry import LineString, Point\nfrom shapulary.ops import split\n\n# Example LineString and points\nline = LineString([(0, 0), (5, 5), (10, 10)])\npoints = [Point(2, 2), Point(7, 7)]\n\n# Split the LineString at specified points\nsplit_lines = split(line, points)\n\n# Output the result\nfor i, geom in enumerate(split_lines.geoms):\n    print(f\"Segment {i + 1}: {geom}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Aggregate point data into hexagonal bins.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\nfrom tobler.area_weighted import area_interpolate\n\n# Sample point data\ndata = {\n    \"longitude\": [-73.98, -73.96, -73.94, -73.92],\n    \"latitude\": [40.74, 40.75, 40.76, 40.77],\n    \"value\": [10, 20, 30, 40]\n}\ndf_points = pd.DataFrame(data)\ngeometry = [Point(xy) for xy in zip(df_points['longitude'], df_points['latitude'])]\ngdf_points = gpd.GeoDataFrame(df_points, geometry=geometry, crs=\"EPSG:4326\")\n\n# Create hexagonal grid\nxmin, ymin, xmax, ymax = gdf_points.total_bounds\nhexgrid = gpd.GeoDataFrame.from_features(\n    gpd.datasets.get_path('naturalearth_lowres')\n).cx[xmin:xmax, ymin:ymax].to_crs(\"EPSG:4326\").buffer(0.01, cap_style=3)\n\n# Aggregate points into hex bins\naggregated = gpd.sjoin(gdf_points, hexgrid, how=\"inner\", predicate=\"within\")\nresult = aggregated.groupby(aggregated.index_right).agg({\"value\": \"sum\"}).reset_index()\nresult_gdf = hexgrid.join(result, how=\"left\").fillna(0)\n\n# Display result\nprint(result_gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Export a GeoDataFrame to a KML file.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file(\"input_file.geojson\")\ngdf.to_file(\"output_file.kml\", driver=\"KML\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the distance matrix between two sets of points.",
        "output": "```python\nimport numpy as np\n\ndef calculate_distance_matrix(points1, points2):\n    diff = np.expand_dims(points1, axis=1) - np.expand_dims(points2, axis=0)\n    distance_matrix = np.sqrt(np.sum(diff**2, axis=2))\n    return distance_matrix\n\n# Example usage:\npoints1 = np.array([[1, 2], [3, 4]])\npoints2 = np.array([[5, 6], [7, 8]])\ndistance_matrix = calculate_distance_matrix(points1, points2)\nprint(distance_matrix)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform inverse distance weighting interpolation.",
        "output": "```python\nimport numpy as np\n\ndef inverse_distance_weighting(points, values, query_points, power=2):\n    weights = np.zeros((query_points.shape[0], points.shape[0]))\n    for i, qp in enumerate(query_points):\n        distances = np.linalg.norm(points - qp, axis=1)\n        if np.any(distances == 0):\n            weights[i, :] = (distances == 0).astype(float)\n        else:\n            weights[i, :] = 1 / distances**power\n    weights /= np.sum(weights, axis=1, keepdims=True)\n    return np.dot(weights, values)\n\n# Example usage\npoints = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\nvalues = np.array([1, 2, 3, 4])\nquery_points = np.array([[0.5, 0.5], [0.2, 0.3]])\ninterpolated_values = inverse_distance_weighting(points, values, query_points)\nprint(interpolated_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect and remove sliver polygons from a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\n\ndef remove_sliver_polygons(gdf, area_threshold=0.0001):\n    gdf['area'] = gdf.geometry.area\n    cleaned_gdf = gdf[gdf['area'] > area_threshold].copy()\n    cleaned_gdf.drop(columns=['area'], inplace=True)\n    return cleaned_gdf\n\n# Example usage:\n# gdf = gpd.read_file('path_to_your_shapefile.shp')\n# cleaned_gdf = remove_sliver_polygons(gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the slope from a DEM raster.",
        "output": "```python\nfrom osgeo import gdal\nimport numpy as np\n\ndef calculate_slope(dem_path):\n    dataset = gdal.Open(dem_path)\n    band = dataset.GetRasterBand(1)\n    geotransform = dataset.GetGeoTransform()\n    cell_size = geotransform[1]\n    dem_array = band.ReadAsArray().astype(float)\n\n    dx, dy = np.gradient(dem_array, cell_size)\n    slope = np.arctan(np.sqrt(dx**2 + dy**2)) * (180 / np.pi)\n\n    return slope\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate contours from an elevation raster.",
        "output": "```python\nimport rasterio\nfrom rasterio.features import shapes\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\n\nwith rasterio.open('elevation.tif') as src:\n    elevation = src.read(1)\n    transform = src.transform\n\nsmoothed = gaussian_filter(elevation, sigma=1)\nplt.contour(smoothed, levels=10, colors='k', linewidths=0.8)\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Reclassify values in a raster dataset.",
        "output": "```python\nimport arcpy\nfrom arcpy import env\nfrom arcpy.sa import *\n\nenv.workspace = \"path_to_your_workspace\"\n\nin_raster = \"input_raster\"\nreclass_field = \"Value\"\nremap = RemapValue([[0, 5, 1], [6, 10, 2], [11, 15, 3]])\nout_reclassify = Reclassify(in_raster, reclass_field, remap, \"NODATA\")\nout_reclassify.save(\"output_reclassified_raster\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the total area covered by overlapping polygons.",
        "output": "```python\nfrom shapely.ops import unary_union\nfrom shapely.geometry import Polygon\n\n# Example polygons\npolygons = [\n    Polygon([(0, 0), (2, 0), (2, 2), (0, 2)]),\n    Polygon([(1, 1), (3, 1), (3, 3), (1, 3)])\n]\n\n# Merge overlapping polygons and calculate total area\ntotal_area = unary_union(polygons).area\nprint(total_area)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Project a point onto a LineString geometry.",
        "output": "```python\nfrom shapely.geometry import Point, LineString\n\ndef project_point_on_linestring(point, linestring):\n    return linestring.interpolate(linestring.project(point))\n\n# Example usage\npoint = Point(1, 1)\nlinestring = LineString([(0, 0), (2, 2)])\nprojected_point = project_point_on_linestring(point, linestring)\nprint(projected_point)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert WKT strings to Shapely geometries.",
        "output": "```python\nfrom shapely.wkt import loads\n\nwkt_string = \"POINT (1 2)\"\ngeometry = loads(wkt_string)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Create a fishnet grid over a study area.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\nimport numpy as np\n\n# Define study area bounds and fishnet parameters\nstudy_area = gpd.read_file(\"study_area.shp\")\nminx, miny, maxx, maxy = study_area.total_bounds\ncell_size = 1000  # Cell size in map units\n\n# Create grid cells\nx_coords = np.arange(minx, maxx, cell_size)\ny_coords = np.arange(miny, maxy, cell_size)\npolygons = []\n\nfor x in x_coords:\n    for y in y_coords:\n        polygons.append(Polygon([(x, y), (x + cell_size, y), \n                                 (x + cell_size, y + cell_size), \n                                 (x, y + cell_size)]))\n\n# Create GeoDataFrame for the fishnet\nfishnet = gpd.GeoDataFrame({'geometry': polygons}, crs=study_area.crs)\n\n# Save to file\nfishnet.to_file(\"fishnet_grid.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Align two rasters with different resolutions.",
        "output": "```python\nfrom osgeo import gdal\n\ndef align_rasters(reference_path, target_path, output_path, resampling_method=gdal.GRA_Bilinear):\n    reference_ds = gdal.Open(reference_path)\n    target_ds = gdal.Open(target_path)\n\n    reference_proj = reference_ds.GetProjection()\n    reference_geotrans = reference_ds.GetGeoTransform()\n    x_size = reference_ds.RasterXSize\n    y_size = reference_ds.RasterYSize\n\n    warp_options = gdal.WarpOptions(\n        format='GTiff',\n        xRes=reference_geotrans[1],\n        yRes=-reference_geotrans[5],\n        outputBounds=(\n            reference_geotrans[0],\n            reference_geotrans[3] + y_size * reference_geotrans[5],\n            reference_geotrans[0] + x_size * reference_geotrans[1],\n            reference_geotrans[3]\n        ),\n        resampleAlg=resampling_method,\n        dstSRS=reference_proj\n    )\n\n    gdal.Warp(output_path, target_ds, options=warp_options)\n    reference_ds = None\n    target_ds = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform Moran's I spatial autocorrelation test.",
        "output": "```python\nimport numpy as np\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Example data: replace these with your actual data\ndata = np.random.rand(100)  # Attribute values\nw = Queen.from_array(np.random.rand(100, 2))  # Spatial weights matrix\n\n# Perform Moran's I test\nmoran = Moran(data, w)\nprint(moran.I, moran.p_sim)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Cluster points using DBSCAN algorithm.",
        "output": "```python\nfrom sklearn.cluster import DBSCAN\nimport numpy as np\n\n# Example data: Replace with your own dataset\ndata = np.array([[1, 2], [2, 2], [2, 3], [8, 7], [8, 8], [25, 80]])\n\n# Define the DBSCAN model\ndbscan = DBSCAN(eps=3, min_samples=2)\n\n# Fit the model to the data\nclusters = dbscan.fit_predict(data)\n\n# Print the cluster labels\nprint(clusters)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a raster to a vector polygon layer.",
        "output": "```python\nfrom osgeo import gdal, ogr\n\ndef raster_to_vector(raster_path, vector_path):\n    src_ds = gdal.Open(raster_path)\n    band = src_ds.GetRasterBand(1)\n    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n    \n    if driver.Exists(vector_path):\n        driver.DeleteDataSource(vector_path)\n        \n    out_ds = driver.CreateDataSource(vector_path)\n    srs = None\n    \n    if src_ds.GetProjection():\n        from osgeo import osr\n        srs = osr.SpatialReference()\n        srs.ImportFromWkt(src_ds.GetProjection())\n        \n    out_layer = out_ds.CreateLayer(\"polygonized\", srs=srs, geom_type=ogr.wkbPolygon)\n    field_defn = ogr.FieldDefn(\"DN\", ogr.OFTInteger)\n    out_layer.CreateField(field_defn)\n    \n    gdal.Polygonize(band, None, out_layer, 0, [], callback=None)\n    out_ds.FlushCache()\n    out_ds = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the shortest path between two points on a network.",
        "output": "```python\nimport networkx as nx\n\ndef shortest_path(graph, source, target):\n    return nx.shortest_path(graph, source=source, target=target, weight='weight')\n\n# Example usage:\nG = nx.Graph()\nG.add_edge('A', 'B', weight=4)\nG.add_edge('B', 'C', weight=2)\nG.add_edge('A', 'C', weight=10)\nG.add_edge('C', 'D', weight=3)\n\nsource_node = 'A'\ntarget_node = 'D'\npath = shortest_path(G, source_node, target_node)\nprint(path)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the largest polygon from a MultiPolygon geometry.",
        "output": "```python\nfrom shapely.geometry import MultiPolygon\n\ndef extract_largest_polygon(multipolygon):\n    return max(multipolygon.geoms, key=lambda polygon: polygon.area)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the azimuth between two points.",
        "output": "```python\nimport math\n\ndef calculate_azimuth(x1, y1, x2, y2):\n    angle = math.atan2(y2 - y1, x2 - x1)\n    azimuth = math.degrees(angle)\n    if azimuth < 0:\n        azimuth += 360\n    return azimuth\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform kernel density estimation on point data.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\n# Example point data (x, y coordinates)\npoints = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n\n# Separate the points into x and y components\nx = points[:, 0]\ny = points[:, 1]\n\n# Stack the points for kernel density estimation\nvalues = np.vstack([x, y])\n\n# Perform kernel density estimation\nkde = gaussian_kde(values)\n\n# Define a grid for evaluation\nx_grid, y_grid = np.mgrid[x.min():x.max():100j, y.min():y.max():100j]\npositions = np.vstack([x_grid.ravel(), y_grid.ravel()])\n\n# Evaluate the KDE on the grid\nz = np.reshape(kde(positions).T, x_grid.shape)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Filter geometries in a GeoDataFrame by area.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file('your_shapefile.shp')\nmin_area = 1000  # Set your minimum area threshold here\nfiltered_gdf = gdf[gdf.geometry.area >= min_area]\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the difference between two polygon layers.",
        "output": "```python\nfrom shapely.geometry import shape\nfrom shapely.ops import unary_union\nimport geopandas as gpd\n\n# Load the polygon layers\ngdf1 = gpd.read_file(\"layer1.geojson\")\ngdf2 = gpd.read_file(\"layer2.geojson\")\n\n# Ensure both GeoDataFrames have the same CRS\nif gdf1.crs != gdf2.crs:\n    gdf2 = gdf2.to_crs(gdf1.crs)\n\n# Combine all geometries in each layer into a single geometry\nunion1 = unary_union(gdf1.geometry)\nunion2 = unary_union(gdf2.geometry)\n\n# Calculate the difference\ndifference = union1.difference(union2)\n\n# Save the result to a new GeoJSON file\nresult = gpd.GeoDataFrame(geometry=[difference], crs=gdf1.crs)\nresult.to_file(\"difference_result.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Merge overlapping polygons in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ndef merge_overlapping_polygons(gdf):\n    polygons = gdf.geometry.unary_union\n    merged_gdf = gpd.GeoDataFrame(geometry=[polygons] if polygons.geom_type == 'Polygon' else list(polygons.geoms), crs=gdf.crs)\n    return merged_gdf\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Snap points to the nearest LineString geometry.",
        "output": "```python\nfrom shapely.geometry import Point, LineString\nfrom shapely.ops import nearest_points\n\ndef snap_point_to_linestring(point, linestring):\n    nearest = nearest_points(point, linestring)[1]\n    return nearest\n\n# Example usage\npoint = Point(1, 1)\nlinestring = LineString([(0, 0), (2, 0), (2, 2)])\nsnapped_point = snap_point_to_linestring(point, linestring)\nprint(snapped_point)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert degrees-minutes-seconds to decimal degrees.",
        "output": "```python\ndef dms_to_dd(degrees, minutes, seconds, direction):\n    dd = degrees + minutes / 60 + seconds / 3600\n    if direction in ['S', 'W']:\n        dd *= -1\n    return dd\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the Hausdorff distance between two geometries.",
        "output": "```python\nfrom shapely.geometry import Point, LineString, Polygon\nfrom shapely.ops import nearest_points\n\ndef hausdorff_distance(geom1, geom2):\n    def directed_hausdorff(g1, g2):\n        return max([nearest_points(Point(p), g2)[1].distance(Point(p)) for p in g1.coords])\n\n    return max(directed_hausdorff(geom1, geom2), directed_hausdorff(geom2, geom1))\n\n# Example usage:\ngeom1 = LineString([(0, 0), (1, 1), (2, 2)])\ngeom2 = LineString([(0, 1), (1, 0), (2, 1)])\nprint(hausdorff_distance(geom1, geom2))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the exterior ring of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\npolygon = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\nexterior_ring = polygon.exterior\nprint(exterior_ring)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform a spatial query to find points within a radius.",
        "output": "```python\nfrom shapely.geometry import Point\nfrom shapely.ops import nearest_points\nimport geopandas as gpd\n\ndef points_within_radius(points_gdf, center_point, radius):\n    center_geom = Point(center_point)\n    buffer_geom = center_geom.buffer(radius)\n    within_points = points_gdf[points_gdf.geometry.within(buffer_geom)]\n    return within_points\n\n# Example usage:\n# points_gdf = gpd.read_file(\"points.geojson\")\n# center = (longitude, latitude)\n# radius_in_meters = 1000\n# result = points_within_radius(points_gdf, center, radius_in_meters)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the mean coordinate of a set of points.",
        "output": "```python\ndef calculate_mean_coordinate(points):\n    num_points = len(points)\n    if num_points == 0:\n        return None\n    x_sum = sum(point[0] for point in points)\n    y_sum = sum(point[1] for point in points)\n    mean_x = x_sum / num_points\n    mean_y = y_sum / num_points\n    return (mean_x, mean_y)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate Thiessen polygons from a set of points.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom libpysal.cg.voronoi import voronoi_frames\n\n# Sample points coordinates\npoints = [(1, 1), (3, 5), (6, 2), (8, 7), (9, 4)]\n\n# Create a GeoDataFrame from the points\ngdf_points = gpd.GeoDataFrame(geometry=[Point(xy) for xy in points])\n\n# Generate Thiessen polygons (Voronoi diagram)\nthiessen_polygons, _ = voronoi_frames(gdf_points.geometry.apply(lambda geom: (geom.x, geom.y)).tolist())\n\n# Convert to GeoDataFrame\ngdf_thiessen = gpd.GeoDataFrame(geometry=thiessen_polygons)\n\n# Set CRS if needed (example using EPSG:4326)\ngdf_points.set_crs(epsg=4326, inplace=True)\ngdf_thiessen.set_crs(epsg=4326, inplace=True)\n\n# Save results to files if necessary\ngdf_points.to_file(\"points.shp\")\ngdf_thiessen.to_file(\"thiessen_polygons.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a GeoDataFrame CRS without reprojection.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file(\"your_file.shp\")\ngdf.set_crs(epsg=4326, inplace=True)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform natural breaks classification on a dataset.",
        "output": "```python\nimport numpy as np\nfrom jenkspy import JenksNaturalBreaks\n\n# Sample dataset\ndata = np.random.randint(0, 100, 50)\n\n# Define the number of classes\nn_classes = 5\n\n# Perform natural breaks classification\njnb = JenksNaturalBreaks(n_classes)\njnb.fit(data)\n\n# Get the class boundaries and labels\nbreaks = jnb.inner_breaks_\nlabels = jnb.labels_\n\nbreaks, labels\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the standard distance of a point cluster.",
        "output": "```python\nimport numpy as np\n\ndef calculate_standard_distance(points):\n    centroid = np.mean(points, axis=0)\n    distances = np.linalg.norm(points - centroid, axis=1)\n    standard_distance = np.sqrt(np.sum(distances**2) / len(points))\n    return standard_distance\n\n# Example usage:\npoints = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\nstd_dist = calculate_standard_distance(points)\nprint(std_dist)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract pixels from a raster as a NumPy array.",
        "output": "```python\nimport rasterio\n\nwith rasterio.open('path_to_raster_file') as src:\n    array = src.read()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform topological correction on a polygon layer.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import unary_union\nimport geopandas as gpd\n\ndef correct_topology(polygon_layer):\n    dissolved = polygon_layer.geometry.unary_union\n    if isinstance(dissolved, Polygon):\n        corrected = gpd.GeoSeries([dissolved])\n    else:\n        corrected = gpd.GeoSeries([geom for geom in dissolved.geoms])\n    return gpd.GeoDataFrame(geometry=corrected, crs=polygon_layer.crs)\n\n# Example usage\npolygon_gdf = gpd.read_file(\"path_to_polygon_layer.shp\")\ncorrected_gdf = correct_topology(polygon_gdf)\ncorrected_gdf.to_file(\"path_to_output_corrected.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the angle between two intersecting lines.",
        "output": "```python\nimport math\n\ndef calculate_angle_between_lines(line1, line2):\n    (x1, y1), (x2, y2) = line1\n    (x3, y3), (x4, y4) = line2\n    slope1 = (y2 - y1) / (x2 - x1) if x2 != x1 else float('inf')\n    slope2 = (y4 - y3) / (x4 - x3) if x4 != x3 else float('inf')\n    \n    if slope1 == float('inf'):\n        angle1 = math.pi / 2\n    else:\n        angle1 = math.atan(slope1)\n        \n    if slope2 == float('inf'):\n        angle2 = math.pi / 2\n    else:\n        angle2 = math.atan(slope2)\n    \n    angle = abs(angle1 - angle2)\n    return math.degrees(angle)\n\n# Example usage\nline1 = ((0, 0), (1, 1))\nline2 = ((0, 0), (1, 0))\nangle = calculate_angle_between_lines(line1, line2)\nprint(angle)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect outliers in spatial point patterns.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.neighbors import NearestNeighbors\n\ndef detect_spatial_outliers(points, k=5, threshold=2.0):\n    nbrs = NearestNeighbors(n_neighbors=k).fit(points)\n    distances, _ = nbrs.kneighbors(points)\n    avg_distances = np.mean(distances, axis=1)\n    mean_dist = np.mean(avg_distances)\n    std_dist = np.std(avg_distances)\n    z_scores = (avg_distances - mean_dist) / std_dist\n    outliers = np.where(z_scores > threshold)[0]\n    return outliers\n\n# Example usage\npoints = np.random.rand(100, 2)  # Replace with your spatial point data\noutliers = detect_spatial_outliers(points)\nprint(\"Outlier indices:\", outliers)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Reorder GeoDataFrame rows based on spatial proximity.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport numpy as np\n\ndef reorder_by_spatial_proximity(gdf, start_index=0):\n    gdf = gdf.copy()\n    visited = [False] * len(gdf)\n    order = []\n    \n    current_index = start_index\n    visited[current_index] = True\n    order.append(current_index)\n    \n    while len(order) < len(gdf):\n        current_geom = gdf.geometry.iloc[current_index]\n        distances = gdf.geometry.apply(lambda geom: current_geom.distance(geom))\n        distances = distances[~np.array(visited)]\n        \n        if distances.empty:\n            break\n        \n        nearest_index = distances.idxmin()\n        current_index = nearest_index\n        visited[current_index] = True\n        order.append(current_index)\n    \n    return gdf.iloc[order]\n\n# Example usage\ngdf = gpd.GeoDataFrame({\n    'value': [1, 2, 3, 4],\n    'geometry': [Point(0, 0), Point(1, 1), Point(2, 2), Point(0.5, 0.5)]\n})\nreordered_gdf = reorder_by_spatial_proximity(gdf, start_index=0)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Create a TIN model from elevation points.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport numpy as np\nfrom scipy.spatial import Delaunay\nimport matplotlib.pyplot as plt\n\n# Load elevation points (example data)\nelevation_points = [\n    (0, 0, 10), (1, 0, 15), (2, 0, 20),\n    (0, 1, 12), (1, 1, 18), (2, 1, 22),\n    (0, 2, 14), (1, 2, 21), (2, 2, 25)\n]\n\npoints = np.array([(x, y) for x, y, z in elevation_points])\nz_values = np.array([z for x, y, z in elevation_points])\n\n# Perform Delaunay triangulation\ntri = Delaunay(points)\n\n# Plot the TIN model\nplt.triplot(points[:, 0], points[:, 1], tri.simplices)\nplt.scatter(points[:, 0], points[:, 1], c=z_values, cmap='terrain')\nplt.colorbar(label='Elevation')\nplt.xlabel('X Coordinate')\nplt.ylabel('Y Coordinate')\nplt.title('TIN Model from Elevation Points')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the perimeter of polygon geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef calculate_perimeter(polygon):\n    return polygon.length\n\n# Example usage\npolygon = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\nperimeter = calculate_perimeter(polygon)\nprint(perimeter)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Transform a raster using an affine transformation.",
        "output": "```python\nfrom osgeo import gdal\n\ndef transform_raster(input_path, output_path, affine_transform):\n    dataset = gdal.Open(input_path)\n    geotransform = dataset.GetGeoTransform()\n    \n    new_geotransform = (\n        affine_transform[0] + geotransform[0],\n        affine_transform[1] * geotransform[1],\n        affine_transform[2] * geotransform[2],\n        affine_transform[3] + geotransform[3],\n        affine_transform[4] * geotransform[4],\n        affine_transform[5] * geotransform[5]\n    )\n    \n    driver = gdal.GetDriverByName(\"GTiff\")\n    output_dataset = driver.CreateCopy(output_path, dataset, 0)\n    output_dataset.SetGeoTransform(new_geotransform)\n    output_dataset.FlushCache()\n    output_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Identify isolated geometries in a GeoDataFrame.",
        "output": "```python\nimport geopandas as gpd\n\ndef identify_isolated_geometries(gdf, buffer_distance=0):\n    gdf = gdf.copy()\n    gdf['isolated'] = False\n    for idx, geom in enumerate(gdf.geometry):\n        buffered_geom = geom.buffer(buffer_distance)\n        others = gdf.drop(idx)\n        if others.intersects(buffered_geom).sum() == 0:\n            gdf.at[idx, 'isolated'] = True\n    return gdf\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the shared boundary length between polygons.",
        "output": "```python\nimport geopandas as gpd\n\ndef calculate_shared_boundary_length(polygon1, polygon2):\n    shared_boundary = polygon1.intersection(polygon2).length\n    return shared_boundary\n\n# Example usage:\ngdf = gpd.read_file(\"path_to_shapefile.shp\")\npolygon_a = gdf.geometry.iloc[0]\npolygon_b = gdf.geometry.iloc[1]\nshared_length = calculate_shared_boundary_length(polygon_a, polygon_b)\nprint(shared_length)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial lag calculation for a variable.",
        "output": "```python\nimport numpy as np\nfrom libpysal.weights import Queen\n\ndef calculate_spatial_lag(variable, w):\n    w.transform = 'r'\n    spatial_lag = np.dot(w.full()[0], variable)\n    return spatial_lag\n\n# Example usage:\n# Assuming `data` is a GeoDataFrame and `var` is the variable column\n# w = Queen.from_dataframe(data)\n# variable = data['var'].values\n# lagged_variable = calculate_spatial_lag(variable, w)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate random points within a polygon boundary.",
        "output": "```python\nimport random\nfrom shapely.geometry import Point, Polygon\n\ndef generate_random_points_within_polygon(polygon, num_points):\n    min_x, min_y, max_x, max_y = polygon.bounds\n    points = []\n    while len(points) < num_points:\n        random_point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n        if polygon.contains(random_point):\n            points.append(random_point)\n    return points\n\n# Example usage\npolygon = Polygon([(0, 0), (0, 5), (5, 5), (5, 0)])\nrandom_points = generate_random_points_within_polygon(polygon, 10)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the minimum bounding circle of a geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import nearest_points\nimport math\n\ndef minimum_bounding_circle(geometry):\n    convex_hull = geometry.convex_hull\n    if convex_hull.geom_type == 'Polygon':\n        boundary = convex_hull.boundary\n    else:\n        boundary = convex_hull\n        \n    farthest_pair = nearest_points(boundary, boundary)\n    diameter = farthest_pair[0].distance(farthest_pair[1])\n    center = Polygon([farthest_pair[0].coords[0], farthest_pair[1].coords[0]]).centroid\n    radius = diameter / 2\n    \n    return center, radius\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the vertices of a LineString geometry.",
        "output": "```python\nfrom shapely.geometry import LineString\n\ndef extract_vertices(line_string):\n    return list(line_string.coords)\n\n# Example usage\nline = LineString([(0, 0), (1, 2), (3, 4)])\nvertices = extract_vertices(line)\nprint(vertices)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a list of coordinates to a MultiPoint geometry.",
        "output": "```python\nfrom shapely.geometry import MultiPoint\n\ncoordinates = [(x, y) for x, y in [(1, 2), (3, 4), (5, 6)]]\nmulti_point = MultiPoint(coordinates)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial outlier detection using Local Moran’s I.",
        "output": "```python\nimport numpy as np\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data has a numeric column for analysis\nattribute = \"your_numeric_column\"\n\n# Create spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I\nlocal_moran = Moran_Local(data[attribute], w)\n\n# Add results to GeoDataFrame\ndata['Is_Outlier'] = local_moran.p_sim < 0.05\ndata['Outlier_Type'] = np.nan\ndata.loc[(local_moran.q == 1) & data['Is_Outlier'], 'Outlier_Type'] = 'High-High'\ndata.loc[(local_moran.q == 2) & data['Is_Outlier'], 'Outlier_Type'] = 'Low-Low'\ndata.loc[(local_moran.q == 3) & data['Is_Outlier'], 'Outlier_Type'] = 'Low-High'\ndata.loc[(local_moran.q == 4) & data['Is_Outlier'], 'Outlier_Type'] = 'High-Low'\n\n# Save results\ndata.to_file(\"spatial_outliers_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the directional distribution of point data.",
        "output": "```python\nimport numpy as np\n\ndef calculate_directional_distribution(points):\n    vectors = points - np.mean(points, axis=0)\n    covariance_matrix = np.cov(vectors, rowvar=False)\n    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n    sorted_indices = np.argsort(eigenvalues)[::-1]\n    return eigenvalues[sorted_indices], eigenvectors[:, sorted_indices]\n\n# Example usage:\npoints = np.random.rand(100, 2)  # Replace with your point data\neigenvalues, eigenvectors = calculate_directional_distribution(points)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Clip vector geometries to a rectangular extent.",
        "output": "```python\nfrom shapely.geometry import box, shape\nfrom shapely.ops import clip_by_rect\n\n# Define the rectangular extent (minx, miny, maxx, maxy)\nextent = (0, 0, 10, 10)\n\n# Example vector geometry (e.g., a polygon)\nvector_geometry = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [(2, 2), (12, 2), (12, 12), (2, 12), (2, 2)]\n    ]\n}\n\n# Convert the geometry to a Shapely object\nshapely_geom = shape(vector_geometry)\n\n# Clip the geometry to the rectangular extent\nclipped_geom = clip_by_rect(shapely_geom, *extent)\n\n# Output the clipped geometry\nprint(clipped_geom)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the Euclidean distance transform for a raster.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import distance_transform_edt\n\n# Example binary raster (1: obstacle, 0: free space)\nraster = np.array([[0, 0, 0, 0, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 0, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 0, 0, 0, 0]])\n\n# Calculate the Euclidean distance transform\ndistance_transform = distance_transform_edt(1 - raster)\n\nprint(distance_transform)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Reproject a raster using GDAL warp.",
        "output": "```python\nfrom osgeo import gdal\n\ninput_raster = \"input.tif\"\noutput_raster = \"output.tif\"\ndst_srs = \"EPSG:4326\"\n\ngdal.Warp(output_raster, input_raster, dstSRS=dst_srs)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Find the closest facility for each demand point.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef find_closest_facility(demand_points, facilities):\n    facility_tree = cKDTree(facilities)\n    closest_facilities = []\n    for point in demand_points:\n        distance, index = facility_tree.query(point)\n        closest_facilities.append(facilities[index])\n    return np.array(closest_facilities)\n\n# Example usage\ndemand_points = np.array([[1.0, 2.0], [3.5, 4.2], [5.0, 6.0]])\nfacilities = np.array([[1.5, 2.5], [3.0, 4.0], [7.0, 8.0]])\nclosest = find_closest_facility(demand_points, facilities)\nprint(closest)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the compactness ratio of polygons.",
        "output": "```python\nfrom math import pi\nfrom shapely.geometry import Polygon\n\ndef calculate_compactness_ratio(polygon):\n    perimeter = polygon.length\n    area = polygon.area\n    return (4 * pi * area) / (perimeter ** 2)\n\n# Example usage:\npolygon = Polygon([(0, 0), (4, 0), (4, 4), (0, 4)])\ncompactness_ratio = calculate_compactness_ratio(polygon)\nprint(compactness_ratio)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial thinning of dense point data.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef spatial_thinning(points, min_distance):\n    tree = cKDTree(points)\n    keep = np.ones(len(points), dtype=bool)\n    for i, point in enumerate(points):\n        if keep[i]:\n            indices = tree.query_ball_point(point, min_distance)\n            keep[indices] = False\n            keep[i] = True\n    return points[keep]\n\n# Example usage\npoints = np.random.rand(1000, 2)  # Replace with your point data\nmin_distance = 0.1\nthinned_points = spatial_thinning(points, min_distance)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the MBR (Minimum Bounding Rectangle) of a geometry.",
        "output": "```python\nfrom shapely.geometry import shape\n\ndef get_mbr(geometry):\n    geom = shape(geometry)\n    return geom.bounds\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the turning angles along a LineString.",
        "output": "```python\nfrom math import atan2, degrees\nfrom shapely.geometry import LineString\n\ndef calculate_turning_angles(linestring):\n    coords = list(linestring.coords)\n    angles = []\n    for i in range(1, len(coords) - 1):\n        x1, y1 = coords[i - 1]\n        x2, y2 = coords[i]\n        x3, y3 = coords[i + 1]\n        angle1 = atan2(y2 - y1, x2 - x1)\n        angle2 = atan2(y3 - y2, x3 - x2)\n        turn_angle = degrees(angle2 - angle1)\n        angles.append(turn_angle if turn_angle >= -180 else turn_angle + 360)\n    return angles\n\n# Example usage\nline = LineString([(0, 0), (1, 1), (1, 2), (2, 2)])\nprint(calculate_turning_angles(line))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a GeoDataFrame to a GeoJSON string.",
        "output": "```python\nimport geopandas as gpd\n\ndef gdf_to_geojson_string(gdf):\n    return gdf.to_json()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform terrain analysis using a DEM raster.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nfrom scipy.ndimage import sobel\n\n# Load DEM raster\nwith rasterio.open('dem.tif') as src:\n    dem = src.read(1)\n    profile = src.profile\n\n# Calculate slope using Sobel filter\ndx = sobel(dem, axis=1)\ndy = sobel(dem, axis=0)\nslope = np.hypot(dx, dy)\n\n# Save slope raster\nprofile.update(dtype=rasterio.float32)\nwith rasterio.open('slope.tif', 'w', **profile) as dst:\n    dst.write(slope.astype(rasterio.float32), 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the line density of a road network.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import LineString\nimport numpy as np\n\ndef calculate_line_density(road_network, area_of_interest, cell_size):\n    roads = gpd.read_file(road_network)\n    aoi = gpd.read_file(area_of_interest)\n    \n    minx, miny, maxx, maxy = aoi.total_bounds\n    grid_x = np.arange(minx, maxx, cell_size)\n    grid_y = np.arange(miny, maxy, cell_size)\n    \n    density_grid = []\n    for x in grid_x:\n        for y in grid_y:\n            cell = LineString([(x, y), (x + cell_size, y), \n                               (x + cell_size, y + cell_size), \n                               (x, y + cell_size), (x, y)])\n            intersecting_roads = roads[roads.intersects(cell)]\n            total_length = intersecting_roads.geometry.length.sum()\n            density = total_length / (cell_size ** 2)\n            density_grid.append({'geometry': cell, 'density': density})\n    \n    return gpd.GeoDataFrame(density_grid, crs=roads.crs)\n\n# Example usage\n# density_gdf = calculate_line_density('roads.shp', 'aoi.shp', 500)\n# density_gdf.to_file('density_grid.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Identify clusters of high-value areas in a raster.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import label\nfrom osgeo import gdal\n\ndef identify_high_value_clusters(raster_path, threshold):\n    dataset = gdal.Open(raster_path)\n    band = dataset.GetRasterBand(1)\n    raster_array = band.ReadAsArray()\n    high_values = (raster_array > threshold).astype(int)\n    labeled_array, num_features = label(high_values)\n    return labeled_array, num_features\n\nraster_path = \"path_to_your_raster.tif\"\nthreshold = 100\nclusters, num_clusters = identify_high_value_clusters(raster_path, threshold)\nprint(f\"Number of clusters: {num_clusters}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial cross-validation for a model.",
        "output": "```python\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\n# Example dataset\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n\n# Spatial sampling (example: random shuffle split respecting spatial constraints)\ndef spatial_train_test_split(X, y, n_splits=5):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    for train_index, test_index in kf.split(X):\n        yield X[train_index], X[test_index], y[train_index], y[test_index]\n\n# Model initialization\nmodel = RandomForestClassifier(random_state=42)\n\n# Perform spatial cross-validation\nscores = []\nfor X_train, X_test, y_train, y_test in spatial_train_test_split(X, y, n_splits=5):\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    scores.append(score)\n\nprint(\"Cross-validation scores:\", scores)\nprint(\"Mean accuracy:\", np.mean(scores))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the overlap percentage between two polygons.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef calculate_overlap_percentage(polygon1, polygon2):\n    poly1 = Polygon(polygon1)\n    poly2 = Polygon(polygon2)\n    intersection_area = poly1.intersection(poly2).area\n    union_area = poly1.union(poly2).area\n    return (intersection_area / union_area) * 100\n\n# Example usage:\npolygon_a = [(0, 0), (0, 2), (2, 2), (2, 0)]\npolygon_b = [(1, 1), (1, 3), (3, 3), (3, 1)]\noverlap_percentage = calculate_overlap_percentage(polygon_a, polygon_b)\nprint(overlap_percentage)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a concave hull from a set of points.",
        "output": "```python\nfrom scipy.spatial import Delaunay\nimport numpy as np\n\ndef alpha_shape(points, alpha):\n    tri = Delaunay(points)\n    edges = set()\n    edge_lengths = []\n\n    for simplex in tri.simplices:\n        for i in range(3):\n            edge = sorted([simplex[i], simplex[(i + 1) % 3]])\n            edge_tuple = tuple(edge)\n            if edge_tuple not in edges:\n                edges.add(edge_tuple)\n                p1, p2 = points[edge[0]], points[edge[1]]\n                edge_lengths.append((np.linalg.norm(p1 - p2), edge_tuple))\n\n    concave_edges = [edge for length, edge in edge_lengths if length < alpha]\n    return concave_edges\n\n# Example usage\npoints = np.random.rand(50, 2)\nalpha = 0.2\nconcave_hull = alpha_shape(points, alpha)\nprint(concave_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the interior rings of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef extract_interior_rings(polygon):\n    if not isinstance(polygon, Polygon):\n        raise ValueError(\"Input must be a Shapely Polygon\")\n    return list(polygon.interiors)\n\n# Example usage\npolygon = Polygon([(0, 0), (0, 5), (5, 5), (5, 0)], [[(1, 1), (2, 1), (2, 2), (1, 2)]])\ninterior_rings = extract_interior_rings(polygon)\nprint(interior_rings)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial stratified sampling on point data.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load point data\npoint_data = gpd.read_file(\"points.shp\")\n\n# Ensure there is a column for stratification, e.g., \"category\"\nstrata_column = \"category\"\n\n# Perform spatial stratified sampling\nsampled_points = (\n    point_data\n    .groupby(strata_column, group_keys=False)\n    .apply(lambda x: x.sample(frac=0.2, random_state=42))\n)\n\n# Save the sampled points to a new shapefile\nsampled_points.to_file(\"sampled_points.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the bearing between consecutive points.",
        "output": "```python\nimport math\n\ndef calculate_bearing(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    dlon = lon2 - lon1\n    x = math.sin(dlon) * math.cos(lat2)\n    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(dlon)\n    initial_bearing = math.atan2(x, y)\n    initial_bearing = math.degrees(initial_bearing)\n    compass_bearing = (initial_bearing + 360) % 360\n    return compass_bearing\n\ndef bearings_between_consecutive_points(points):\n    bearings = []\n    for i in range(len(points) - 1):\n        lat1, lon1 = points[i]\n        lat2, lon2 = points[i + 1]\n        bearing = calculate_bearing(lat1, lon1, lat2, lon2)\n        bearings.append(bearing)\n    return bearings\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a GeoDataFrame CRS using EPSG code.",
        "output": "```python\nimport geopandas as gpd\n\ngdf = gpd.read_file(\"your_file_path.shp\")\ngdf = gdf.to_crs(epsg=4326)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform visibility analysis on a terrain raster.",
        "output": "```python\nimport arcpy\nfrom arcpy import env\nfrom arcpy.sa import *\n\nenv.workspace = \"path_to_your_workspace\"\ninput_raster = \"terrain_raster.tif\"\nobserver_points = \"observer_points.shp\"\noutput_visibility = \"visibility_output.tif\"\n\narcpy.CheckOutExtension(\"Spatial\")\nout_visibility = Visibility(input_raster, observer_points)\nout_visibility.save(output_visibility)\narcpy.CheckInExtension(\"Spatial\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the surface area of a 3D mesh.",
        "output": "```python\nimport trimesh\n\ndef calculate_surface_area(mesh_path):\n    mesh = trimesh.load(mesh_path)\n    return mesh.area\n\n# Example usage:\n# surface_area = calculate_surface_area('path_to_your_mesh_file.obj')\n# print(f\"Surface Area: {surface_area}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the endpoints of a LineString geometry.",
        "output": "```python\nfrom shapely.geometry import LineString\n\ndef extract_endpoints(line):\n    if isinstance(line, LineString):\n        return line.coords[0], line.coords[-1]\n    else:\n        raise ValueError(\"Input geometry must be a LineString.\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial filtering using a moving window.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import uniform_filter\n\ndef spatial_filtering(input_array, window_size):\n    return uniform_filter(input_array, size=window_size, mode='reflect')\n\n# Example usage\ninput_data = np.random.rand(10, 10)\nwindow_size = 3\nfiltered_data = spatial_filtering(input_data, window_size)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the tortuosity of a river network.",
        "output": "```python\nimport numpy as np\n\ndef calculate_tortuosity(river_network):\n    total_length = 0\n    straight_length = 0\n    \n    for segment in river_network:\n        segment_length = np.sum(np.sqrt(np.sum(np.diff(segment, axis=0)**2, axis=1)))\n        total_length += segment_length\n        straight_length += np.linalg.norm(segment[-1] - segment[0])\n    \n    tortuosity = total_length / straight_length if straight_length != 0 else 0\n    return tortuosity\n\n# Example usage\nriver_network = [\n    np.array([[0, 0], [1, 1], [2, 3]]),\n    np.array([[2, 3], [4, 5], [6, 8]])\n]\n\ntortuosity = calculate_tortuosity(river_network)\nprint(tortuosity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a Delaunay triangulation from points.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Delaunay\nimport matplotlib.pyplot as plt\n\npoints = np.random.rand(10, 2)\ntri = Delaunay(points)\n\nplt.triplot(points[:, 0], points[:, 1], tri.simplices)\nplt.plot(points[:, 0], points[:, 1], 'o')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform cost-distance analysis on a raster.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import distance_transform_edt\n\ndef cost_distance_analysis(cost_raster, source_points):\n    cost_raster = np.where(cost_raster <= 0, 1e-10, cost_raster)\n    inverse_cost = 1.0 / cost_raster\n    distance_map = distance_transform_edt(inverse_cost, sampling=1)\n    output = np.zeros_like(distance_map)\n    for point in source_points:\n        output[point] = distance_map[point]\n    return output\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the eccentricity of polygon shapes.",
        "output": "```python\nfrom math import sqrt\nfrom shapely.geometry import Polygon\n\ndef calculate_eccentricity(polygon):\n    if not isinstance(polygon, Polygon):\n        raise ValueError(\"Input must be a Shapely Polygon.\")\n    \n    coords = list(polygon.exterior.coords)\n    n = len(coords) - 1  # Exclude the repeated last point\n    x_coords, y_coords = zip(*coords)\n    \n    x_mean = sum(x_coords) / n\n    y_mean = sum(y_coords) / n\n    \n    numerator = sum((x - x_mean)**2 + (y - y_mean)**2 for x, y in coords[:-1])\n    denominator = sum((x - x_mean) * (y - y_mean) for x, y in coords[:-1])\n    \n    if denominator == 0:\n        return 0.0\n    \n    eccentricity = sqrt(1 - (numerator / (2 * denominator**2)))\n    return eccentricity\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Identify disconnected components in a road network.",
        "output": "```python\nimport networkx as nx\n\ndef find_disconnected_components(graph):\n    if not nx.is_connected(graph):\n        components = list(nx.connected_components(graph))\n        return components\n    else:\n        return []\n\n# Example usage\nG = nx.Graph()\nG.add_edges_from([(1, 2), (2, 3), (4, 5)])\ndisconnected_components = find_disconnected_components(G)\nprint(disconnected_components)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial clustering using K-means.",
        "output": "```python\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\n# Example data: Replace with your spatial data\ncoordinates = np.array([[x1, y1], [x2, y2], [x3, y3], ...])\n\nkmeans = KMeans(n_clusters=5, random_state=42)\nlabels = kmeans.fit_predict(coordinates)\n\nprint(labels)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the longest side of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef get_longest_side(polygon):\n    coords = list(polygon.exterior.coords)\n    max_length = 0\n    longest_side = None\n    for i in range(len(coords) - 1):\n        p1, p2 = coords[i], coords[i + 1]\n        side_length = ((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2) ** 0.5\n        if side_length > max_length:\n            max_length = side_length\n            longest_side = (p1, p2)\n    return longest_side\n\n# Example usage\npolygon = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\nprint(get_longest_side(polygon))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Convert a GeoDataFrame to a GeoPackage file.",
        "output": "```python\nimport geopandas as gpd\n\ngdf.to_file(\"output.gpkg\", driver=\"GPKG\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the roundness index of polygons.",
        "output": "```python\nimport math\n\ndef calculate_roundness_index(area, perimeter):\n    return (4 * math.pi * area) / (perimeter ** 2)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform hotspot analysis using Getis-Ord Gi*.",
        "output": "```python\nimport arcpy\nfrom arcpy import env\nfrom arcpy.sa import *\n\nenv.workspace = \"path_to_your_workspace\"\n\ninput_feature_class = \"your_input_feature_class\"\noutput_feature_class = \"your_output_feature_class\"\nfield_to_analyze = \"your_analysis_field\"\ndistance_band = 1000  # Set your distance band here\n\narcpy.stats.HotSpots(input_feature_class, field_to_analyze, output_feature_class, \"GETIS_ORD_GEN\", \"EUCLIDEAN_DISTANCE\", \"NONE\", distance_band)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster footprint as a vector layer.",
        "output": "```python\nfrom osgeo import gdal, ogr\n\ndef raster_footprint_to_vector(raster_path, output_vector_path):\n    dataset = gdal.Open(raster_path)\n    geotransform = dataset.GetGeoTransform()\n    cols = dataset.RasterXSize\n    rows = dataset.RasterYSize\n\n    ring = ogr.Geometry(ogr.wkbLinearRing)\n    ring.AddPoint(geotransform[0], geotransform[3])\n    ring.AddPoint(geotransform[0] + geotransform[1] * cols, geotransform[3])\n    ring.AddPoint(geotransform[0] + geotransform[1] * cols, geotransform[3] + geotransform[5] * rows)\n    ring.AddPoint(geotransform[0], geotransform[3] + geotransform[5] * rows)\n    ring.CloseRings()\n\n    polygon = ogr.Geometry(ogr.wkbPolygon)\n    polygon.AddGeometry(ring)\n\n    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n    if driver.Exists(output_vector_path):\n        driver.DeleteDataSource(output_vector_path)\n    out_data_source = driver.CreateDataSource(output_vector_path)\n    spatial_ref = dataset.GetSpatialRef()\n    out_layer = out_data_source.CreateLayer(\"footprint\", spatial_ref, ogr.wkbPolygon)\n    feature_defn = out_layer.GetLayerDefn()\n    feature = ogr.Feature(feature_defn)\n    feature.SetGeometry(polygon)\n    out_layer.CreateFeature(feature)\n\n    feature = None\n    out_data_source = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the fractal dimension of a coastline.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\ndef fractal_dimension(coastline, box_sizes):\n    def box_count(points, size):\n        min_x, min_y = np.min(points, axis=0)\n        max_x, max_y = np.max(points, axis=0)\n        grid = {}\n        for point in points:\n            idx = (int((point[0] - min_x) // size), int((point[1] - min_y) // size))\n            grid[idx] = 1\n        return len(grid)\n\n    coastline = np.array(coastline)\n    counts = []\n    for size in box_sizes:\n        counts.append(box_count(coastline, size))\n\n    coeffs = np.polyfit(np.log(1 / np.array(box_sizes)), np.log(counts), 1)\n    return coeffs[0]\n\n# Example usage:\ncoastline = [(0, 0), (1, 2), (3, 4), (5, 6), (7, 8)]\nbox_sizes = [1.0, 0.5, 0.25, 0.125]\nfd = fractal_dimension(coastline, box_sizes)\nprint(\"Fractal Dimension:\", fd)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the intersection points of two LineStrings.",
        "output": "```python\nfrom shapely.geometry import LineString\n\ndef get_intersection_points(line1_coords, line2_coords):\n    line1 = LineString(line1_coords)\n    line2 = LineString(line2_coords)\n    intersection = line1.intersection(line2)\n    if intersection.is_empty:\n        return []\n    elif intersection.geom_type == 'Point':\n        return [(intersection.x, intersection.y)]\n    elif intersection.geom_type == 'MultiPoint':\n        return [(point.x, point.y) for point in intersection.geoms]\n    else:\n        return []\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial interpolation using spline methods.",
        "output": "```python\nimport numpy as np\nfrom scipy.interpolate import griddata\nimport matplotlib.pyplot as plt\n\n# Sample points and values\npoints = np.random.rand(100, 2)\nvalues = np.sin(points[:, 0] * 4) + np.cos(points[:, 1] * 4)\n\n# Grid for interpolation\ngrid_x, grid_y = np.mgrid[0:1:100j, 0:1:100j]\n\n# Perform spline interpolation\ngrid_z = griddata(points, values, (grid_x, grid_y), method='cubic')\n\n# Plot the result\nplt.imshow(grid_z.T, extent=(0, 1, 0, 1), origin='lower', cmap='viridis')\nplt.scatter(points[:, 0], points[:, 1], c=values, edgecolor='k', cmap='viridis')\nplt.colorbar()\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the orientation of polygon shapes.",
        "output": "```python\nfrom math import atan2, degrees\n\ndef calculate_polygon_orientation(vertices):\n    if len(vertices) < 3:\n        raise ValueError(\"A polygon must have at least 3 vertices.\")\n    \n    total_angle = 0\n    n = len(vertices)\n    \n    for i in range(n):\n        x1, y1 = vertices[i]\n        x2, y2 = vertices[(i + 1) % n]\n        angle = atan2(y2 - y1, x2 - x1)\n        total_angle += angle\n    \n    orientation = \"Clockwise\" if total_angle < 0 else \"Counter-Clockwise\"\n    return orientation\n\n# Example usage\nvertices = [(0, 0), (4, 0), (4, 3), (0, 3)]\nprint(calculate_polygon_orientation(vertices))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial autocorrelation using Geary’s C.",
        "output": "```python\nimport numpy as np\nfrom libpysal.weights import Queen\nfrom esda.geary import Geary\n\n# Example data: spatial data points and attribute values\npoints = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\nattribute_values = np.array([10, 20, 30, 40])\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_array(points)\nw.transform = 'R'  # Row-standardize the weights\n\n# Calculate Geary's C statistic\ngeary_c = Geary(attribute_values, w)\nprint(geary_c.C)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform network analysis to find shortest paths.",
        "output": "```python\nimport networkx as nx\n\n# Create a graph\nG = nx.Graph()\n\n# Add edges with weights\nG.add_edge('A', 'B', weight=4)\nG.add_edge('A', 'C', weight=2)\nG.add_edge('B', 'C', weight=5)\nG.add_edge('B', 'D', weight=10)\nG.add_edge('C', 'D', weight=3)\n\n# Find the shortest path\nshortest_path = nx.dijkstra_path(G, source='A', target='D')\n\nprint(shortest_path)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the straightness centrality of a network.",
        "output": "```python\nimport networkx as nx\n\ndef calculate_straightness_centrality(graph, weight=None):\n    nodes = list(graph.nodes)\n    straightness = {node: 0.0 for node in nodes}\n    shortest_paths = dict(nx.all_pairs_dijkstra_path_length(graph, weight=weight))\n\n    for i, u in enumerate(nodes):\n        total_distance = 0.0\n        euclidean_total = 0.0\n        for j, v in enumerate(nodes):\n            if i != j:\n                shortest_path_dist = shortest_paths[u][v]\n                euclidean_dist = ((graph.nodes[u]['pos'][0] - graph.nodes[v]['pos'][0])**2 +\n                                  (graph.nodes[u]['pos'][1] - graph.nodes[v]['pos'][1])**2)**0.5\n                if shortest_path_dist > 0:\n                    total_distance += euclidean_dist / shortest_path_dist\n                euclidean_total += 1\n        if euclidean_total > 0:\n            straightness[u] = total_distance / euclidean_total\n\n    return straightness\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex vertices of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef extract_convex_vertices(polygon):\n    coords = list(polygon.exterior.coords)\n    convex_vertices = []\n    for i in range(len(coords) - 1):\n        p1, p2, p3 = coords[i - 1], coords[i], coords[i + 1]\n        cross_product = (p2[0] - p1[0]) * (p3[1] - p2[1]) - (p2[1] - p1[1]) * (p3[0] - p2[0])\n        if cross_product >= 0:\n            convex_vertices.append(p2)\n    return convex_vertices\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 4), (2, 6), (0, 4)])\nconvex_vertices = extract_convex_vertices(polygon)\nprint(convex_vertices)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial partitioning using quadtree indexing.",
        "output": "```python\nfrom rtree import index\n\ndef create_quadtree_index(geometries):\n    idx = index.Index()\n    for i, geom in enumerate(geometries):\n        idx.insert(i, geom.bounds)\n    return idx\n\n# Example usage:\nif __name__ == \"__main__\":\n    from shapely.geometry import box\n\n    geometries = [box(i, i, i + 1, i + 1) for i in range(10)]\n    quadtree_index = create_quadtree_index(geometries)\n\n    query_geom = box(2, 2, 4, 4)\n    intersected_ids = list(quadtree_index.intersection(query_geom.bounds))\n    print(intersected_ids)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the skewness of a spatial distribution.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import skew\n\ndef calculate_skewness(data):\n    return skew(data)\n\n# Example usage\nspatial_data = np.random.normal(loc=0, scale=1, size=100)\nskewness = calculate_skewness(spatial_data)\nprint(skewness)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster hillshade from a DEM.",
        "output": "```python\nfrom osgeo import gdal\nimport numpy as np\n\ndef generate_hillshade(dem_path, output_path, azimuth=315, altitude=45, z_factor=1.0):\n    dem_dataset = gdal.Open(dem_path)\n    band = dem_dataset.GetRasterBand(1)\n    dem_array = band.ReadAsArray()\n    geotransform = dem_dataset.GetGeoTransform()\n    projection = dem_dataset.GetProjection()\n\n    cell_size_x = geotransform[1]\n    cell_size_y = -geotransform[5]\n\n    slope, aspect = gdal.DEMProcessingOptions().ComputeSlopeAspect(band, z_factor=z_factor)\n\n    azimuth_rad = np.deg2rad(360 - azimuth + 90)\n    altitude_rad = np.deg2rad(altitude)\n\n    shaded = np.sin(altitude_rad) * np.cos(slope) + \\\n             np.cos(altitude_rad) * np.sin(slope) * np.cos(azimuth_rad - aspect)\n\n    shaded = 255 * (shaded + 1) / 2\n    shaded = np.clip(shaded, 0, 255).astype(np.uint8)\n\n    driver = gdal.GetDriverByName('GTiff')\n    out_dataset = driver.Create(output_path, dem_dataset.RasterXSize, dem_dataset.RasterYSize, 1, gdal.GDT_Byte)\n    out_dataset.SetGeoTransform(geotransform)\n    out_dataset.SetProjection(projection)\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(shaded)\n    out_band.FlushCache()\n\ngenerate_hillshade(\"input_dem.tif\", \"output_hillshade.tif\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial trend analysis on point data.",
        "output": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import linregress\n\ndef spatial_trend_analysis(points, values):\n    x = [p[0] for p in points]\n    y = [p[1] for p in points]\n    z = values\n\n    slope_x, intercept_x, _, _, _ = linregress(x, z)\n    slope_y, intercept_y, _, _, _ = linregress(y, z)\n\n    trend_surface = [\n        slope_x * xi + slope_y * yi + (intercept_x + intercept_y) / 2\n        for xi, yi in zip(x, y)\n    ]\n\n    fig, ax = plt.subplots()\n    sc = ax.scatter(x, y, c=z, cmap='viridis', label='Observed Data')\n    ax.scatter(x, y, c=trend_surface, cmap='plasma', marker='x', label='Trend Surface')\n    plt.colorbar(sc, label='Values')\n    plt.xlabel('X Coordinate')\n    plt.ylabel('Y Coordinate')\n    plt.legend()\n    plt.show()\n\n# Example usage:\npoints = [(1, 2), (2, 3), (3, 4), (4, 5)]\nvalues = [10, 15, 20, 25]\nspatial_trend_analysis(points, values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the elongation ratio of polygons.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\nimport numpy as np\n\ndef calculate_elongation_ratio(polygon):\n    coords = np.array(polygon.exterior.coords)\n    covariance_matrix = np.cov(coords[:, 0], coords[:, 1])\n    eigenvalues, _ = np.linalg.eigh(covariance_matrix)\n    eigenvalues = np.sort(eigenvalues)[::-1]\n    elongation_ratio = eigenvalues[1] / eigenvalues[0]\n    return elongation_ratio\n\ngdf = gpd.read_file(\"path_to_your_shapefile.shp\")\ngdf['elongation_ratio'] = gdf.geometry.apply(calculate_elongation_ratio)\nprint(gdf[['geometry', 'elongation_ratio']])\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the parallel segments of two LineStrings.",
        "output": "```python\nfrom shapely.geometry import LineString\nfrom shapely.ops import split\n\ndef extract_parallel_segments(line1, line2, tolerance=1e-6):\n    segments1 = [LineString([line1.coords[i], line1.coords[i+1]]) for i in range(len(line1.coords)-1)]\n    segments2 = [LineString([line2.coords[i], line2.coords[i+1]]) for i in range(len(line2.coords)-1)]\n    \n    parallel_segments = []\n    for seg1 in segments1:\n        for seg2 in segments2:\n            if seg1.length == 0 or seg2.length == 0:\n                continue\n            v1 = (seg1.coords[1][0] - seg1.coords[0][0], seg1.coords[1][1] - seg1.coords[0][1])\n            v2 = (seg2.coords[1][0] - seg2.coords[0][0], seg2.coords[1][1] - seg2.coords[0][1])\n            cross_product = v1[0] * v2[1] - v1[1] * v2[0]\n            if abs(cross_product) < tolerance:\n                parallel_segments.append((seg1, seg2))\n    return parallel_segments\n\n# Example usage\nline1 = LineString([(0, 0), (1, 1), (2, 2)])\nline2 = LineString([(0, 1), (1, 2), (2, 3)])\nparallel_segments = extract_parallel_segments(line1, line2)\nprint(parallel_segments)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial smoothing of point densities.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter\nfrom scipy.spatial import cKDTree\n\ndef spatial_smoothing(points, grid_size, smoothing_sigma):\n    x_min, y_min = points.min(axis=0)\n    x_max, y_max = points.max(axis=0)\n    grid_x, grid_y = np.mgrid[x_min:x_max:grid_size, y_min:y_max:grid_size]\n    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n\n    tree = cKDTree(points)\n    _, indices = tree.query(grid_points, k=1)\n    density = np.bincount(indices, minlength=len(points)) / (grid_size ** 2)\n\n    density_grid = density.reshape(grid_x.shape)\n    smoothed_density = gaussian_filter(density_grid, sigma=smoothing_sigma)\n    return grid_x, grid_y, smoothed_density\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the aspect ratio of polygon shapes.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef calculate_aspect_ratio(polygon):\n    bounds = polygon.bounds\n    width = bounds[2] - bounds[0]\n    height = bounds[3] - bounds[1]\n    return width / height if height != 0 else float('inf')\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 2), (0, 2)])\naspect_ratio = calculate_aspect_ratio(polygon)\nprint(aspect_ratio)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial heterogeneity using LISA clusters.",
        "output": "```python\nimport geopandas as gpd\nimport libpysal\nfrom esda.moran import Moran_Local\nfrom pysal.viz.splot.esda import lisa_cluster\n\n# Load your GeoDataFrame (replace 'your_data.shp' with your file path)\ngdf = gpd.read_file('your_data.shp')\n\n# Ensure the GeoDataFrame has a valid CRS and is in projected coordinates\ngdf = gdf.to_crs(epsg=3857)\n\n# Extract the variable of interest (replace 'your_column' with your target column)\nvalues = gdf['your_column']\n\n# Create a spatial weights matrix (Queen contiguity by default)\nw = libpysal.weights.Queen.from_dataframe(gdf)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis\nlocal_moran = Moran_Local(values, w)\n\n# Add LISA cluster results to the GeoDataFrame\ngdf['lisa_cluster'] = local_moran.q\ngdf['lisa_significance'] = local_moran.p_sim\n\n# Plot LISA clusters\nlisa_cluster(local_moran, gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial prediction using kriging.",
        "output": "```python\nfrom pykrige.ok import OrdinaryKriging\nimport numpy as np\n\ndata = np.array([[0.3, 1.2, 0.47],\n                 [1.9, 0.6, 0.56],\n                 [1.1, 3.2, 0.74],\n                 [3.3, 4.4, 1.47],\n                 [4.7, 3.8, 1.74]])\n\ngrid_x = np.linspace(0, 5, 50)\ngrid_y = np.linspace(0, 5, 50)\n\nOK = OrdinaryKriging(data[:, 0], data[:, 1], data[:, 2], variogram_model=\"linear\")\nz, ss = OK.execute(\"grid\", grid_x, grid_y)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster slope map from elevation data.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nfrom scipy.ndimage import sobel\n\n# Load elevation data\nwith rasterio.open('elevation.tif') as src:\n    elevation = src.read(1)\n    profile = src.profile\n\n# Calculate slope using Sobel filter\ndx = sobel(elevation, axis=1)\ndy = sobel(elevation, axis=0)\nslope = np.arctan(np.sqrt(dx**2 + dy**2))\n\n# Update metadata for the output file\nprofile.update(dtype=rasterio.float32, count=1)\n\n# Save the slope raster\nwith rasterio.open('slope.tif', 'w', **profile) as dst:\n    dst.write(slope.astype(rasterio.float32), 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the sinuosity index of rivers.",
        "output": "```python\nimport math\n\ndef calculate_sinuosity_index(river_length, straight_line_distance):\n    return river_length / straight_line_distance\n\nriver_length = 120.5\nstraight_line_distance = 80.0\nsinuosity_index = calculate_sinuosity_index(river_length, straight_line_distance)\nprint(sinuosity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the perpendicular bisector of a LineString.",
        "output": "```python\nfrom shapely.geometry import LineString, Point\nfrom shapely.ops import split\n\ndef perpendicular_bisector(line):\n    midpoint = line.interpolate(0.5, normalized=True)\n    start, end = line.boundary.geoms\n    slope = (end.y - start.y) / (end.x - start.x)\n    perp_slope = -1 / slope\n    perp_line = LineString([midpoint, Point(midpoint.x + 1, midpoint.y + perp_slope)])\n    return perp_line\n\n# Example usage\nline = LineString([(0, 0), (4, 4)])\nbisector = perpendicular_bisector(line)\nprint(bisector)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial aggregation using hexagonal grids.",
        "output": "```python\nimport geopandas as gpd\nimport h3\nfrom shapely.geometry import Polygon\n\ndef generate_hexagons(geometry, resolution):\n    hexagons = h3.polyfill(geometry.__geo_interface__, resolution, geo_json_conformant=True)\n    return [Polygon(h3.h3_to_geo_boundary(h, geo_json=True)) for h in hexagons]\n\ndef spatial_aggregation_hexagonal(input_gdf, resolution, agg_column):\n    all_hexagons = []\n    for geom in input_gdf.geometry:\n        all_hexagons.extend(generate_hexagons(geom, resolution))\n    \n    hex_grid = gpd.GeoDataFrame(geometry=all_hexagons, crs=input_gdf.crs)\n    joined = gpd.sjoin(input_gdf, hex_grid, how=\"inner\", predicate=\"intersects\")\n    aggregated = joined.groupby(joined.index_right)[agg_column].sum().reset_index()\n    hex_grid_aggregated = hex_grid.merge(aggregated, left_index=True, right_on=\"index_right\", how=\"left\")\n    return hex_grid_aggregated\n\n# Example usage:\n# input_gdf = gpd.read_file(\"path_to_your_shapefile.shp\")\n# result = spatial_aggregation_hexagonal(input_gdf, resolution=9, agg_column=\"your_column_name\")\n# result.to_file(\"output_hexagons.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the rectangularity of polygon shapes.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef calculate_rectangularity(polygon):\n    area = polygon.area\n    min_x, min_y, max_x, max_y = polygon.bounds\n    bounding_box_area = (max_x - min_x) * (max_y - min_y)\n    rectangularity = area / bounding_box_area if bounding_box_area != 0 else 0\n    return rectangularity\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 3), (0, 3)])\nprint(calculate_rectangularity(polygon))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial colocation patterns in point data.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom sklearn.cluster import DBSCAN\n\ndef detect_spatial_colocation(points, distance_threshold, min_samples):\n    dist_matrix = distance_matrix(points, points)\n    dbscan = DBSCAN(eps=distance_threshold, min_samples=min_samples, metric='precomputed')\n    labels = dbscan.fit_predict(dist_matrix)\n    return labels\n\n# Example usage\npoints = np.array([[1, 2], [2, 3], [10, 11], [11, 12], [20, 21], [21, 22]])\ndistance_threshold = 2.5\nmin_samples = 2\nlabels = detect_spatial_colocation(points, distance_threshold, min_samples)\nprint(labels)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial overlay using erase operation.",
        "output": "```python\nimport geopandas as gpd\n\n# Load the input GeoDataFrames\ninput_gdf = gpd.read_file(\"input_shapefile.shp\")\nerase_gdf = gpd.read_file(\"erase_shapefile.shp\")\n\n# Perform the erase operation\nresult_gdf = gpd.overlay(input_gdf, erase_gdf, how='difference')\n\n# Save the result to a new shapefile\nresult_gdf.to_file(\"output_erased.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the circular variance of point directions.",
        "output": "```python\nimport numpy as np\n\ndef circular_variance(directions):\n    directions = np.radians(directions)\n    x_components = np.cos(directions)\n    y_components = np.sin(directions)\n    mean_x = np.mean(x_components)\n    mean_y = np.mean(y_components)\n    mean_vector_length = np.sqrt(mean_x**2 + mean_y**2)\n    return 1 - mean_vector_length\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster curvature map from a DEM.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom scipy.ndimage import gaussian_filter\n\ndef calculate_curvature(dem_path, output_path):\n    # Open the DEM file\n    dataset = gdal.Open(dem_path)\n    band = dataset.GetRasterBand(1)\n    dem = band.ReadAsArray().astype(float)\n\n    # Replace NoData values with NaN\n    nodata = band.GetNoDataValue()\n    if nodata is not None:\n        dem[dem == nodata] = np.nan\n\n    # Compute gradients\n    dzdx, dzdy = np.gradient(dem)\n\n    # Smooth the gradients to reduce noise\n    dzdx_smooth = gaussian_filter(dzdx, sigma=1)\n    dzdy_smooth = gaussian_filter(dzdy, sigma=1)\n\n    # Compute second derivatives\n    d2zdx2, _ = np.gradient(dzdx_smooth)\n    _, d2zdy2 = np.gradient(dzdy_smooth)\n    d2zdxdy, _ = np.gradient(dzdx_smooth)\n\n    # Calculate curvature\n    curvature = (d2zdx2 + d2zdy2) / 2\n\n    # Create output raster\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Float32)\n    out_dataset.SetGeoTransform(dataset.GetGeoTransform())\n    out_dataset.SetProjection(dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(curvature)\n    out_band.SetNoDataValue(np.nan)\n    out_band.FlushCache()\n\n    # Clean up\n    dataset = None\n    out_dataset = None\n\n# Example usage\ndem_path = \"path_to_your_dem.tif\"\noutput_path = \"path_to_output_curvature.tif\"\ncalculate_curvature(dem_path, output_path)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial feature selection using filters.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Separate features and target variable\nX = data.drop(columns=[\"target_column\"])\ny = data[\"target_column\"]\n\n# Ensure all features are numeric\nX = X.select_dtypes(include=['number'])\n\n# Apply feature selection using ANOVA F-test\nselector = SelectKBest(score_func=f_classif, k=5)\nX_selected = selector.fit_transform(X, y)\n\n# Get selected feature names\nselected_features = X.columns[selector.get_support()]\nprint(selected_features)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the solidity of polygon shapes.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef calculate_solidity(polygon, convex_hull=None):\n    if not isinstance(polygon, Polygon):\n        raise ValueError(\"Input must be a Shapely Polygon.\")\n    convex_hull = polygon.convex_hull if convex_hull is None else convex_hull\n    return polygon.area / convex_hull.area\n\n# Example usage:\npolygon = Polygon([(0, 0), (4, 0), (4, 4), (2, 2), (0, 4)])\nsolidity = calculate_solidity(polygon)\nprint(solidity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the medial axis of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom skimage import measure\nimport numpy as np\n\ndef extract_medial_axis(polygon, resolution=100):\n    min_x, min_y, max_x, max_y = polygon.bounds\n    x = np.linspace(min_x, max_x, resolution)\n    y = np.linspace(min_y, max_y, resolution)\n    xv, yv = np.meshgrid(x, y)\n    grid = np.zeros((resolution, resolution), dtype=bool)\n\n    for i in range(resolution):\n        for j in range(resolution):\n            point = (xv[i, j], yv[i, j])\n            if polygon.contains(Point(point)):\n                grid[i, j] = True\n\n    skeleton = measure.skeletonize(grid)\n    return skeleton, x, y\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 3), (0, 3)])\nskeleton, x, y = extract_medial_axis(polygon)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial regression analysis on point data.",
        "output": "```python\nimport geopandas as gpd\nimport libpysal\nfrom mgwr.gwr import GWR\nfrom mgwr.sel_bw import Sel_BW\n\n# Load point data\npoint_data = gpd.read_file('points.shp')\n\n# Prepare dependent and independent variables\ny = point_data['dependent_var'].values.reshape(-1, 1)\nX = point_data[['independent_var1', 'independent_var2']].values\n\n# Create spatial weights matrix\ncoords = list(zip(point_data.geometry.x, point_data.geometry.y))\nw = libpysal.weights.KNN(coords, k=5)\n\n# Bandwidth selection\nbw_selector = Sel_BW(coords, y, X, w)\nbw = bw_selector.search()\n\n# Perform Geographically Weighted Regression (GWR)\ngwr_model = GWR(coords, y, X, bw)\ngwr_results = gwr_model.fit()\n\n# Output results\nprint(gwr_results.summary())\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the dispersion index of point patterns.",
        "output": "```python\nimport numpy as np\n\ndef calculate_dispersion_index(points):\n    n = len(points)\n    if n < 2:\n        return 0.0\n    \n    distances = []\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.sqrt((points[i][0] - points[j][0])**2 + (points[i][1] - points[j][1])**2)\n            distances.append(dist)\n    \n    mean_distance = np.mean(distances)\n    variance_distance = np.var(distances)\n    \n    if mean_distance == 0:\n        return 0.0\n    \n    dispersion_index = variance_distance / mean_distance\n    return dispersion_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster flow accumulation map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\ndef flow_accumulation(dem_path, output_path):\n    dem_dataset = gdal.Open(dem_path)\n    dem_band = dem_dataset.GetRasterBand(1)\n    dem_array = dem_band.ReadAsArray()\n    rows, cols = dem_array.shape\n    flow_acc = np.zeros_like(dem_array, dtype=np.float32)\n\n    def calculate_flow(r, c):\n        if r < 0 or r >= rows or c < 0 or c >= cols:\n            return 0\n        min_val = dem_array[r, c]\n        min_r, min_c = r, c\n        for dr in [-1, 0, 1]:\n            for dc in [-1, 0, 1]:\n                if dr == 0 and dc == 0:\n                    continue\n                nr, nc = r + dr, c + dc\n                if 0 <= nr < rows and 0 <= nc < cols:\n                    if dem_array[nr, nc] < min_val:\n                        min_val = dem_array[nr, nc]\n                        min_r, min_c = nr, nc\n        if min_r == r and min_c == c:\n            return 1\n        return 1 + calculate_flow(min_r, min_c)\n\n    for row in range(rows):\n        for col in range(cols):\n            flow_acc[row, col] = calculate_flow(row, col)\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_path, cols, rows, 1, gdal.GDT_Float32)\n    out_dataset.SetGeoTransform(dem_dataset.GetGeoTransform())\n    out_dataset.SetProjection(dem_dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(flow_acc)\n    out_band.FlushCache()\n    out_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial anomaly detection using residuals.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom sklearn.linear_model import LinearRegression\n\ndef calculate_residuals(X, y):\n    model = LinearRegression()\n    model.fit(X, y)\n    predictions = model.predict(X)\n    residuals = y - predictions\n    return residuals\n\ndef spatial_anomaly_detection(coords, residuals, threshold=2.0):\n    distances = cdist(coords, coords)\n    weights = np.exp(-distances / np.mean(distances))\n    weighted_residuals = weights.dot(residuals)\n    mean_residual = np.mean(weighted_residuals)\n    std_residual = np.std(weighted_residuals)\n    z_scores = (weighted_residuals - mean_residual) / std_residual\n    anomalies = np.where(np.abs(z_scores) > threshold)[0]\n    return anomalies\n\n# Example usage\ncoords = np.random.rand(100, 2)  # Spatial coordinates\nX = np.random.rand(100, 3)       # Independent variables\ny = np.random.rand(100)          # Dependent variable\n\nresiduals = calculate_residuals(X, y)\nanomalies = spatial_anomaly_detection(coords, residuals)\nprint(\"Anomalies detected at indices:\", anomalies)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the connectivity index of a network.",
        "output": "```python\nimport networkx as nx\n\ndef calculate_connectivity_index(graph):\n    if not graph.is_directed():\n        return nx.algebraic_connectivity(graph)\n    else:\n        return nx.directed_laplacian_matrix(graph).min()\n\n# Example usage\nG = nx.Graph()\nG.add_edges_from([(1, 2), (2, 3), (3, 1)])\nconnectivity_index = calculate_connectivity_index(G)\nprint(connectivity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the buffer zone around a LineString.",
        "output": "```python\nfrom shapely.geometry import LineString\nfrom shapely.ops import transform\nfrom pyproj import Transformer\n\ndef create_buffer_around_linestring(linestring, distance, crs_from, crs_to):\n    transformer = Transformer.from_crs(crs_from, crs_to, always_xy=True)\n    linestring_transformed = transform(transformer.transform, linestring)\n    buffer_zone = linestring_transformed.buffer(distance)\n    return transform(transformer.transform, buffer_zone)\n\n# Example usage\nline = LineString([(0, 0), (1, 1), (2, 1)])\nbuffer_distance = 0.1\nbuffer_result = create_buffer_around_linestring(line, buffer_distance, \"EPSG:4326\", \"EPSG:3857\")\nprint(buffer_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial clustering using OPTICS.",
        "output": "```python\nfrom sklearn.cluster import OPTICS\nimport geopandas as gpd\n\n# Load spatial data\ngdf = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Extract coordinates\ncoords = gdf.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n\n# Perform OPTICS clustering\noptics = OPTICS(min_samples=5, xi=0.05, min_cluster_size=0.05)\nlabels = optics.fit_predict(coords)\n\n# Add cluster labels to GeoDataFrame\ngdf['cluster'] = labels\n\n# Save the result to a new shapefile\ngdf.to_file(\"path_to_output_shapefile.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the isoperimetric quotient of polygons.",
        "output": "```python\nimport math\n\ndef calculate_isoperimetric_quotient(area, perimeter):\n    return (4 * math.pi * area) / (perimeter ** 2)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial outliers using robust methods.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.neighbors import LocalOutlierFactor\n\ndef detect_spatial_outliers_robust(coords, n_neighbors=20, contamination=0.1):\n    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n    outlier_labels = lof.fit_predict(coords)\n    return np.where(outlier_labels == -1)[0]\n\n# Example usage\ncoordinates = np.random.rand(100, 2)  # Replace with actual spatial coordinates\noutlier_indices = detect_spatial_outliers_robust(coordinates)\nprint(\"Outlier indices:\", outlier_indices)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial matching of point datasets.",
        "output": "```python\nimport geopandas as gpd\n\n# Load point datasets\npoints1 = gpd.read_file(\"points1.shp\")\npoints2 = gpd.read_file(\"points2.shp\")\n\n# Ensure both datasets are in the same CRS\npoints2 = points2.to_crs(points1.crs)\n\n# Perform spatial join\nspatial_join = gpd.sjoin(points1, points2, how=\"inner\", predicate=\"intersects\")\n\n# Save the result to a new shapefile\nspatial_join.to_file(\"spatial_match_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the radial distribution function.",
        "output": "```python\nimport numpy as np\n\ndef radial_distribution_function(coords, box_length, num_bins):\n    distances = []\n    n_particles = len(coords)\n    \n    for i in range(n_particles):\n        for j in range(i + 1, n_particles):\n            diff = coords[i] - coords[j]\n            diff = diff - np.round(diff / box_length) * box_length\n            dist = np.linalg.norm(diff)\n            distances.append(dist)\n    \n    max_distance = box_length / 2\n    bins = np.linspace(0, max_distance, num_bins + 1)\n    hist, _ = np.histogram(distances, bins=bins)\n    \n    bin_centers = (bins[:-1] + bins[1:]) / 2\n    density = n_particles / (box_length ** 3)\n    rdf = hist / (4 * np.pi * bin_centers**2 * (bins[1] - bins[0]) * density * n_particles)\n    \n    return bin_centers, rdf\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster viewshed from a DEM.",
        "output": "```python\nimport rasterio\nfrom rasterio.features import rasterize\nfrom rasterio.transform import from_origin\nimport numpy as np\nfrom scipy.ndimage import distance_transform_edt\n\ndef generate_viewshed(dem_path, observer_x, observer_y, observer_height, target_height, output_path):\n    with rasterio.open(dem_path) as src:\n        dem = src.read(1)\n        transform = src.transform\n        meta = src.meta\n\n    rows, cols = dem.shape\n    x_coords, y_coords = np.meshgrid(np.arange(cols), np.arange(rows))\n    x_coords, y_coords = rasterio.transform.xy(transform, y_coords, x_coords)\n\n    observer_row, observer_col = rasterio.transform.rowcol(transform, observer_x, observer_y)\n    observer_elevation = dem[observer_row, observer_col] + observer_height\n\n    distance = np.sqrt((x_coords - observer_x)**2 + (y_coords - observer_y)**2)\n    angle = np.degrees(np.arctan2(dem + target_height - observer_elevation, distance))\n\n    visible = angle >= np.max(angle)\n\n    meta.update(dtype=rasterio.uint8, count=1, compress='lzw')\n    with rasterio.open(output_path, 'w', **meta) as dst:\n        dst.write(visible.astype(rasterio.uint8), 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial optimization using simulated annealing.",
        "output": "```python\nimport random\nimport math\n\ndef objective_function(solution):\n    return sum(solution)\n\ndef neighbor(solution):\n    index = random.randint(0, len(solution) - 1)\n    solution[index] = random.uniform(-10, 10)\n    return solution\n\ndef simulated_annealing(initial_solution, temp, cooling_rate, min_temp, max_iter):\n    current_solution = initial_solution[:]\n    current_energy = objective_function(current_solution)\n    best_solution = current_solution[:]\n    best_energy = current_energy\n\n    while temp > min_temp:\n        for i in range(max_iter):\n            new_solution = neighbor(current_solution[:])\n            new_energy = objective_function(new_solution)\n            energy_delta = new_energy - current_energy\n\n            if energy_delta < 0 or random.random() < math.exp(-energy_delta / temp):\n                current_solution = new_solution[:]\n                current_energy = new_energy\n\n                if current_energy < best_energy:\n                    best_solution = current_solution[:]\n                    best_energy = current_energy\n\n        temp *= cooling_rate\n\n    return best_solution, best_energy\n\ninitial_solution = [random.uniform(-10, 10) for _ in range(5)]\ntemp = 1000\ncooling_rate = 0.95\nmin_temp = 1\nmax_iter = 100\n\nbest_solution, best_energy = simulated_annealing(initial_solution, temp, cooling_rate, min_temp, max_iter)\nprint(\"Best Solution:\", best_solution)\nprint(\"Best Energy:\", best_energy)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the angular deviation of point orientations.",
        "output": "```python\nimport numpy as np\n\ndef calculate_angular_deviation(orientations):\n    mean_orientation = np.arctan2(np.mean(np.sin(orientations)), np.mean(np.cos(orientations)))\n    deviations = np.abs(np.mod(orientations - mean_orientation + np.pi, 2 * np.pi) - np.pi)\n    angular_deviation = np.mean(deviations)\n    return angular_deviation\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex decomposition of a polygon.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import triangulate\n\ndef convex_decomposition(polygon):\n    triangles = triangulate(polygon)\n    return triangles\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 4), (0, 4)])\nconvex_parts = convex_decomposition(polygon)\nprint(convex_parts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial segmentation using region growing.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import label\n\ndef region_growing(image, seed, threshold):\n    segmented = np.zeros_like(image, dtype=bool)\n    value = image[seed]\n    stack = [seed]\n\n    while stack:\n        x, y = stack.pop()\n        if not segmented[x, y] and abs(image[x, y] - value) <= threshold:\n            segmented[x, y] = True\n            neighbors = [(x-1, y), (x+1, y), (x, y-1), (x, y+1)]\n            for nx, ny in neighbors:\n                if 0 <= nx < image.shape[0] and 0 <= ny < image.shape[1]:\n                    stack.append((nx, ny))\n                    \n    return segmented\n\n# Example usage\nimage = np.random.rand(100, 100)\nseed_point = (50, 50)\nthreshold_value = 0.1\nsegmented_image = region_growing(image, seed_point, threshold_value)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial entropy of point patterns.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom math import log\n\ndef spatial_entropy(points, num_bins=10):\n    dist_matrix = distance_matrix(points, points)\n    upper_triangle = dist_matrix[np.triu_indices_from(dist_matrix, k=1)]\n    hist, _ = np.histogram(upper_triangle, bins=num_bins)\n    probabilities = hist / np.sum(hist)\n    probabilities = probabilities[probabilities > 0]\n    entropy = -np.sum(probabilities * np.log(probabilities))\n    return entropy\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster drainage network map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom scipy.ndimage import label\n\ndef generate_drainage_network(dem_path, output_path, threshold=100):\n    dem_dataset = gdal.Open(dem_path)\n    dem_array = dem_dataset.ReadAsArray()\n    geotransform = dem_dataset.GetGeoTransform()\n    projection = dem_dataset.GetProjection()\n\n    flow_direction = np.zeros_like(dem_array, dtype=np.int32)\n    rows, cols = dem_array.shape\n\n    def calculate_flow_direction(r, c):\n        neighbors = [\n            (r - 1, c), (r - 1, c + 1), (r, c + 1), (r + 1, c + 1),\n            (r + 1, c), (r + 1, c - 1), (r, c - 1), (r - 1, c - 1)\n        ]\n        min_value = dem_array[r, c]\n        direction = 0\n        for idx, (nr, nc) in enumerate(neighbors):\n            if 0 <= nr < rows and 0 <= nc < cols:\n                if dem_array[nr, nc] < min_value:\n                    min_value = dem_array[nr, nc]\n                    direction = idx + 1\n        return direction\n\n    for r in range(rows):\n        for c in range(cols):\n            flow_direction[r, c] = calculate_flow_direction(r, c)\n\n    labeled_array, num_features = label(flow_direction > 0)\n    drainage_network = np.where(np.bincount(labeled_array.ravel())[labeled_array] > threshold, 1, 0)\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    output_dataset = driver.Create(output_path, cols, rows, 1, gdal.GDT_Byte)\n    output_dataset.SetGeoTransform(geotransform)\n    output_dataset.SetProjection(projection)\n    output_band = output_dataset.GetRasterBand(1)\n    output_band.WriteArray(drainage_network)\n    output_band.FlushCache()\n    output_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial decision-making using AHP.",
        "output": "```python\nimport numpy as np\n\n# Define the pairwise comparison matrix\ncriteria = np.array([\n    [1, 3, 5],\n    [1/3, 1, 2],\n    [1/5, 1/2, 1]\n])\n\n# Calculate the normalized matrix\nnormalized_matrix = criteria / criteria.sum(axis=0)\n\n# Calculate the priority vector (weights)\nweights = normalized_matrix.mean(axis=1)\n\n# Consistency Index (CI) and Random Consistency Index (RI)\nn = criteria.shape[0]\neigenvalues, _ = np.linalg.eig(criteria)\nmax_eigenvalue = np.max(eigenvalues)\nCI = (max_eigenvalue - n) / (n - 1)\nRI_values = {3: 0.58, 4: 0.9, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}\nRI = RI_values.get(n, 0)\n\n# Consistency Ratio (CR)\nCR = CI / RI if RI != 0 else 0\n\n# Output results\nif CR < 0.1:\n    print(\"Weights:\", weights)\nelse:\n    print(\"Inconsistent matrix. CR:\", CR)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the geometric median of a point set.",
        "output": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef geometric_median(points, tol=1e-6):\n    points = np.array(points)\n    median_guess = np.mean(points, axis=0)\n\n    def objective(x):\n        return np.sum(np.linalg.norm(points - x, axis=1))\n\n    result = minimize(objective, median_guess, method='BFGS', tol=tol)\n    return result.x\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the contour lines from a TIN model.",
        "output": "```python\nimport arcpy\n\ntin_path = \"path_to_your_tin\"\noutput_contours = \"path_to_output_contours\"\ncontour_interval = 10\nbase_contour = 0\n\narcpy.SurfaceContour_3d(tin_path, output_contours, contour_interval, base_contour)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial association rule mining.",
        "output": "```python\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\n\n# Load spatial data (example: CSV with spatial attributes)\ndata = pd.read_csv('spatial_data.csv')\n\n# Convert the data into a one-hot encoded format\none_hot_data = pd.get_dummies(data)\n\n# Apply Apriori algorithm to find frequent itemsets\nfrequent_itemsets = apriori(one_hot_data, min_support=0.1, use_colnames=True)\n\n# Generate association rules\nrules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n\n# Filter rules based on spatial constraints if needed\nfiltered_rules = rules[rules['lift'] > 1.0]\n\nprint(filtered_rules)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial Gini coefficient.",
        "output": "```python\nimport numpy as np\n\ndef spatial_gini(matrix):\n    n = matrix.shape[0]\n    total = np.sum(matrix)\n    if total == 0:\n        return 0\n    gini = 0\n    for i in range(n):\n        for j in range(n):\n            gini += np.abs(matrix[i] - matrix[j])\n    return gini / (2 * n**2 * np.mean(matrix))\n\n# Example usage\ndata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(spatial_gini(data))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial discontinuities in raster data.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import sobel\n\ndef detect_spatial_discontinuities(raster_data):\n    dx = sobel(raster_data, axis=1)\n    dy = sobel(raster_data, axis=0)\n    magnitude = np.hypot(dx, dy)\n    return magnitude\n\n# Example usage\nraster = np.random.rand(100, 100)  # Replace with actual raster data\ndiscontinuities = detect_spatial_discontinuities(raster)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial simulation of urban growth.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef urban_growth_simulation(initial_grid, iterations, kernel, growth_threshold):\n    grid = initial_grid.copy()\n    for _ in range(iterations):\n        neighbor_sum = convolve(grid, kernel, mode='constant', cval=0)\n        growth_probability = neighbor_sum / np.max(neighbor_sum)\n        new_growth = (growth_probability > growth_threshold).astype(int)\n        grid = np.clip(grid + new_growth, 0, 1)\n    return grid\n\n# Example usage\ninitial_grid = np.random.choice([0, 1], size=(50, 50), p=[0.8, 0.2])\nkernel = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\niterations = 10\ngrowth_threshold = 0.5\n\nfinal_grid = urban_growth_simulation(initial_grid, iterations, kernel, growth_threshold)\nprint(final_grid)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial correlation coefficient.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import pearsonr\n\ndef calculate_spatial_correlation(matrix1, matrix2):\n    if matrix1.shape != matrix2.shape:\n        raise ValueError(\"Input matrices must have the same dimensions.\")\n    flat1 = matrix1.flatten()\n    flat2 = matrix2.flatten()\n    correlation, _ = pearsonr(flat1, flat2)\n    return correlation\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the skeleton of a polygon geometry.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import unary_union\nimport numpy as np\nfrom scipy.ndimage import distance_transform_edt, generate_binary_structure\n\ndef polygon_skeleton(polygon, resolution=1000):\n    minx, miny, maxx, maxy = polygon.bounds\n    width, height = int((maxx - minx) * resolution), int((maxy - miny) * resolution)\n    raster = np.zeros((height, width), dtype=np.uint8)\n\n    coords = np.array(polygon.exterior.coords)\n    shifted_coords = (coords - [minx, miny]) * resolution\n    shifted_coords = shifted_coords.astype(int)\n\n    rows, cols = shifted_coords[:, 1], shifted_coords[:, 0]\n    raster[rows, cols] = 1\n\n    structure = generate_binary_structure(2, 2)\n    edt = distance_transform_edt(raster, structure=structure)\n    skeleton = edt > 0\n\n    return skeleton\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial uncertainty modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef spatial_uncertainty_modeling(mean, std_dev, num_samples, grid_size):\n    x = np.linspace(0, grid_size, num_samples)\n    y = np.linspace(0, grid_size, num_samples)\n    xx, yy = np.meshgrid(x, y)\n    positions = np.vstack([xx.ravel(), yy.ravel()]).T\n    \n    distribution = norm(loc=mean, scale=std_dev)\n    uncertainty_values = distribution.pdf(positions[:, 0]) * distribution.pdf(positions[:, 1])\n    uncertainty_grid = uncertainty_values.reshape(xx.shape)\n    \n    return xx, yy, uncertainty_grid\n\nmean = 0\nstd_dev = 1\nnum_samples = 100\ngrid_size = 10\n\nxx, yy, uncertainty_grid = spatial_uncertainty_modeling(mean, std_dev, num_samples, grid_size)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial concentration index.",
        "output": "```python\nimport numpy as np\n\ndef spatial_concentration_index(values, distances, alpha=1.0):\n    n = len(values)\n    total_value = np.sum(values)\n    sci = 0.0\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                sci += (values[i] * values[j]) / (distances[i][j] ** alpha)\n    \n    sci /= (total_value ** 2)\n    return sci\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster relief map from elevation data.",
        "output": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom osgeo import gdal\n\ndef generate_relief_map(elevation_file, output_file):\n    dataset = gdal.Open(elevation_file)\n    band = dataset.GetRasterBand(1)\n    elevation = band.ReadAsArray()\n    \n    plt.figure(figsize=(10, 8))\n    plt.imshow(elevation, cmap='terrain', interpolation='nearest')\n    plt.colorbar(label='Elevation (m)')\n    plt.title('Relief Map')\n    plt.xlabel('X Coordinate')\n    plt.ylabel('Y Coordinate')\n    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n    plt.close()\n\ngenerate_relief_map('elevation.tif', 'relief_map.png')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial sensitivity analysis.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import sobol_indices\n\ndef spatial_sensitivity_analysis(model_func, bounds, num_samples):\n    from SALib.sample import saltelli\n    from SALib.analyze import sobol\n\n    problem = {\n        'num_vars': len(bounds),\n        'names': [f'x{i}' for i in range(len(bounds))],\n        'bounds': bounds\n    }\n\n    param_values = saltelli.sample(problem, num_samples)\n    Y = np.array([model_func(*params) for params in param_values])\n\n    Si = sobol.analyze(problem, Y)\n    return Si\n\n# Example usage:\n# Define your spatial model function here\ndef spatial_model(x1, x2):\n    return x1**2 + x2\n\nbounds = [[-1, 1], [-1, 1]]\nnum_samples = 1000\nresult = spatial_sensitivity_analysis(spatial_model, bounds, num_samples)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial diversity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\ndef calculate_spatial_diversity(points, categories):\n    unique_categories = np.unique(categories)\n    category_counts = {cat: np.sum(categories == cat) for cat in unique_categories}\n    total_points = len(points)\n    diversity_index = 0\n\n    distance_matrix = squareform(pdist(points))\n\n    for i in range(total_points):\n        for j in range(i + 1, total_points):\n            if categories[i] != categories[j]:\n                diversity_index += distance_matrix[i, j]\n\n    max_possible_diversity = (total_points * (total_points - 1)) / 2\n    normalized_diversity = diversity_index / max_possible_diversity if max_possible_diversity > 0 else 0\n\n    return normalized_diversity\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the envelope of a geometry collection.",
        "output": "```python\nfrom shapely.geometry import GeometryCollection, Polygon\nfrom shapely.ops import unary_union\n\ndef extract_envelope(geometry_collection):\n    if not isinstance(geometry_collection, GeometryCollection):\n        raise ValueError(\"Input must be a GeometryCollection\")\n    return unary_union([geom.envelope for geom in geometry_collection.geoms])\n\n# Example usage\ngeometries = GeometryCollection([Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(2, 2), (3, 3), (3, 2)])])\nenvelope = extract_envelope(geometries)\nprint(envelope)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial pattern recognition.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform spatial pattern recognition using Moran's I\nattribute = \"your_attribute_column\"\nmoran = Moran(data[attribute], weights)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial inequality measure.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_inequality(values, weights=None):\n    if weights is None:\n        weights = np.ones_like(values)\n    total_weight = np.sum(weights)\n    weighted_mean = np.sum(values * weights) / total_weight\n    inequality = np.sum(weights * np.abs(values - weighted_mean)) / total_weight\n    return inequality\n\n# Example usage\nvalues = np.array([10, 20, 30, 40])\nweights = np.array([1, 1, 1, 1])\ninequality_measure = calculate_spatial_inequality(values, weights)\nprint(inequality_measure)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial clusters using scan statistics.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom scipy.stats import poisson\n\ndef detect_spatial_clusters(points, cases, population, radius, alpha=0.05):\n    n = len(points)\n    distances = distance_matrix(points, points)\n    max_likelihood = -np.inf\n    best_cluster = None\n\n    for i in range(n):\n        neighbors = np.where(distances[i] <= radius)[0]\n        cluster_cases = np.sum(cases[neighbors])\n        cluster_population = np.sum(population[neighbors])\n        total_cases = np.sum(cases)\n        total_population = np.sum(population)\n\n        if cluster_population == 0 or cluster_cases == 0:\n            continue\n\n        p_null = total_cases / total_population\n        p_cluster = cluster_cases / cluster_population\n        likelihood = (p_cluster ** cluster_cases) * ((1 - p_cluster) ** (cluster_population - cluster_cases)) / \\\n                     ((p_null ** cluster_cases) * ((1 - p_null) ** (cluster_population - cluster_cases)))\n\n        if likelihood > max_likelihood:\n            max_likelihood = likelihood\n            best_cluster = neighbors\n\n    threshold = poisson.ppf(1 - alpha, np.sum(cases) / np.sum(population) * np.sum(population[best_cluster]))\n    return best_cluster if np.sum(cases[best_cluster]) > threshold else None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial interpolation using IDW.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef idw_interpolation(points, values, grid_x, grid_y, power=2):\n    tree = cKDTree(points)\n    grid_points = np.array(np.meshgrid(grid_x, grid_y)).T.reshape(-1, 2)\n    distances, indices = tree.query(grid_points, k=5)\n    weights = 1 / (distances**power)\n    weights /= weights.sum(axis=1, keepdims=True)\n    interpolated_values = np.sum(weights * values[indices], axis=1)\n    return interpolated_values.reshape(len(grid_y), len(grid_x))\n\n# Example usage:\npoints = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\nvalues = np.array([1, 2, 3, 4])\ngrid_x = np.linspace(0, 1, 10)\ngrid_y = np.linspace(0, 1, 10)\nresult = idw_interpolation(points, values, grid_x, grid_y)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial interaction potential.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_interaction_potential(populations, distances, beta):\n    potentials = np.zeros(len(populations))\n    for i in range(len(populations)):\n        for j in range(len(populations)):\n            if i != j:\n                potentials[i] += populations[j] / (distances[i][j] ** beta)\n    return potentials\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster aspect map from a DEM.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo.gdalconst import GA_ReadOnly\n\ndef calculate_aspect(dem_path, output_path):\n    dataset = gdal.Open(dem_path, GA_ReadOnly)\n    band = dataset.GetRasterBand(1)\n    dem_array = band.ReadAsArray().astype(np.float32)\n    geotransform = dataset.GetGeoTransform()\n    cell_size_x = geotransform[1]\n    cell_size_y = -geotransform[5]\n\n    dzdx = ((np.roll(dem_array, 1, axis=1) - np.roll(dem_array, -1, axis=1)) / (2 * cell_size_x))\n    dzdy = ((np.roll(dem_array, -1, axis=0) - np.roll(dem_array, 1, axis=0)) / (2 * cell_size_y))\n\n    aspect = np.arctan2(dzdy, -dzdx) * (180 / np.pi)\n    aspect = (450 - aspect) % 360\n    aspect[dem_array == band.GetNoDataValue()] = -9999\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Float32)\n    out_dataset.SetGeoTransform(geotransform)\n    out_dataset.SetProjection(dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(aspect)\n    out_band.SetNoDataValue(-9999)\n    out_band.FlushCache()\n\n    dataset = None\n    out_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial econometric modeling.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\nimport libpysal\nfrom spreg import ML_Lag, ML_Error\n\n# Load data\ndata = pd.read_csv(\"spatial_data.csv\")\ny = data['dependent_variable'].values.reshape(-1, 1)\nX = data[['independent_var1', 'independent_var2']].values\n\n# Spatial weights matrix\nw = libpysal.weights.Queen.from_dataframe(data)\nw.transform = 'r'\n\n# Spatial Lag Model\nlag_model = ML_Lag(y, X, w=w)\nprint(lag_model.summary)\n\n# Spatial Error Model\nerror_model = ML_Error(y, X, w=w)\nprint(error_model.summary)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial dependency index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_spatial_dependency_index(data, threshold_distance):\n    n = len(data)\n    distances = cdist(data, data, metric='euclidean')\n    weights = (distances <= threshold_distance).astype(float)\n    np.fill_diagonal(weights, 0)\n    row_sums = weights.sum(axis=1)\n    row_sums[row_sums == 0] = 1\n    normalized_weights = weights / row_sums[:, np.newaxis]\n    spatial_dependency_index = np.sum(normalized_weights) / (n * (n - 1))\n    return spatial_dependency_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex hull boundary of a point set.",
        "output": "```python\nfrom scipy.spatial import ConvexHull\nimport numpy as np\n\npoints = np.random.rand(10, 2)  # Example point set\nhull = ConvexHull(points)\nboundary_points = points[hull.vertices]\nprint(boundary_points)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial scenario analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nregions = gpd.read_file(\"regions.geojson\")\npoints = gpd.read_file(\"points.geojson\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to find points within regions\njoined_data = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Group by region and count points in each region\nscenario_analysis = joined_data.groupby(\"region_id\").size().reset_index(name=\"point_count\")\n\n# Save results to a new file\nscenario_analysis.to_csv(\"spatial_scenario_analysis.csv\", index=False)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial exposure index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_exposure_index(population_grid, distance_decay_function, bandwidth):\n    n = population_grid.shape[0]\n    exposure_index = np.zeros_like(population_grid, dtype=float)\n    \n    for i in range(n):\n        for j in range(n):\n            if population_grid[i, j] > 0:\n                distances = np.sqrt((np.arange(n)[:, None] - i)**2 + (np.arange(n)[None, :] - j)**2)\n                decay_weights = distance_decay_function(distances, bandwidth)\n                exposure_index[i, j] = np.sum(decay_weights * population_grid)\n    \n    return exposure_index\n\ndef gaussian_decay(distance, bandwidth):\n    return np.exp(-0.5 * (distance / bandwidth)**2)\n\n# Example usage\npopulation_grid = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\nbandwidth = 1.5\nsei = calculate_spatial_exposure_index(population_grid, gaussian_decay, bandwidth)\nprint(sei)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial trends using semivariograms.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nimport matplotlib.pyplot as plt\n\ndef calculate_semivariogram(coords, values, lags):\n    distances = squareform(pdist(coords))\n    semivariances = []\n    for lag in lags:\n        indices = (distances >= lag - 0.5) & (distances < lag + 0.5)\n        if np.any(indices):\n            semivariance = 0.5 * np.mean((values[:, None] - values[None, :])**2, where=indices)\n            semivariances.append(semivariance)\n        else:\n            semivariances.append(np.nan)\n    return semivariances\n\n# Example usage\ncoords = np.random.rand(100, 2) * 100\nvalues = np.random.normal(size=100)\nlags = np.arange(1, 50)\n\nsemivariances = calculate_semivariogram(coords, values, lags)\n\nplt.plot(lags, semivariances, 'o-')\nplt.xlabel('Lag Distance')\nplt.ylabel('Semivariance')\nplt.title('Semivariogram')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial allocation using p-median models.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom scipy.optimize import linear_sum_assignment\n\ndef p_median_model(demand_points, facility_points, p):\n    distance_matrix = cdist(demand_points, facility_points, metric='euclidean')\n    num_demands = distance_matrix.shape[0]\n    num_facilities = distance_matrix.shape[1]\n\n    if p >= num_facilities:\n        raise ValueError(\"p must be less than the number of candidate facilities.\")\n\n    min_cost = float('inf')\n    best_combination = None\n\n    from itertools import combinations\n    for facility_subset in combinations(range(num_facilities), p):\n        subset_distances = distance_matrix[:, facility_subset]\n        min_distances = np.min(subset_distances, axis=1)\n        total_cost = np.sum(min_distances)\n\n        if total_cost < min_cost:\n            min_cost = total_cost\n            best_combination = facility_subset\n\n    return best_combination, min_cost\n\n# Example usage\ndemand_points = np.array([[2, 3], [5, 6], [8, 4]])\nfacility_points = np.array([[1, 1], [4, 2], [7, 5], [3, 8]])\np = 2\n\nselected_facilities, total_cost = p_median_model(demand_points, facility_points, p)\nprint(\"Selected Facilities:\", selected_facilities)\nprint(\"Total Cost:\", total_cost)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial accessibility index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_accessibility_index(demand, supply, distance_matrix, beta=1.0):\n    weighted_supply = supply * np.exp(-beta * distance_matrix)\n    accessibility_index = np.dot(demand, weighted_supply)\n    return accessibility_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster shaded relief map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo.gdalconst import GA_ReadOnly\n\ndef generate_shaded_relief(input_dem, output_file, z_factor=1.0, scale=1.0, azimuth=315, altitude=45):\n    dataset = gdal.Open(input_dem, GA_ReadOnly)\n    band = dataset.GetRasterBand(1)\n    nodata = band.GetNoDataValue()\n    dem = band.ReadAsArray().astype(np.float32)\n\n    if nodata is not None:\n        dem[dem == nodata] = np.nan\n\n    x_res = dataset.RasterXSize\n    y_res = dataset.RasterYSize\n    geotransform = dataset.GetGeoTransform()\n    cell_size_x = geotransform[1]\n    cell_size_y = -geotransform[5]\n\n    x, y = np.gradient(dem, cell_size_y * scale, cell_size_x * scale)\n    slope = np.pi / 2.0 - np.arctan(np.sqrt(x * x + y * y))\n    aspect = np.arctan2(-x, y)\n\n    azimuth_rad = np.deg2rad(360 - azimuth + 90)\n    altitude_rad = np.deg2rad(altitude)\n\n    shaded = np.sin(altitude_rad) * np.sin(slope) + np.cos(altitude_rad) * np.cos(slope) * np.cos(azimuth_rad - aspect)\n    shaded = np.clip(shaded, 0, 1)\n    shaded = (shaded * 255).astype(np.uint8)\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_file, x_res, y_res, 1, gdal.GDT_Byte)\n    out_dataset.SetGeoTransform(geotransform)\n    out_dataset.SetProjection(dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(shaded)\n    out_band.SetNoDataValue(0)\n    out_band.FlushCache()\n\n    dataset = None\n    out_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial forecasting using time series.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_squared_error\n\n# Load spatial-temporal data\ndata = pd.read_csv('spatial_temporal_data.csv', parse_dates=['date'], index_col='date')\n\n# Define a function for spatial forecasting\ndef spatial_forecasting(data, target_location, p, d, q, forecast_steps):\n    # Filter data for the target location\n    target_data = data[data['location'] == target_location]['value']\n    \n    # Train ARIMA model\n    model = ARIMA(target_data, order=(p, d, q))\n    model_fit = model.fit()\n    \n    # Forecast future values\n    forecast = model_fit.forecast(steps=forecast_steps)\n    return forecast\n\n# Example usage\ntarget_location = 'Location_A'\nforecast_steps = 10\np, d, q = 5, 1, 0  # ARIMA parameters\nforecast = spatial_forecasting(data, target_location, p, d, q, forecast_steps)\n\nprint(forecast)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial segregation index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_segregation_index(locations, group_labels):\n    n = len(locations)\n    distances = cdist(locations, locations)\n    np.fill_diagonal(distances, np.inf)\n    \n    segregation_scores = []\n    for i in range(n):\n        nearest_neighbor_idx = np.argmin(distances[i])\n        if group_labels[i] == group_labels[nearest_neighbor_idx]:\n            segregation_scores.append(1)\n        else:\n            segregation_scores.append(0)\n    \n    segregation_index = np.mean(segregation_scores)\n    return segregation_index\n\n# Example usage:\nlocations = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\ngroup_labels = np.array([0, 0, 1, 1])\nindex = calculate_segregation_index(locations, group_labels)\nprint(index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex cover of a geometry set.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\n\ndef get_convex_hull(geometries):\n    points = [point for geom in geometries for point in geom.exterior.coords]\n    multipoint = MultiPoint(points)\n    return multipoint.convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = get_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial multicriteria evaluation.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\n# Example criteria rasters (replace with actual file paths)\ncriteria_raster_paths = [\"criterion1.tif\", \"criterion2.tif\", \"criterion3.tif\"]\nweights = [0.4, 0.3, 0.3]  # Weights for each criterion\n\n# Load rasters and normalize values\ndef load_and_normalize(raster_path):\n    dataset = gdal.Open(raster_path)\n    band = dataset.GetRasterBand(1)\n    array = band.ReadAsArray().astype(float)\n    array_normalized = (array - np.min(array)) / (np.max(array) - np.min(array))\n    return array_normalized\n\ncriteria_arrays = [load_and_normalize(path) for path in criteria_raster_paths]\n\n# Perform weighted overlay\nweighted_sum = np.zeros_like(criteria_arrays[0])\nfor i, array in enumerate(criteria_arrays):\n    weighted_sum += array * weights[i]\n\n# Save the result to a new raster\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"weighted_overlay_result.tif\", \n                              criteria_arrays[0].shape[1], \n                              criteria_arrays[0].shape[0], \n                              1, gdal.GDT_Float32)\noutput_raster.GetRasterBand(1).WriteArray(weighted_sum)\n\n# Copy geotransform and projection from input raster\nreference_raster = gdal.Open(criteria_raster_paths[0])\noutput_raster.SetGeoTransform(reference_raster.GetGeoTransform())\noutput_raster.SetProjection(reference_raster.GetProjection())\n\noutput_raster.FlushCache()\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial polarization index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_spatial_polarization(data, alpha=0.5):\n    distances = cdist(data, data, metric='euclidean')\n    np.fill_diagonal(distances, np.inf)\n    nearest_neighbor_idx = np.argmin(distances, axis=1)\n    polarization_index = np.mean(np.abs(data - data[nearest_neighbor_idx]) ** alpha)\n    return polarization_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial hotspots using KDE.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import gaussian_kde\nfrom shapely.geometry import Point\nimport geopandas as gpd\n\ndef detect_hotspots(points, bandwidth=None, grid_size=100):\n    points = np.array(points)\n    kde = gaussian_kde(points.T, bw_method=bandwidth)\n    \n    x_min, y_min = points.min(axis=0)\n    x_max, y_max = points.max(axis=0)\n    \n    x = np.linspace(x_min, x_max, grid_size)\n    y = np.linspace(y_min, y_max, grid_size)\n    xx, yy = np.meshgrid(x, y)\n    \n    coords = np.vstack([xx.ravel(), yy.ravel()])\n    density = kde(coords).reshape(xx.shape)\n    \n    hotspots = []\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if density[i, j] > np.percentile(density, 95):\n                hotspots.append(Point(x[j], y[i]))\n                \n    return gpd.GeoDataFrame(geometry=hotspots)\n\n# Example usage:\n# points = [[x1, y1], [x2, y2], ...]\n# hotspots_gdf = detect_hotspots(points)\n# hotspots_gdf.plot()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial risk assessment.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\n\n# Load risk factors data and spatial data\nrisk_factors = pd.read_csv(\"risk_factors.csv\")\nspatial_data = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the coordinate reference systems (CRS) match\nspatial_data = spatial_data.to_crs(epsg=4326)\n\n# Convert risk factor points to GeoDataFrame\ngeometry = [Point(xy) for xy in zip(risk_factors['longitude'], risk_factors['latitude'])]\nrisk_points = gpd.GeoDataFrame(risk_factors, geometry=geometry, crs=\"EPSG:4326\")\n\n# Perform spatial join to associate risk points with spatial polygons\njoined_data = gpd.sjoin(spatial_data, risk_points, how=\"inner\", predicate=\"contains\")\n\n# Aggregate risk scores by spatial unit\nrisk_summary = joined_data.groupby('region_id')['risk_score'].sum().reset_index()\n\n# Merge aggregated risk scores back to the spatial data\nspatial_data = spatial_data.merge(risk_summary, on='region_id', how='left')\n\n# Fill missing risk scores with 0\nspatial_data['risk_score'] = spatial_data['risk_score'].fillna(0)\n\n# Save the result to a new shapefile\nspatial_data.to_file(\"spatial_risk_assessment.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial proximity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_proximity_index(matrix):\n    n = matrix.shape[0]\n    spi = np.zeros(n)\n    for i in range(n):\n        total_distance = np.sum(matrix[i])\n        if total_distance > 0:\n            spi[i] = np.sum(matrix[i] / total_distance)\n    return spi\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster flow direction map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\ndef generate_flow_direction(dem_path, output_path):\n    dem_dataset = gdal.Open(dem_path)\n    band = dem_dataset.GetRasterBand(1)\n    dem_array = band.ReadAsArray()\n    rows, cols = dem_array.shape\n    flow_dir = np.zeros_like(dem_array, dtype=np.uint8)\n\n    directions = [\n        (1, 0, 1), (1, -1, 2), (0, -1, 4), (-1, -1, 8),\n        (-1, 0, 16), (-1, 1, 32), (0, 1, 64), (1, 1, 128)\n    ]\n\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            min_val = dem_array[i, j]\n            dir_idx = 0\n            for idx, (di, dj, code) in enumerate(directions):\n                ni, nj = i + di, j + dj\n                if dem_array[ni, nj] < min_val:\n                    min_val = dem_array[ni, nj]\n                    dir_idx = code\n            flow_dir[i, j] = dir_idx\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_path, cols, rows, 1, gdal.GDT_Byte)\n    out_dataset.SetGeoTransform(dem_dataset.GetGeoTransform())\n    out_dataset.SetProjection(dem_dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(flow_dir)\n    out_band.FlushCache()\n    out_dataset = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial impact assessment.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the impact area and target layers\nimpact_area = gpd.read_file(\"impact_area.shp\")\ntarget_layer = gpd.read_file(\"target_layer.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\ntarget_layer = target_layer.to_crs(impact_area.crs)\n\n# Perform spatial join to find intersections\nspatial_join = gpd.sjoin(target_layer, impact_area, how=\"inner\", predicate=\"intersects\")\n\n# Save the results to a new shapefile\nspatial_join.to_file(\"spatial_impact_assessment_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial fragmentation index.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import label\n\ndef calculate_spatial_fragmentation(binary_map):\n    labeled_array, num_features = label(binary_map)\n    total_cells = np.sum(binary_map)\n    fragmentation_index = (num_features - 1) / total_cells if total_cells > 0 else 0\n    return fragmentation_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex partition of a polygon.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import triangulate\n\ndef convex_partition(polygon):\n    triangles = triangulate(polygon)\n    return [triangle for triangle in triangles if polygon.contains(triangle)]\n\n# Example usage\npolygon = Polygon([(0, 0), (4, 0), (4, 4), (0, 4)])\nconvex_parts = convex_partition(polygon)\nprint(convex_parts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial vulnerability analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load vulnerability and hazard data\nvulnerability_data = gpd.read_file(\"vulnerability.shp\")\nhazard_data = gpd.read_file(\"hazard.shp\")\n\n# Ensure both datasets are in the same CRS\nvulnerability_data = vulnerability_data.to_crs(hazard_data.crs)\n\n# Perform spatial join to find intersections\nspatial_join = gpd.sjoin(vulnerability_data, hazard_data, how=\"inner\", predicate=\"intersects\")\n\n# Calculate vulnerability score based on attributes\nspatial_join[\"vulnerability_score\"] = spatial_join[\"population\"] * spatial_join[\"hazard_intensity\"]\n\n# Save results to a new shapefile\nspatial_join.to_file(\"vulnerability_analysis_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial resilience index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_resilience_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    resilience_index = np.sum(weighted_data, axis=1)\n    return resilience_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial anomalies using machine learning.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom sklearn.ensemble import IsolationForest\nfrom shapely.geometry import Point\n\n# Load spatial data (example: shapefile)\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a geometry column and convert to WGS84 if necessary\ndata = data.to_crs(epsg=4326)\n\n# Extract coordinates for analysis\ndata['x'] = data.geometry.x\ndata['y'] = data.geometry.y\n\n# Prepare feature matrix\nfeatures = data[['x', 'y']]\n\n# Initialize and fit the anomaly detection model\nmodel = IsolationForest(contamination=0.05, random_state=42)\ndata['anomaly'] = model.fit_predict(features)\n\n# Mark anomalies (-1 indicates an anomaly)\ndata['is_anomaly'] = data['anomaly'] == -1\n\n# Save results to a new shapefile\nanomalies = data[data['is_anomaly']]\nanomalies.to_file(\"detected_anomalies.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial prioritization using ranking.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define the criteria for ranking (example: based on a column named 'value')\ndata['rank'] = data['value'].rank(ascending=False)\n\n# Sort the GeoDataFrame by rank\nprioritized_data = data.sort_values(by='rank')\n\n# Save the prioritized data to a new shapefile\nprioritized_data.to_file(\"prioritized_data.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial dominance index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_dominance_index(values, weights):\n    total_weight = np.sum(weights)\n    weighted_values = values * weights\n    dominance_index = np.sum(weighted_values) / total_weight\n    return dominance_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster watershed map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom scipy.ndimage import label\n\ndef generate_watershed_map(dem_path, output_path):\n    # Read DEM\n    dataset = gdal.Open(dem_path)\n    band = dataset.GetRasterBand(1)\n    dem = band.ReadAsArray()\n    \n    # Fill sinks in DEM\n    filled_dem = fill_sinks(dem)\n    \n    # Compute flow direction\n    flow_dir = compute_flow_direction(filled_dem)\n    \n    # Compute flow accumulation\n    flow_acc = compute_flow_accumulation(flow_dir)\n    \n    # Define outlets based on high accumulation\n    outlets = define_outlets(flow_acc)\n    \n    # Label watersheds\n    watershed_labels, _ = label(outlets)\n    \n    # Save the result to a new raster\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_dataset = driver.Create(output_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Int32)\n    out_dataset.SetGeoTransform(dataset.GetGeoTransform())\n    out_dataset.SetProjection(dataset.GetProjection())\n    out_band = out_dataset.GetRasterBand(1)\n    out_band.WriteArray(watershed_labels)\n    out_band.FlushCache()\n\ndef fill_sinks(dem):\n    from richdem import rdarray, FillDepressions\n    dem_rd = rdarray(dem, no_data=-9999)\n    filled_dem = FillDepressions(dem_rd, epsilon=True)\n    return filled_dem\n\ndef compute_flow_direction(dem):\n    from richdem import rdarray, FlowAccumulation\n    dem_rd = rdarray(dem, no_data=-9999)\n    flow_dir = FlowAccumulation(dem_rd, method='D8')\n    return flow_dir\n\ndef compute_flow_accumulation(flow_dir):\n    from richdem import rdarray, FlowAccumulation\n    flow_dir_rd = rdarray(flow_dir, no_data=-9999)\n    flow_acc = FlowAccumulation(flow_dir_rd, method='D8')\n    return flow_acc\n\ndef define_outlets(flow_acc, threshold=1000):\n    outlets = (flow_acc > threshold).astype(int)\n    return outlets\n\n# Example usage\ngenerate_watershed_map(\"input_dem.tif\", \"output_watershed.tif\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial trade-off analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both datasets are in the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to associate points with regions\nspatial_join = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Aggregate point attributes within each region\ntrade_off_analysis = spatial_join.groupby(\"region_id\").agg(\n    total_value=(\"value\", \"sum\"),\n    count=(\"value\", \"count\")\n).reset_index()\n\n# Save results to a new shapefile\ntrade_off_analysis.to_file(\"trade_off_analysis.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial equity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_equity_index(accessibility_scores):\n    mean_accessibility = np.mean(accessibility_scores)\n    deviations = np.abs(accessibility_scores - mean_accessibility)\n    spatial_equity_index = np.mean(deviations)\n    return spatial_equity_index\n\n# Example usage\naccessibility_scores = np.array([5, 10, 15, 20, 25])\nsei = calculate_spatial_equity_index(accessibility_scores)\nprint(sei)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex tessellation of a point set.",
        "output": "```python\nfrom scipy.spatial import ConvexHull\nimport numpy as np\n\ndef convex_tessellation(points):\n    hull = ConvexHull(points)\n    return hull.points[hull.vertices]\n\n# Example usage\npoints = np.random.rand(10, 2)\nconvex_vertices = convex_tessellation(points)\nprint(convex_vertices)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial sustainability assessment.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both datasets are in the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to associate points with regions\njoined_data = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Aggregate sustainability metrics (example: count of points per region)\nsustainability_metrics = joined_data.groupby(\"region_id\").size().reset_index(name=\"point_count\")\n\n# Merge metrics back to the regions dataset\nregions_with_metrics = regions.merge(sustainability_metrics, on=\"region_id\", how=\"left\")\n\n# Fill NaN values for regions without points\nregions_with_metrics[\"point_count\"] = regions_with_metrics[\"point_count\"].fillna(0)\n\n# Save the result to a new shapefile\nregions_with_metrics.to_file(\"sustainability_assessment.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial efficiency index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_efficiency_index(area, population, service_area):\n    population_density = population / area\n    coverage_ratio = service_area / area\n    spatial_efficiency_index = np.log(population_density + 1) * coverage_ratio\n    return spatial_efficiency_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial patterns using PCA.",
        "output": "```python\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Example spatial data (replace with your actual dataset)\ndata = np.random.rand(100, 5)  # 100 samples, 5 variables\n\n# Standardize the data\nscaler = StandardScaler()\ndata_standardized = scaler.fit_transform(data)\n\n# Perform PCA\npca = PCA()\nprincipal_components = pca.fit_transform(data_standardized)\n\n# Explained variance ratio\nexplained_variance = pca.explained_variance_ratio_\n\n# Cumulative explained variance\ncumulative_variance = np.cumsum(explained_variance)\n\n# Output results\nprint(\"Principal Components:\")\nprint(principal_components)\nprint(\"\\nExplained Variance Ratio:\")\nprint(explained_variance)\nprint(\"\\nCumulative Explained Variance:\")\nprint(cumulative_variance)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial governance analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both datasets are in the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to find points within regions\nspatial_join = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Group by region and count points in each region\npoint_counts = spatial_join.groupby(\"region_id\").size().reset_index(name=\"point_count\")\n\n# Merge counts back to the regions dataset\nregions_with_counts = regions.merge(point_counts, on=\"region_id\", how=\"left\")\n\n# Fill NaN values with 0 for regions without points\nregions_with_counts[\"point_count\"] = regions_with_counts[\"point_count\"].fillna(0)\n\n# Save results to a new shapefile\nregions_with_counts.to_file(\"regions_with_point_counts.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial inclusiveness index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_inclusiveness_index(accessibility_scores, population_distribution):\n    normalized_accessibility = accessibility_scores / np.max(accessibility_scores)\n    weighted_accessibility = normalized_accessibility * population_distribution\n    spatial_inclusiveness_index = np.sum(weighted_accessibility) / np.sum(population_distribution)\n    return spatial_inclusiveness_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster landform classification map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom scipy.ndimage import convolve\n\ndef generate_landform_classification(dem_path, output_path):\n    # Load DEM\n    ds = gdal.Open(dem_path)\n    band = ds.GetRasterBand(1)\n    dem = band.ReadAsArray().astype(float)\n\n    # Define kernels for terrain analysis\n    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n    kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n\n    # Compute slope gradient in x and y directions\n    grad_x = convolve(dem, kernel_x)\n    grad_y = convolve(dem, kernel_y)\n\n    # Calculate slope and aspect\n    slope = np.arctan(np.sqrt(grad_x**2 + grad_y**2))\n    aspect = np.arctan2(grad_y, grad_x)\n\n    # Normalize slope and aspect to 0-255 range for classification\n    slope_norm = (slope / np.max(slope)) * 255\n    aspect_norm = (aspect / np.max(aspect)) * 255\n\n    # Simple landform classification based on thresholds\n    classification = np.zeros_like(dem, dtype=np.uint8)\n    classification[(slope_norm < 50) & (aspect_norm < 50)] = 1  # Flat areas\n    classification[(slope_norm >= 50) & (slope_norm < 150)] = 2  # Gentle slopes\n    classification[slope_norm >= 150] = 3  # Steep slopes\n\n    # Save the classification raster\n    driver = gdal.GetDriverByName(\"GTiff\")\n    out_ds = driver.Create(output_path, ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Byte)\n    out_ds.SetGeoTransform(ds.GetGeoTransform())\n    out_ds.SetProjection(ds.GetProjection())\n    out_band = out_ds.GetRasterBand(1)\n    out_band.WriteArray(classification)\n    out_band.FlushCache()\n    out_ds = None\n\n# Example usage\ngenerate_landform_classification(\"input_dem.tif\", \"output_landform_map.tif\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial policy evaluation.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load policy and target area shapefiles\npolicy_areas = gpd.read_file(\"policy_areas.shp\")\ntarget_areas = gpd.read_file(\"target_areas.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\npolicy_areas = policy_areas.to_crs(target_areas.crs)\n\n# Perform spatial join to evaluate overlap\nspatial_join = gpd.sjoin(policy_areas, target_areas, how=\"inner\", predicate=\"intersects\")\n\n# Calculate intersection areas\nspatial_join[\"intersection_area\"] = spatial_join.apply(\n    lambda row: row.geometry.intersection(target_areas.loc[row.index_right].geometry).area, axis=1\n)\n\n# Aggregate results by target area ID\nevaluation_results = spatial_join.groupby(\"index_right\").agg(\n    total_overlap_area=(\"intersection_area\", \"sum\"),\n    policy_count=(\"policy_id\", \"count\")\n).reset_index()\n\n# Save results to a new shapefile\nevaluation_results.to_file(\"evaluation_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial cohesion index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_spatial_cohesion(points, weights=None):\n    if weights is None:\n        weights = np.ones(len(points))\n    distances = cdist(points, points)\n    np.fill_diagonal(distances, np.inf)\n    min_distances = np.min(distances, axis=1)\n    cohesion_index = np.sum(weights * min_distances) / np.sum(weights)\n    return cohesion_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex arrangement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_arrangement(geometries):\n    combined = unary_union(geometries)\n    if combined.geom_type == \"Polygon\":\n        return [combined.convex_hull]\n    elif combined.geom_type in [\"MultiPolygon\", \"GeometryCollection\"]:\n        convex_parts = []\n        for geom in combined.geoms:\n            convex_parts.append(geom.convex_hull)\n        return convex_parts\n    else:\n        points = MultiPoint([pt for geom in geometries for pt in geom.exterior.coords])\n        return [points.convex_hull]\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial stakeholder analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load stakeholder data and spatial boundary data\nstakeholders = gpd.read_file(\"stakeholders.geojson\")\nboundaries = gpd.read_file(\"boundaries.geojson\")\n\n# Ensure both GeoDataFrames have the same CRS\nstakeholders = stakeholders.to_crs(boundaries.crs)\n\n# Perform spatial join to identify stakeholders within each boundary\nspatial_join = gpd.sjoin(stakeholders, boundaries, how=\"inner\", predicate=\"within\")\n\n# Group by boundary ID and aggregate stakeholder information\nstakeholder_analysis = spatial_join.groupby(\"boundary_id\").agg(\n    stakeholder_count=(\"stakeholder_id\", \"count\"),\n    unique_stakeholders=(\"stakeholder_name\", lambda x: list(x.unique()))\n).reset_index()\n\n# Save the result to a new GeoJSON file\nstakeholder_analysis.to_file(\"spatial_stakeholder_analysis.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial adaptability index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_adaptability_index(weights, factors):\n    normalized_factors = (factors - np.min(factors, axis=0)) / (np.max(factors, axis=0) - np.min(factors, axis=0))\n    weighted_factors = normalized_factors * weights\n    spatial_adaptability_index = np.sum(weighted_factors, axis=1)\n    return spatial_adaptability_index\n\nweights = np.array([0.4, 0.3, 0.3])\nfactors = np.array([[5, 3, 8], [7, 6, 5], [2, 9, 7]])\nsai = calculate_spatial_adaptability_index(weights, factors)\nprint(sai)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial conflicts using overlays.",
        "output": "```python\nimport geopandas as gpd\n\n# Load the shapefiles or GeoJSON files\nlayer1 = gpd.read_file(\"path_to_layer1.shp\")\nlayer2 = gpd.read_file(\"path_to_layer2.shp\")\n\n# Perform overlay operation to detect spatial conflicts\nconflicts = gpd.overlay(layer1, layer2, how=\"intersection\")\n\n# Save the conflict areas to a new file\nconflicts.to_file(\"spatial_conflicts.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial collaboration modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform Local Moran's I analysis for spatial collaboration modeling\nlocal_moran = Moran_Local(data[\"attribute_column\"], weights)\n\n# Add results to the GeoDataFrame\ndata[\"Isignificance\"] = local_moran.p_sim\ndata[\"Ivalue\"] = local_moran.Is\n\n# Filter significant clusters\nsignificant_clusters = data[data[\"Isignificance\"] < 0.05]\n\n# Save results to a new shapefile\nsignificant_clusters.to_file(\"spatial_collaboration_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial integration index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_integration_index(values, weights):\n    weighted_sum = np.sum(values * weights)\n    total_weight = np.sum(weights)\n    return weighted_sum / total_weight if total_weight != 0 else 0\n\n# Example usage:\nvalues = np.array([10, 20, 30, 40])\nweights = np.array([1, 2, 3, 4])\nspatial_integration_index = calculate_spatial_integration_index(values, weights)\nprint(spatial_integration_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster vegetation index map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\n\n# Load the input raster bands (e.g., red and near-infrared bands)\nwith rasterio.open('red_band.tif') as red_src, rasterio.open('nir_band.tif') as nir_src:\n    red = red_src.read(1).astype(float)\n    nir = nir_src.read(1).astype(float)\n\n    # Calculate the NDVI (Normalized Difference Vegetation Index)\n    ndvi = (nir - red) / (nir + red)\n\n    # Handle NaN or Inf values\n    ndvi[np.isnan(ndvi)] = -1\n    ndvi[np.isinf(ndvi)] = -1\n\n    # Write the NDVI result to a new raster file\n    profile = red_src.profile\n    profile.update(dtype=rasterio.float32, count=1)\n\n    with rasterio.open('ndvi_map.tif', 'w', **profile) as dst:\n        dst.write(ndvi.astype(rasterio.float32), 1)\n\n# Display the NDVI map\nwith rasterio.open('ndvi_map.tif') as ndvi_src:\n    show(ndvi_src, cmap='RdYlGn')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial innovation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Create a buffer around points\ndata['buffer'] = data.geometry.buffer(0.1)\n\n# Perform spatial join to find intersections\njoined_data = gpd.sjoin(data, data, how=\"inner\", predicate=\"intersects\")\n\n# Calculate innovation metric (example: count of intersecting features)\ninnovation_analysis = joined_data.groupby('index_left').size().reset_index(name='intersection_count')\n\n# Merge results back to original data\nresult = data.merge(innovation_analysis, left_index=True, right_on='index_left')\n\n# Save the result to a new shapefile\nresult.to_file(\"innovation_analysis_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial participation index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spi(values, weights):\n    weighted_values = np.sum(values * weights)\n    total_weights = np.sum(weights)\n    spi = weighted_values / total_weights if total_weights != 0 else 0\n    return spi\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex alignment of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(1, 1), (2, 2), (2, 1)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial partnership modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis\nattribute = \"your_target_column\"\nmoran_loc = Moran_Local(data[attribute], w)\n\n# Add results to GeoDataFrame\ndata['Isign'] = moran_loc.p_sim\ndata['Ivalue'] = moran_loc.Is\n\n# Classify spatial partnerships\ndata['Partnership'] = None\ndata.loc[(data['Ivalue'] > 0) & (data['Isign'] < 0.05), 'Partnership'] = 'Cluster_HH'\ndata.loc[(data['Ivalue'] < 0) & (data['Isign'] < 0.05), 'Partnership'] = 'Cluster_LL'\ndata.loc[(data['Ivalue'] > 0) & (data['Isign'] >= 0.05), 'Partnership'] = 'Outlier_HL'\ndata.loc[(data['Ivalue'] < 0) & (data['Isign'] >= 0.05), 'Partnership'] = 'Outlier_LH'\n\n# Save results to a new shapefile\ndata.to_file(\"spatial_partnership_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial empowerment index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_empowerment_index(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    sei = np.sum(weighted_data, axis=1)\n    return sei\n\n# Example usage\ndata = np.array([[5, 10, 3], [8, 7, 6], [9, 5, 2]])\nweights = np.array([0.4, 0.3, 0.3])\nsei_values = calculate_spatial_empowerment_index(data, weights)\nprint(sei_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial synergies using networks.",
        "output": "```python\nimport geopandas as gpd\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ngdf = gpd.read_file(\"spatial_data.shp\")\n\n# Create a graph\nG = nx.Graph()\n\n# Add nodes with spatial attributes\nfor idx, row in gdf.iterrows():\n    G.add_node(idx, geometry=row.geometry)\n\n# Add edges based on spatial proximity\nfor i, row_i in gdf.iterrows():\n    for j, row_j in gdf.iterrows():\n        if i != j and row_i.geometry.distance(row_j.geometry) < threshold_distance:\n            G.add_edge(i, j)\n\n# Analyze spatial synergies\ndegree_centrality = nx.degree_centrality(G)\nbetweenness_centrality = nx.betweenness_centrality(G)\n\n# Plot the network\npos = {idx: (row.geometry.centroid.x, row.geometry.centroid.y) for idx, row in gdf.iterrows()}\nnx.draw(G, pos, with_labels=True, node_size=50, node_color=\"skyblue\", edge_color=\"gray\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial leadership analysis.",
        "output": "Performing spatial leadership analysis typically involves analyzing spatial data to identify patterns, clusters, or leading regions based on certain attributes. Below is an example of Python code using GeoPandas and PySAL libraries to perform a basic spatial leadership analysis (e.g., identifying spatial clusters using Local Moran's I).\n\n```python\nimport geopandas as gpd\nimport libpysal\nfrom esda.moran import Moran_Local\nimport matplotlib.pyplot as plt\n\n# Load spatial data (replace 'your_shapefile.shp' with your dataset)\ngdf = gpd.read_file('your_shapefile.shp')\n\n# Ensure the GeoDataFrame has a valid CRS\ngdf = gdf.to_crs(epsg=4326)\n\n# Extract the variable of interest for analysis (replace 'attribute_column' with your column name)\nattribute_values = gdf['attribute_column']\n\n# Create a spatial weights matrix (e.g., Queen contiguity)\nweights = libpysal.weights.Queen.from_dataframe(gdf)\nweights.transform = 'R'\n\n# Perform Local Moran's I analysis\nlocal_moran = Moran_Local(attribute_values, weights)\n\n# Add results to the GeoDataFrame\ngdf['morans_I'] = local_moran.Is\ngdf['p_value'] = local_moran.p_sim\ngdf['quadrant'] = local_moran.q\n\n# Classify clusters into High-High, Low-Low, High-Low, Low-High\ngdf['cluster_type'] = None\ngdf.loc[(gdf['quadrant'] == 1) & (gdf['p_value'] < 0.05), 'cluster_type'] = 'High-High'\ngdf.loc[(gdf['quadrant'] == 2) & (gdf['p_value'] < 0.05), 'cluster_type'] = 'Low-High'\ngdf.loc[(gdf['quadrant'] == 3) & (gdf['p_value'] < 0.05), 'cluster_type'] = 'Low-Low'\ngdf.loc[(gdf['quadrant'] == 4) & (gdf['p_value'] < 0.05), 'cluster_type'] = 'High-Low'\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(12, 10))\ngdf.plot(column='cluster_type', cmap='coolwarm', legend=True, ax=ax, \n         legend_kw"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial accountability index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_accountability_index(values, weights):\n    weighted_values = np.multiply(values, weights)\n    total_weight = np.sum(weights)\n    spatial_accountability_index = np.sum(weighted_values) / total_weight\n    return spatial_accountability_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster soil erosion map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define parameters\nrows, cols = 100, 100\ncell_size = 30\nrainfall_intensity = 50\nsoil_erodibility = 0.3\nslope_angle = np.deg2rad(10)\n\n# Generate synthetic slope and rainfall data\nx = np.linspace(0, cols * cell_size, cols)\ny = np.linspace(0, rows * cell_size, rows)\nxx, yy = np.meshgrid(x, y)\nslope = np.full((rows, cols), np.tan(slope_angle))\nrainfall = np.full((rows, cols), rainfall_intensity)\n\n# Calculate soil erosion using a simplified USLE model\nerosion = rainfall * soil_erodibility * slope\n\n# Save the erosion map as a GeoTIFF\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"soil_erosion_map.tif\", cols, rows, 1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform((0, cell_size, 0, rows * cell_size, 0, -cell_size))\n\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(32633)  # Example: UTM Zone 33N\noutput_raster.SetProjection(srs.ExportToWkt())\n\nband = output_raster.GetRasterBand(1)\nband.WriteArray(erosion)\nband.FlushCache()\nband.SetNoDataValue(-9999)\n\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial capacity building analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ncapacity_data = gpd.read_file(\"capacity_data.shp\")\ndemand_data = gpd.read_file(\"demand_data.shp\")\n\n# Ensure both datasets are in the same CRS\ncapacity_data = capacity_data.to_crs(epsg=4326)\ndemand_data = demand_data.to_crs(epsg=4326)\n\n# Perform spatial join to find nearest capacity points for each demand point\njoined_data = gpd.sjoin_nearest(demand_data, capacity_data, how=\"left\", distance_col=\"distance\")\n\n# Calculate total capacity and demand\ntotal_capacity = joined_data['capacity'].sum()\ntotal_demand = demand_data['demand'].sum()\n\n# Evaluate surplus or deficit\nsurplus_deficit = total_capacity - total_demand\n\n# Output results\nprint(f\"Total Capacity: {total_capacity}\")\nprint(f\"Total Demand: {total_demand}\")\nprint(f\"Surplus/Deficit: {surplus_deficit}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial transparency index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_transparency_index(density, visibility):\n    density_normalized = (density - np.min(density)) / (np.max(density) - np.min(density))\n    visibility_normalized = (visibility - np.min(visibility)) / (np.max(visibility) - np.min(visibility))\n    spatial_transparency_index = 1 - (density_normalized * visibility_normalized)\n    return spatial_transparency_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex coordination of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull_coordinates(geometries):\n    combined_geometry = unary_union(geometries)\n    convex_hull = combined_geometry.convex_hull\n    if isinstance(convex_hull, Polygon):\n        return list(convex_hull.exterior.coords)\n    elif isinstance(convex_hull, MultiPolygon):\n        return [list(polygon.exterior.coords) for polygon in convex_hull.geoms]\n    else:\n        return []\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial trust modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\ndef calculate_trust(source_locations, target_location, trust_weights):\n    distances = distance.cdist(source_locations, [target_location], 'euclidean').flatten()\n    normalized_distances = 1 / (1 + distances)\n    weighted_trust = np.dot(normalized_distances, trust_weights)\n    return weighted_trust / np.sum(trust_weights)\n\nsource_locations = np.array([[34.05, -118.25], [40.71, -74.01], [51.51, -0.13]])\ntarget_location = np.array([37.77, -122.42])\ntrust_weights = np.array([0.5, 0.3, 0.2])\n\ntrust_score = calculate_trust(source_locations, target_location, trust_weights)\nprint(trust_score)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial responsiveness index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_responsiveness_index(values, distances):\n    weights = 1 / distances\n    weighted_values = values * weights\n    total_weight = np.sum(weights)\n    spatial_responsiveness_index = np.sum(weighted_values) / total_weight\n    return spatial_responsiveness_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial opportunities using scenarios.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nexisting_locations = gpd.read_file(\"existing_locations.geojson\")\ncandidate_locations = gpd.read_file(\"candidate_locations.geojson\")\n\n# Define a buffer radius for proximity analysis (in meters)\nbuffer_radius = 1000\n\n# Create buffers around existing locations\nexisting_buffers = existing_locations.copy()\nexisting_buffers[\"geometry\"] = existing_locations.buffer(buffer_radius)\n\n# Dissolve buffers to create a single exclusion zone\nexclusion_zone = existing_buffers.unary_union\n\n# Identify candidate locations outside the exclusion zone\nopportunities = candidate_locations[~candidate_locations.intersects(exclusion_zone)]\n\n# Save the resulting opportunities to a new file\nopportunities.to_file(\"spatial_opportunities.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial negotiation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Example: Load spatial data\nregion_boundaries = gpd.read_file(\"regions.shp\")\nnegotiation_points = gpd.read_file(\"points.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\nregion_boundaries = region_boundaries.to_crs(epsg=4326)\nnegotiation_points = negotiation_points.to_crs(epsg=4326)\n\n# Perform spatial join to find points within each region\nspatial_join = gpd.sjoin(negotiation_points, region_boundaries, how=\"inner\", predicate=\"within\")\n\n# Group by region and count negotiation points in each region\nnegotiation_analysis = spatial_join.groupby(\"index_right\").size().reset_index(name=\"point_count\")\n\n# Merge results back to original regions for visualization or further analysis\nregion_boundaries = region_boundaries.merge(negotiation_analysis, left_index=True, right_on=\"index_right\", how=\"left\")\n\n# Fill NaN values for regions with no points\nregion_boundaries[\"point_count\"] = region_boundaries[\"point_count\"].fillna(0).astype(int)\n\n# Save results to a new shapefile\nregion_boundaries.to_file(\"negotiation_analysis_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial fairness index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_fairness_index(values, distances):\n    n = len(values)\n    total_value = np.sum(values)\n    fairness_index = 0\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                fairness_index += (values[i] / total_value) * (values[j] / total_value) * distances[i][j]\n\n    return fairness_index\n\n# Example usage\nvalues = np.array([10, 20, 30])\ndistances = np.array([[0, 5, 10], [5, 0, 15], [10, 15, 0]])\nresult = calculate_spatial_fairness_index(values, distances)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster flood risk map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\ndef generate_flood_risk_map(dem_path, output_path, flood_level):\n    dem_dataset = gdal.Open(dem_path)\n    geotransform = dem_dataset.GetGeoTransform()\n    projection = dem_dataset.GetProjection()\n    band = dem_dataset.GetRasterBand(1)\n    dem_array = band.ReadAsArray()\n\n    flood_risk = np.where(dem_array <= flood_level, 1, 0)\n\n    driver = gdal.GetDriverByName(\"GTiff\")\n    output_dataset = driver.Create(output_path, dem_dataset.RasterXSize, dem_dataset.RasterYSize, 1, gdal.GDT_Byte)\n    output_dataset.SetGeoTransform(geotransform)\n    output_dataset.SetProjection(projection)\n    output_band = output_dataset.GetRasterBand(1)\n    output_band.WriteArray(flood_risk)\n    output_band.FlushCache()\n\ndem_path = \"path_to_your_dem.tif\"\noutput_path = \"flood_risk_map.tif\"\nflood_level = 10.0\ngenerate_flood_risk_map(dem_path, output_path, flood_level)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial dialogue modeling.",
        "output": "Performing spatial dialogue modeling typically involves integrating GIS data with natural language processing (NLP) techniques. Below is an example of Python code that demonstrates a basic framework for spatial dialogue modeling using geopandas for spatial data handling and transformers for NLP.\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom transformers import pipeline\n\n# Load spatial data (example: GeoJSON file containing points of interest)\nspatial_data = gpd.read_file(\"points_of_interest.geojson\")\n\n# Define a function to find the nearest point of interest\ndef find_nearest_poi(user_location, spatial_data):\n    user_point = Point(user_location)\n    spatial_data['distance'] = spatial_data.geometry.distance(user_point)\n    nearest_poi = spatial_data.loc[spatial_data['distance'].idxmin()]\n    return nearest_poi\n\n# Initialize NLP model for dialogue understanding\nnlp_model = pipeline(\"question-answering\")\n\n# Example user input (location + question)\nuser_location = (-73.994454, 40.750042)  # Latitude and Longitude\nuser_question = \"What is the nearest park?\"\n\n# Find the nearest point of interest\nnearest_poi = find_nearest_poi(user_location, spatial_data)\n\n# Generate context from the nearest POI attributes\ncontext = f\"The nearest point of interest is {nearest_poi['name']} located at {nearest_poi.geometry}. It is a {nearest_poi['type']}.\"\n\n# Use NLP model to answer the user's question based on the context\nresponse = nlp_model(question=user_question, context=context)\n\n# Output the response\nprint(response['answer'])\n``` \n\nThis code assumes you have a GeoJSON file (`points_of_interest.geojson`) containing spatial data and uses a pre-trained NLP model for question-answering. Make sure to install the required libraries (`geopandas`, `transformers`, and `shapely`) before running the code."
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial legitimacy index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_legitimacy_index(weights, values):\n    normalized_weights = weights / np.sum(weights)\n    spatial_legitimacy_index = np.dot(normalized_weights, values)\n    return spatial_legitimacy_index\n\nweights = np.array([0.2, 0.3, 0.5])\nvalues = np.array([10, 20, 30])\n\nresult = calculate_spatial_legitimacy_index(weights, values)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex cooperation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    return combined_geom.convex_hull\n\n# Example usage:\ngeometries = [\n    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n    Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\n]\n\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial consensus building analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\n\n# Example input data: GeoDataFrames for different layers\nlayer1 = gpd.GeoDataFrame({\n    'id': [1, 2],\n    'geometry': [Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n                 Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])]\n})\n\nlayer2 = gpd.GeoDataFrame({\n    'id': [3, 4],\n    'geometry': [Polygon([(0.5, 0.5), (1.5, 0.5), (1.5, 1.5), (0.5, 1.5)]),\n                 Polygon([(1.5, 1.5), (2.5, 1.5), (2.5, 2.5), (1.5, 2.5)])]\n})\n\n# Perform intersection to find overlapping areas\nintersection = gpd.overlay(layer1, layer2, how='intersection')\n\n# Calculate consensus score based on area overlap\nintersection['area'] = intersection.geometry.area\nconsensus_score = intersection.groupby('id')['area'].sum()\n\nprint(consensus_score)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial solidarity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef spatial_solidarity_index(points, values, bandwidth):\n    distances = cdist(points, points)\n    weights = np.exp(-distances / bandwidth)\n    np.fill_diagonal(weights, 0)\n    weighted_values = weights.dot(values)\n    total_weights = weights.sum(axis=1)\n    weighted_values /= total_weights\n    solidarity_index = np.sum((values - weighted_values) ** 2) / len(values)\n    return solidarity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial transformations using dynamics.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef detect_spatial_transformations(points_before, points_after):\n    centroid_before = np.mean(points_before, axis=0)\n    centroid_after = np.mean(points_after, axis=0)\n    \n    centered_before = points_before - centroid_before\n    centered_after = points_after - centroid_after\n    \n    H = np.dot(centered_before.T, centered_after)\n    U, _, Vt = np.linalg.svd(H)\n    rotation_matrix = np.dot(Vt.T, U.T)\n    \n    if np.linalg.det(rotation_matrix) < 0:\n        Vt[-1, :] *= -1\n        rotation_matrix = np.dot(Vt.T, U.T)\n    \n    translation_vector = centroid_after - np.dot(rotation_matrix, centroid_before)\n    \n    return rotation_matrix, translation_vector\n\n# Example usage\npoints_before = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\npoints_after = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10]])\n\nrotation, translation = detect_spatial_transformations(points_before, points_after)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial mediation modeling.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom pysal.model.spreg import ML_Lag\n\ndef spatial_mediation_model(data, X, M, Y, W):\n    # Prepare data\n    X_data = data[X].values.reshape(-1, 1)\n    M_data = data[M].values.reshape(-1, 1)\n    Y_data = data[Y].values.reshape(-1, 1)\n\n    # Step 1: Regression of M on X\n    model_M_on_X = LinearRegression().fit(X_data, M_data)\n    M_pred = model_M_on_X.predict(X_data)\n\n    # Step 2: Spatial regression of Y on M and X\n    X_and_M = np.hstack([M_data, X_data])\n    model_Y_on_MX = ML_Lag(Y_data, X_and_M, w=W, name_y=Y, name_x=[M, X])\n\n    # Extract coefficients\n    coef_X_on_M = model_M_on_X.coef_[0][0]\n    coef_M_on_Y = model_Y_on_MX.betas[1][0]\n    coef_X_on_Y = model_Y_on_MX.betas[2][0]\n\n    # Calculate indirect and direct effects\n    indirect_effect = coef_X_on_M * coef_M_on_Y\n    direct_effect = coef_X_on_Y\n    total_effect = indirect_effect + direct_effect\n\n    return {\n        \"indirect_effect\": indirect_effect,\n        \"direct_effect\": direct_effect,\n        \"total_effect\": total_effect\n    }\n\n# Example usage:\n# Assuming `data` is a DataFrame, `W` is a spatial weights matrix, and columns 'X', 'M', 'Y' exist.\n# results = spatial_mediation_model(data, 'X', 'M', 'Y', W)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial ownership index.",
        "output": "```python\nimport geopandas as gpd\n\ndef calculate_spatial_ownership_index(ownership_data, area_of_interest):\n    ownership_gdf = gpd.GeoDataFrame(ownership_data)\n    aoi_gdf = gpd.GeoDataFrame(area_of_interest)\n    \n    intersection = gpd.overlay(ownership_gdf, aoi_gdf, how='intersection')\n    intersection['area'] = intersection.geometry.area\n    \n    total_area = aoi_gdf.geometry.area.sum()\n    intersection['ownership_ratio'] = intersection['area'] / total_area\n    \n    spatial_ownership_index = intersection.groupby('owner_id')['ownership_ratio'].sum()\n    return spatial_ownership_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster habitat suitability map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\n# Example parameters\ncell_size = 100\nx_min, x_max, y_min, y_max = 0, 1000, 0, 1000\nhabitat_factors = {\n    \"vegetation\": np.random.rand(10, 10),\n    \"water_distance\": np.random.rand(10, 10),\n    \"slope\": np.random.rand(10, 10)\n}\n\nweights = {\n    \"vegetation\": 0.5,\n    \"water_distance\": 0.3,\n    \"slope\": 0.2\n}\n\ndef calculate_suitability(factors, weights):\n    suitability = np.zeros_like(next(iter(factors.values())))\n    for factor, weight in weights.items():\n        suitability += factors[factor] * weight\n    return suitability\n\nsuitability_map = calculate_suitability(habitat_factors, weights)\n\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"habitat_suitability.tif\", \n                              suitability_map.shape[1], \n                              suitability_map.shape[0], \n                              1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform((x_min, cell_size, 0, y_max, 0, -cell_size))\noutput_band = output_raster.GetRasterBand(1)\noutput_band.WriteArray(suitability_map)\noutput_band.FlushCache()\noutput_band.SetNoDataValue(-9999)\noutput_raster.SetProjection(\"EPSG:4326\")\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial arbitration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Example: Load shapefile data\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to find which region each point falls into\nspatial_join = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Group by region and count points within each region\narbitration_analysis = spatial_join.groupby(\"region_id\").size().reset_index(name=\"point_count\")\n\nprint(arbitration_analysis)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial stewardship index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_stewardship_index(area_covered, total_area, conservation_effort):\n    if total_area <= 0:\n        raise ValueError(\"Total area must be greater than zero.\")\n    coverage_ratio = np.clip(area_covered / total_area, 0, 1)\n    effort_score = np.clip(conservation_effort, 0, 1)\n    stewardship_index = np.sqrt(coverage_ratio * effort_score)\n    return stewardship_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex engagement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    return combined_geom.convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reconciliation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Example: Load spatial data\nregions = gpd.read_file(\"regions.geojson\")\npoints = gpd.read_file(\"points.geojson\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform a spatial join to reconcile points within regions\nspatial_join = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Aggregate data (e.g., count points per region)\naggregated_data = spatial_join.groupby(\"region_id\").size().reset_index(name=\"point_count\")\n\n# Merge aggregated data back to the regions\nreconciled_regions = regions.merge(aggregated_data, on=\"region_id\", how=\"left\")\n\n# Fill NaN values for regions with no points\nreconciled_regions[\"point_count\"] = reconciled_regions[\"point_count\"].fillna(0)\n\n# Save the reconciled regions to a new file\nreconciled_regions.to_file(\"reconciled_regions.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial responsibility index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_responsibility_index(weights, distances):\n    normalized_weights = weights / np.sum(weights)\n    inverse_distances = 1 / distances\n    responsibility_scores = normalized_weights * inverse_distances\n    spatial_responsibility_index = np.sum(responsibility_scores)\n    return spatial_responsibility_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial innovations using trends.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef detect_spatial_innovations(data, threshold=0.05):\n    slopes = np.zeros_like(data)\n    p_values = np.zeros_like(data)\n    \n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            y = data[i, j, :]\n            x = np.arange(len(y))\n            slope, _, _, p_value, _ = linregress(x, y)\n            slopes[i, j] = slope\n            p_values[i, j] = p_value\n    \n    significant_trends = (p_values < threshold)\n    return slopes, significant_trends\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial facilitation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load the spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\n\n# Perform Local Moran's I analysis for spatial facilitation\nattribute = \"your_target_column\"\nlocal_moran = Moran_Local(data[attribute], w)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = local_moran.p_sim\ndata['Ivalue'] = local_moran.Is\n\n# Filter significant clusters (e.g., p-value < 0.05)\nsignificant_clusters = data[data['Isign'] < 0.05]\n\n# Save the results to a new shapefile\nsignificant_clusters.to_file(\"spatial_facilitation_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial sustainability index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_sustainability_index(data, weights):\n    normalized_data = data.apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_data = normalized_data.multiply(weights, axis=1)\n    sustainability_index = weighted_data.sum(axis=1)\n    return sustainability_index\n\n# Example usage:\ndata = pd.DataFrame({\n    'green_space': [30, 40, 50, 60],\n    'air_quality': [70, 80, 90, 100],\n    'transport_accessibility': [20, 30, 40, 50]\n})\nweights = pd.Series([0.4, 0.3, 0.3], index=['green_space', 'air_quality', 'transport_accessibility'])\n\nsustainability_index = calculate_spatial_sustainability_index(data, weights)\nprint(sustainability_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster land use change map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\n# Example: Generate two random land use rasters for time t1 and t2\nrows, cols = 500, 500\nland_use_t1 = np.random.randint(1, 6, size=(rows, cols))  # Land use classes at time t1\nland_use_t2 = np.random.randint(1, 6, size=(rows, cols))  # Land use classes at time t2\n\n# Calculate land use change\nchange_map = np.where(land_use_t1 == land_use_t2, 0, 1)  # 0: No change, 1: Change\n\n# Save the change map as a GeoTIFF\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"land_use_change_map.tif\", cols, rows, 1, gdal.GDT_Byte)\noutput_raster.SetGeoTransform((0, 1, 0, 0, 0, -1))  # Set geotransform (example values)\noutput_band = output_raster.GetRasterBand(1)\noutput_band.WriteArray(change_map)\noutput_band.FlushCache()\noutput_band.SetNoDataValue(255)\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial mentoring modeling.",
        "output": "It seems like you might be referring to \"spatial modeling\" instead of \"spatial mentoring modeling.\" If that's the case, here's an example of Python code for performing spatial modeling using the `geopandas` and `libpysal` libraries. This example demonstrates a basic spatial lag model:\n\n```python\nimport geopandas as gpd\nimport libpysal\nfrom libpysal.weights import Queen\nfrom spreg import ML_Lag\n\n# Load spatial data (replace with your dataset)\ndata = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Ensure the data is in a projected coordinate system for accurate spatial weights\ndata = data.to_crs(epsg=3857)\n\n# Create spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Row-standardize the weights\nweights.transform = 'r'\n\n# Prepare dependent and independent variables\ny = data['pop_est'].values.reshape(-1, 1)  # Replace 'pop_est' with your dependent variable\nX = data[['gdp_md_est']].values  # Replace 'gdp_md_est' with your independent variable(s)\n\n# Perform spatial lag modeling\nmodel = ML_Lag(y, X, w=weights)\n\n# Print model summary\nprint(model.summary)\n```\n\nMake sure you have the required libraries installed (`geopandas`, `libpysal`, and `spreg`) before running the code. If this isn't what you were looking for, please clarify further!"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial resilience capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_resilience_capacity(features, weights=None):\n    n = len(features)\n    if weights is None:\n        weights = np.ones(n)\n    dist_matrix = distance_matrix(features, features)\n    np.fill_diagonal(dist_matrix, 1e-10)\n    inverse_dist = 1 / dist_matrix\n    weighted_inverse = inverse_dist * weights[:, np.newaxis]\n    resilience_scores = np.sum(weighted_inverse, axis=1) / np.sum(weights)\n    return resilience_scores\n\n# Example usage\nfeatures = np.array([[34.05, -118.25], [40.71, -74.01], [51.51, -0.13]])\nweights = np.array([1, 2, 1])\nresilience_index = calculate_spatial_resilience_capacity(features, weights)\nprint(resilience_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex adaptation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_adaptation(geometries):\n    if isinstance(geometries, (Polygon, MultiPolygon)):\n        geometries = [geometries]\n    convex_parts = [geom.convex_hull for geom in geometries]\n    return unary_union(convex_parts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial coaching analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a point for spatial coaching analysis\npoint = Point(-73.994454, 40.750042)\n\n# Create a GeoDataFrame for the point\npoint_gdf = gpd.GeoDataFrame(geometry=[point], crs=data.crs)\n\n# Perform spatial join to find nearby features\njoined_data = gpd.sjoin(data, point_gdf, predicate=\"intersects\")\n\n# Output the results\nprint(joined_data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial adaptive capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_adaptive_capacity(data, weights):\n    normalized_data = data.apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_data = normalized_data.multiply(weights, axis=1)\n    adaptive_capacity_index = weighted_data.sum(axis=1)\n    return adaptive_capacity_index\n\n# Example usage:\ndata = pd.DataFrame({\n    'education': [50, 70, 60],\n    'income': [3000, 5000, 4000],\n    'infrastructure': [0.8, 0.9, 0.85]\n})\n\nweights = pd.Series([0.4, 0.3, 0.3], index=['education', 'income', 'infrastructure'])\n\nspatial_adaptive_capacity = calculate_spatial_adaptive_capacity(data, weights)\nprint(spatial_adaptive_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial transitions using trajectories.",
        "output": "```python\nimport numpy as np\nfrom sklearn.cluster import DBSCAN\n\ndef detect_spatial_transitions(trajectories, eps=0.5, min_samples=5):\n    all_points = np.vstack(trajectories)\n    dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(all_points)\n    labels = dbscan.labels_\n    \n    transitions = []\n    start = 0\n    \n    for traj in trajectories:\n        n_points = len(traj)\n        traj_labels = labels[start:start+n_points]\n        start += n_points\n        \n        for i in range(1, len(traj_labels)):\n            if traj_labels[i] != traj_labels[i-1]:\n                transitions.append((traj[i-1], traj[i]))\n    \n    return transitions\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial advocacy modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data is in a projected coordinate system for accurate measurements\nif data.crs.is_geographic:\n    data = data.to_crs(epsg=3857)\n\n# Extract coordinates for clustering\ncoords = data.geometry.centroid.apply(lambda p: [p.x, p.y]).tolist()\n\n# Perform KMeans clustering\nkmeans = KMeans(n_clusters=5, random_state=42).fit(coords)\ndata['cluster'] = kmeans.labels_\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(10, 10))\ndata.plot(column='cluster', ax=ax, legend=True, cmap='tab20')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial transformative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_transformative_capacity(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    index = np.sum(weighted_data, axis=1)\n    return index\n\n# Example usage:\ndata = np.array([[5, 10, 3], [8, 7, 6], [9, 5, 2]])\nweights = np.array([0.4, 0.3, 0.3])\nspatial_index = calculate_spatial_transformative_capacity(data, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster disaster risk reduction map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define parameters\nrows, cols = 500, 500\ncell_size = 30\nx_min, y_max = 500000, 6000000\nno_data_value = -9999\n\n# Generate synthetic data for disaster risk reduction factors\nelevation = np.random.uniform(0, 1000, (rows, cols))\npopulation_density = np.random.uniform(0, 1000, (rows, cols))\ninfrastructure_risk = np.random.uniform(0, 1, (rows, cols))\n\n# Combine factors into a composite risk index\nrisk_index = (elevation / 1000) * 0.4 + (population_density / 1000) * 0.3 + infrastructure_risk * 0.3\n\n# Normalize risk index to range [0, 1]\nrisk_index = (risk_index - np.min(risk_index)) / (np.max(risk_index) - np.min(risk_index))\n\n# Create geotransform\ngeotransform = (x_min, cell_size, 0, y_max, 0, -cell_size)\n\n# Create output raster\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"disaster_risk_map.tif\", cols, rows, 1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set projection (WGS84 UTM Zone 33N as an example)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(32633)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(risk_index)\nband.SetNoDataValue(no_data_value)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial counseling analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the shapefile or GeoJSON containing spatial data\nspatial_data = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Define a point geometry for spatial counseling (example coordinates)\npoint = Point(-73.994454, 40.750042)\n\n# Create a GeoDataFrame for the point\npoint_gdf = gpd.GeoDataFrame(geometry=[point], crs=spatial_data.crs)\n\n# Perform spatial join to find features intersecting with the point\nresult = gpd.sjoin(spatial_data, point_gdf, predicate=\"intersects\")\n\n# Display the result of the spatial counseling analysis\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial regenerative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_regenerative_capacity_index(land_use, vegetation_cover, soil_quality, weights):\n    normalized_land_use = land_use / np.max(land_use)\n    normalized_vegetation_cover = vegetation_cover / np.max(vegetation_cover)\n    normalized_soil_quality = soil_quality / np.max(soil_quality)\n    \n    weighted_sum = (weights['land_use'] * normalized_land_use +\n                    weights['vegetation_cover'] * normalized_vegetation_cover +\n                    weights['soil_quality'] * normalized_soil_quality)\n    \n    total_weight = sum(weights.values())\n    spatial_regenerative_capacity_index = weighted_sum / total_weight\n    \n    return spatial_regenerative_capacity_index\n\n# Example usage:\nland_use = np.array([50, 70, 60])\nvegetation_cover = np.array([80, 90, 75])\nsoil_quality = np.array([65, 85, 80])\nweights = {'land_use': 0.4, 'vegetation_cover': 0.3, 'soil_quality': 0.3}\n\nsrci = calculate_spatial_regenerative_capacity_index(land_use, vegetation_cover, soil_quality, weights)\nprint(srci)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex evolution of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_evolution(geometries):\n    convex_parts = []\n    for geometry in geometries:\n        if isinstance(geometry, Polygon):\n            convex_hull = geometry.convex_hull\n            convex_parts.append(convex_hull)\n        elif isinstance(geometry, MultiPoint):\n            convex_hull = geometry.convex_hull\n            convex_parts.append(convex_hull)\n    return unary_union(convex_parts)\n\n# Example usage\ngeometries = [\n    Polygon([(0, 0), (1, 1), (2, 0)]),\n    MultiPoint([(3, 3), (4, 4), (5, 3)])\n]\n\nresult = extract_convex_evolution(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial therapy modeling.",
        "output": "It seems like you might be referring to \"spatial stratified heterogeneity\" modeling, which is commonly analyzed using methods like Geodetector. Below is an example of Python code that performs spatial stratified heterogeneity analysis using the `geodetector` library:\n\n```python\nimport geodetector as gd\nimport pandas as pd\n\n# Load your dataset (replace 'data.csv' with your file path)\ndata = pd.read_csv('data.csv')\n\n# Ensure your data has a column for the dependent variable (Y) and independent variables (X)\nY = data['dependent_variable']\nX = data[['independent_var1', 'independent_var2']]\n\n# Perform factor detector to measure explanatory power of independent variables\nfactor_results = gd.factor_detector(Y, X)\n\n# Perform interaction detector to analyze interactions between variables\ninteraction_results = gd.interaction_detector(Y, X)\n\n# Print results\nprint(\"Factor Detector Results:\")\nprint(factor_results)\n\nprint(\"\\nInteraction Detector Results:\")\nprint(interaction_results)\n```\n\nMake sure to install the required library by running `pip install geodetector`. Replace `'data.csv'`, `'dependent_variable'`, `'independent_var1'`, and `'independent_var2'` with your actual dataset and variable names."
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial restorative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_restorative_capacity_index(land_use_scores, vegetation_density, accessibility_scores, weights):\n    land_use_scores = np.array(land_use_scores)\n    vegetation_density = np.array(vegetation_density)\n    accessibility_scores = np.array(accessibility_scores)\n    weights = np.array(weights)\n\n    if not (len(land_use_scores) == len(vegetation_density) == len(accessibility_scores) == len(weights)):\n        raise ValueError(\"Input arrays must have the same length\")\n\n    weighted_scores = (\n        weights[0] * land_use_scores +\n        weights[1] * vegetation_density +\n        weights[2] * accessibility_scores\n    )\n\n    spatial_restorative_capacity_index = np.mean(weighted_scores)\n\n    return spatial_restorative_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial shifts using gradients.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import gaussian_gradient_magnitude\n\ndef detect_spatial_shifts(data, sigma=1.0):\n    gradient_magnitude = gaussian_gradient_magnitude(data, sigma=sigma)\n    shifts = np.where(gradient_magnitude > np.mean(gradient_magnitude) + np.std(gradient_magnitude))\n    return shifts\n\n# Example usage\ndata = np.random.rand(100, 100)\nspatial_shifts = detect_spatial_shifts(data, sigma=2.0)\nprint(spatial_shifts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial intervention analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nintervention_areas = gpd.read_file(\"intervention_areas.shp\")\naffected_regions = gpd.read_file(\"affected_regions.shp\")\n\n# Ensure both datasets are in the same CRS\nintervention_areas = intervention_areas.to_crs(epsg=4326)\naffected_regions = affected_regions.to_crs(epsg=4326)\n\n# Perform spatial join to find intersections\nspatial_join = gpd.sjoin(affected_regions, intervention_areas, how=\"inner\", predicate=\"intersects\")\n\n# Calculate intersection areas\nspatial_join[\"intersection_area\"] = spatial_join.geometry.area\n\n# Aggregate results by intervention area\nsummary = spatial_join.groupby(\"id\").agg(total_affected_area=(\"intersection_area\", \"sum\")).reset_index()\n\n# Save results to a new shapefile\nsummary.to_file(\"spatial_intervention_analysis_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial generative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_generative_capacity_index(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    sgc_index = np.sum(weighted_data, axis=1)\n    return sgc_index\n\n# Example usage:\ndata = np.array([[5, 10], [2, 8], [7, 12]])\nweights = np.array([0.6, 0.4])\nsgc_index = calculate_spatial_generative_capacity_index(data, weights)\nprint(sgc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster climate change impact map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the climate data raster\nwith rasterio.open('climate_data.tif') as src:\n    climate_data = src.read(1)\n    profile = src.profile\n\n# Simulate an impact analysis (e.g., temperature increase effect)\nimpact_map = np.where(climate_data > 0, climate_data * 1.2, climate_data)\n\n# Update metadata for the new raster\nprofile.update(dtype=rasterio.float32)\n\n# Save the impact map as a new raster file\nwith rasterio.open('impact_map.tif', 'w', **profile) as dst:\n    dst.write(impact_map.astype(rasterio.float32), 1)\n\n# Visualize the impact map\nplt.figure(figsize=(10, 8))\nshow(impact_map, cmap='viridis', title='Climate Change Impact Map')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial healing modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Delaunay\nfrom sklearn.neighbors import NearestNeighbors\n\ndef spatial_healing_modeling(points, max_distance):\n    nbrs = NearestNeighbors(radius=max_distance).fit(points)\n    distances, indices = nbrs.radius_neighbors(points)\n    healed_points = []\n\n    for i, neighbors in enumerate(indices):\n        if len(neighbors) > 1:\n            neighbor_coords = points[neighbors]\n            avg_point = np.mean(neighbor_coords, axis=0)\n            healed_points.append(avg_point)\n        else:\n            healed_points.append(points[i])\n\n    return np.array(healed_points)\n\n# Example usage\npoints = np.random.rand(100, 2)\nmax_distance = 0.1\nhealed_points = spatial_healing_modeling(points, max_distance)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial innovative capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_innovative_capacity_index(data, innovation_vars, spatial_weights):\n    normalized_data = data[innovation_vars].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_scores = normalized_data.mul(spatial_weights, axis=1)\n    sic_index = weighted_scores.sum(axis=1)\n    return sic_index\n\n# Example usage:\n# Assuming `data` is a DataFrame with innovation variables and `spatial_weights` is a predefined weight matrix\n# innovation_vars = ['var1', 'var2', 'var3']\n# spatial_weights = [0.4, 0.3, 0.3]\n# sic_index = calculate_spatial_innovative_capacity_index(data, innovation_vars, spatial_weights)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex progression of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_progression(geometries):\n    convex_parts = []\n    for geom in geometries:\n        if isinstance(geom, (Polygon, MultiPolygon)):\n            convex_hull = geom.convex_hull\n            convex_parts.append(convex_hull)\n    return unary_union(convex_parts)\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(2, 2), (3, 3), (3, 2)])]\nresult = extract_convex_progression(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial recovery analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial recovery analysis\ndef spatial_recovery_analysis(data, target_geometry):\n    # Ensure the data is in the same CRS\n    data = data.to_crs(target_geometry.crs)\n    \n    # Perform spatial join to find intersections\n    joined_data = gpd.sjoin(data, target_geometry, how=\"inner\", predicate=\"intersects\")\n    \n    # Calculate recovery rate or other metrics if needed\n    recovery_rate = len(joined_data) / len(data)\n    \n    return recovery_rate, joined_data\n\n# Example usage\ntarget_area = gpd.GeoDataFrame(geometry=[Point(0, 0).buffer(1)], crs=\"EPSG:4326\")\nrecovery_rate, recovered_data = spatial_recovery_analysis(data, target_area)\n\nprint(f\"Recovery Rate: {recovery_rate}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial creative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_creative_capacity_index(density, diversity, accessibility):\n    weights = np.array([0.4, 0.3, 0.3])\n    indicators = np.array([density, diversity, accessibility])\n    normalized_indicators = (indicators - np.min(indicators)) / (np.max(indicators) - np.min(indicators))\n    spatial_creative_capacity_index = np.dot(normalized_indicators, weights)\n    return spatial_creative_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial movements using flows.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import LineString\n\n# Example data: origin-destination flows with coordinates\nflows_data = pd.DataFrame({\n    'origin_id': [1, 2, 3],\n    'dest_id': [2, 3, 1],\n    'origin_x': [10.0, 20.0, 30.0],\n    'origin_y': [10.0, 20.0, 30.0],\n    'dest_x': [20.0, 30.0, 10.0],\n    'dest_y': [20.0, 30.0, 10.0]\n})\n\n# Create LineString geometries for flows\nflows_data['geometry'] = flows_data.apply(\n    lambda row: LineString([(row['origin_x'], row['origin_y']), \n                            (row['dest_x'], row['dest_y'])]), axis=1)\n\n# Convert to GeoDataFrame\nflows_gdf = gpd.GeoDataFrame(flows_data, geometry='geometry')\n\n# Detect spatial movements by calculating flow lengths\nflows_gdf['flow_length'] = flows_gdf.length\n\n# Display the resulting GeoDataFrame\nprint(flows_gdf[['origin_id', 'dest_id', 'flow_length']])\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial rehabilitation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n\n# Load spatial data\ninput_data = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a valid CRS\ninput_data = input_data.to_crs(epsg=4326)\n\n# Create additional spatial features if necessary\ninput_data['centroid'] = input_data.geometry.centroid\ninput_data['area'] = input_data.geometry.area\n\n# Prepare features and target variable\nfeatures = ['area', 'additional_feature_1', 'additional_feature_2']\nX = input_data[features]\ny = input_data['target_variable']\n\n# Train a spatial rehabilitation model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X, y)\n\n# Predict using the trained model\ninput_data['predicted_value'] = model.predict(X)\n\n# Save results to a new shapefile\ninput_data.to_file(\"rehabilitation_model_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial productive capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_productive_capacity(locations, productivity_values, decay_factor):\n    dist_matrix = distance_matrix(locations, locations)\n    weight_matrix = np.exp(-decay_factor * dist_matrix)\n    productive_capacity_index = np.dot(weight_matrix, productivity_values) / np.sum(weight_matrix, axis=1)\n    return productive_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster biodiversity conservation map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define parameters\nrows, cols = 500, 500\ncell_size = 30\nx_min, y_max = 500000, 6000000\nnodata_value = -9999\n\n# Create biodiversity conservation values (random for demonstration)\nnp.random.seed(42)\nbiodiversity_data = np.random.uniform(0, 1, (rows, cols))\n\n# Create a GeoTIFF driver\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"biodiversity_conservation_map.tif\", cols, rows, 1, gdal.GDT_Float32)\n\n# Set geotransform and projection\ngeotransform = (x_min, cell_size, 0, y_max, 0, -cell_size)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set spatial reference (WGS84 UTM Zone 33N for example)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(32633)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to raster band and set nodata value\nband = output_raster.GetRasterBand(1)\nband.WriteArray(biodiversity_data)\nband.SetNoDataValue(nodata_value)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial restoration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\noriginal_data = gpd.read_file(\"original_data.shp\")\ndistorted_data = gpd.read_file(\"distorted_data.shp\")\n\n# Ensure both datasets are in the same CRS\noriginal_data = original_data.to_crs(epsg=4326)\ndistorted_data = distorted_data.to_crs(epsg=4326)\n\n# Perform spatial join to find nearest features\ndistorted_data['geometry'] = distorted_data.geometry.centroid\njoined_data = gpd.sjoin_nearest(distorted_data, original_data, how='left', distance_col=\"distance\")\n\n# Calculate restoration metrics\nrestoration_metrics = joined_data.groupby('id').agg({'distance': 'mean'}).reset_index()\nrestoration_metrics.rename(columns={'distance': 'avg_restoration_distance'}, inplace=True)\n\n# Save results\nrestoration_metrics.to_csv(\"restoration_analysis_results.csv\", index=False)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial constructive capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_constructive_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n\n    spatial_constructive_capacity = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_constructive_capacity\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex development of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef convex_hull_geometries(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    return multipoint.convex_hull\n\n# Example usage:\npoly1 = Polygon([(0, 0), (1, 1), (1, 0)])\npoly2 = Polygon([(1, 1), (2, 2), (2, 1)])\ngeometries = [poly1, poly2]\nconvex_hull = convex_hull_geometries(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial renewal modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nexisting_data = gpd.read_file(\"existing_data.shp\")\nnew_data = gpd.read_file(\"new_data.shp\")\n\n# Ensure both datasets are in the same CRS\nnew_data = new_data.to_crs(existing_data.crs)\n\n# Perform spatial join to find overlaps\njoined_data = gpd.sjoin(existing_data, new_data, how=\"inner\", predicate=\"intersects\")\n\n# Identify non-overlapping areas for renewal\nnon_overlapping = existing_data[~existing_data.index.isin(joined_data.index)]\n\n# Create centroids for non-overlapping areas\nnon_overlapping['centroid'] = non_overlapping.geometry.centroid\n\n# Save results to a new shapefile\nnon_overlapping.to_file(\"renewal_areas.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial effective capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_effective_capacity_index(capacity_matrix, distance_matrix, decay_factor):\n    weights = np.exp(-decay_factor * distance_matrix)\n    weighted_capacity = capacity_matrix * weights\n    total_weighted_capacity = np.sum(weighted_capacity, axis=1)\n    total_weights = np.sum(weights, axis=1)\n    effective_capacity_index = total_weighted_capacity / total_weights\n    return effective_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial expansions using frontiers.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS and geometry\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Select the variable of interest\nvariable = \"your_column_name\"\n\n# Calculate Local Moran's I\nlocal_moran = Moran_Local(data[variable], w)\n\n# Identify spatial frontiers (e.g., high-value clusters expanding into low-value areas)\ndata['local_moran_psim'] = local_moran.p_sim\ndata['local_moran_q'] = local_moran.q\n\n# Filter for significant frontiers (e.g., high-low or low-high transitions)\nfrontiers = data[(data['local_moran_psim'] < 0.05) & ((data['local_moran_q'] == 2) | (data['local_moran_q'] == 4))]\n\n# Save the frontier regions to a new shapefile\nfrontiers.to_file(\"spatial_frontiers.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial revitalization analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load the spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis\nattribute = \"your_target_column\"\nmoran_loc = Moran_Local(data[attribute], w)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = moran_loc.p_sim\ndata['Ivalue'] = moran_loc.Is\n\n# Filter significant clusters (e.g., p-value < 0.05)\nsignificant_clusters = data[data['Isign'] < 0.05]\n\n# Save the results to a new shapefile\nsignificant_clusters.to_file(\"spatial_revitalization_analysis_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial efficient capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_efficient_capacity_index(demand, capacity):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    if demand.shape != capacity.shape:\n        raise ValueError(\"Demand and capacity arrays must have the same shape.\")\n    utilization_ratio = demand / capacity\n    efficient_capacity_index = 1 - np.mean(np.abs(utilization_ratio - 1))\n    return efficient_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster ecosystem services map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\n\n# Example: Generating a synthetic ecosystem services map\ndef generate_ecosystem_services_map(output_path, width=500, height=500):\n    # Create a random raster representing ecosystem services\n    data = np.random.uniform(0, 1, (height, width)).astype(np.float32)\n    \n    # Define metadata for the raster\n    transform = rasterio.transform.from_origin(west=0, south=0, xsize=1, ysize=1)\n    meta = {\n        'driver': 'GTiff',\n        'height': height,\n        'width': width,\n        'count': 1,\n        'dtype': 'float32',\n        'crs': 'EPSG:4326',\n        'transform': transform\n    }\n    \n    # Write the raster to file\n    with rasterio.open(output_path, 'w', **meta) as dst:\n        dst.write(data, 1)\n\n# Generate the map and save it as a GeoTIFF\ngenerate_ecosystem_services_map('ecosystem_services_map.tif')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reclamation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import binary_erosion, binary_dilation\nimport rasterio\nfrom rasterio.transform import from_origin\n\ndef perform_spatial_reclamation(input_raster_path, output_raster_path, structure_size=3):\n    with rasterio.open(input_raster_path) as src:\n        data = src.read(1)\n        transform = src.transform\n        profile = src.profile\n\n    structure = np.ones((structure_size, structure_size))\n    reclaimed_area = binary_erosion(data, structure=structure)\n    reclaimed_area = binary_dilation(reclaimed_area, structure=structure)\n\n    profile.update(dtype=rasterio.uint8, count=1, compress='lzw')\n\n    with rasterio.open(output_raster_path, 'w', **profile) as dst:\n        dst.write(reclaimed_area.astype(rasterio.uint8), 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial resourceful capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_resourceful_capacity_index(resource_density, accessibility_score, weight_resource=0.5, weight_accessibility=0.5):\n    resource_density_normalized = (resource_density - np.min(resource_density)) / (np.max(resource_density) - np.min(resource_density))\n    accessibility_normalized = (accessibility_score - np.min(accessibility_score)) / (np.max(accessibility_score) - np.min(accessibility_score))\n    spatial_resourceful_capacity_index = weight_resource * resource_density_normalized + weight_accessibility * accessibility_normalized\n    return spatial_resourceful_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex enhancement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef convex_enhancement(geometries):\n    if isinstance(geometries, (Polygon, MultiPolygon)):\n        geometries = [geometries]\n    convex_geometries = [geom.convex_hull for geom in geometries]\n    return unary_union(convex_geometries)\n\n# Example usage:\n# polygons = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(2, 2), (3, 3), (3, 2)])]\n# result = convex_enhancement(polygons)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial regeneration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\nif data.crs.is_geographic:\n    data = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform spatial autocorrelation analysis (Moran's I)\nattribute = \"your_column_name\"\nmoran = Moran(data[attribute], w)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights, decay_factor=0.5):\n    dist_matrix = distance_matrix(points, points)\n    decay_matrix = np.exp(-decay_factor * dist_matrix)\n    interaction_matrix = decay_matrix * weights[:, np.newaxis]\n    strategic_capacity = np.sum(interaction_matrix, axis=1)\n    return strategic_capacity\n\n# Example usage\npoints = np.array([[0, 0], [1, 2], [3, 1]])\nweights = np.array([1.0, 2.0, 1.5])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial extensions using boundaries.",
        "output": "```python\nfrom shapely.geometry import Polygon, box\n\ndef detect_spatial_extensions(geometries, boundary):\n    boundary_polygon = Polygon(boundary)\n    extended_geometries = []\n    for geometry in geometries:\n        if geometry.intersects(boundary_polygon):\n            extended_geometries.append(geometry.intersection(boundary_polygon))\n    return extended_geometries\n\n# Example usage\ngeometries = [box(0, 0, 2, 2), box(3, 3, 5, 5)]\nboundary = [(1, 1), (4, 1), (4, 4), (1, 4)]\nresult = detect_spatial_extensions(geometries, boundary)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial redesign modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Load spatial data\ninput_data = gpd.read_file(\"input_shapefile.shp\")\n\n# Define a function for spatial redesign\ndef spatial_redesign(input_gdf, scale_factor=1.5):\n    redesigned_geometries = []\n    for geometry in input_gdf.geometry:\n        if isinstance(geometry, Polygon):\n            coords = list(geometry.exterior.coords)\n            scaled_coords = [(x * scale_factor, y * scale_factor) for x, y in coords]\n            redesigned_geometries.append(Polygon(scaled_coords))\n        elif isinstance(geometry, Point):\n            x, y = geometry.x, geometry.y\n            redesigned_geometries.append(Point(x * scale_factor, y * scale_factor))\n    return gpd.GeoDataFrame(geometry=redesigned_geometries, crs=input_gdf.crs)\n\n# Perform spatial redesign\noutput_data = spatial_redesign(input_data)\n\n# Save the output to a new shapefile\noutput_data.to_file(\"redesigned_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    tactical_capacity_index = np.sum(weighted_features, axis=1)\n    return tactical_capacity_index\n\n# Example usage\nfeatures = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights = np.array([0.5, 0.3, 0.2])\nresult = calculate_spatial_tactical_capacity(features, weights)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster environmental management map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample environmental data array\ndata = np.random.rand(500, 500) * 100\n\n# Define the spatial characteristics of the raster\ntransform = rasterio.transform.from_origin(west=0, south=0, xsize=10, ysize=10)\n\n# Write the data to a temporary in-memory raster file\nwith rasterio.open(\n    'environmental_map.tif',\n    'w',\n    driver='GTiff',\n    height=data.shape[0],\n    width=data.shape[1],\n    count=1,\n    dtype=data.dtype,\n    crs='+proj=latlong',\n    transform=transform,\n) as dst:\n    dst.write(data, 1)\n\n# Read and display the generated raster map\nwith rasterio.open('environmental_map.tif') as src:\n    show(src, cmap='viridis')\nplt.title(\"Environmental Management Map\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reorganization analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load the spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis for spatial reorganization\nattribute = \"your_attribute_column\"\nmoran_loc = Moran_Local(data[attribute], w)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = moran_loc.q\ndata['pvalue'] = moran_loc.p_sim\n\n# Filter significant clusters at p < 0.05\nsignificant_clusters = data[data['pvalue'] < 0.05]\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, capacity):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    if demand.shape != capacity.shape:\n        raise ValueError(\"Demand and capacity arrays must have the same shape.\")\n    soc_index = np.divide(capacity, demand, out=np.zeros_like(capacity, dtype=float), where=demand!=0)\n    return np.nan_to_num(soc_index, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Example usage:\ndemand_values = [100, 200, 0, 150]\ncapacity_values = [80, 250, 0, 300]\nsoc_index = calculate_spatial_operational_capacity_index(demand_values, capacity_values)\nprint(soc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex improvement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef convex_improvement(geometries):\n    if isinstance(geometries, (Polygon, MultiPolygon)):\n        geometries = [geometries]\n    convex_geometries = [geom.convex_hull for geom in geometries]\n    return unary_union(convex_geometries)\n\n# Example usage:\n# polygons = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(2, 2), (3, 3), (3, 2)])]\n# result = convex_improvement(polygons)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial restructuring modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Example: Load spatial data\ndata = gpd.read_file(\"input_data.shp\")\n\n# Perform spatial restructuring (e.g., dissolve by an attribute)\nrestructured_data = data.dissolve(by=\"category_column\")\n\n# Save the restructured spatial data to a new file\nrestructured_data.to_file(\"restructured_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    functional_capacity_index = np.sum(weighted_features, axis=1)\n    return functional_capacity_index\n\n# Example usage\nfeatures = np.array([[5, 10, 3], [8, 7, 6], [9, 5, 2]])\nweights = np.array([0.4, 0.3, 0.3])\nresult = calculate_spatial_functional_capacity(features, weights)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial enlargements using zones.",
        "output": "```python\nimport geopandas as gpd\n\nzones = gpd.read_file('zones.geojson')\ninitial_area = zones.geometry.area.sum()\n\nupdated_zones = zones.copy()\nupdated_zones['geometry'] = zones.buffer(100)  # Example buffer distance\nupdated_area = updated_zones.geometry.area.sum()\n\narea_difference = updated_area - initial_area\nprint(f\"Spatial enlargement detected: {area_difference} square units\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial realignment analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for realignment\ndef realign_geometry(geom, shift_x, shift_y):\n    if geom.geom_type == 'Point':\n        return Point(geom.x + shift_x, geom.y + shift_y)\n    elif geom.geom_type == 'Polygon':\n        return Polygon([(p[0] + shift_x, p[1] + shift_y) for p in geom.exterior.coords])\n    else:\n        raise ValueError(\"Unsupported geometry type\")\n\n# Apply realignment to each geometry\nshift_x, shift_y = 100, 200\ndata['realigned_geometry'] = data.geometry.apply(lambda geom: realign_geometry(geom, shift_x, shift_y))\n\n# Create a new GeoDataFrame with realigned geometries\nrealigned_data = gpd.GeoDataFrame(data, geometry='realigned_geometry')\n\n# Save the result to a new file\nrealigned_data.to_file(\"realigned_data.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, weights):\n    normalized_data = (structural_data - np.min(structural_data, axis=0)) / (np.max(structural_data, axis=0) - np.min(structural_data, axis=0))\n    weighted_data = normalized_data * weights\n    spatial_capacity_index = np.sum(weighted_data, axis=1)\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster natural resource planning map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample raster data for natural resource planning\ndata = np.random.randint(1, 6, size=(500, 500), dtype=np.uint8)\n\n# Define the profile for the raster (metadata)\nprofile = {\n    'driver': 'GTiff',\n    'height': data.shape[0],\n    'width': data.shape[1],\n    'count': 1,\n    'dtype': data.dtype,\n    'crs': 'EPSG:4326',\n    'transform': rasterio.transform.from_origin(-180, 90, 0.72, 0.72),\n    'nodata': 0\n}\n\n# Save the raster to a file\noutput_raster_path = 'natural_resource_map.tif'\nwith rasterio.open(output_raster_path, 'w', **profile) as dst:\n    dst.write(data, 1)\n\n# Plot the generated raster map\nwith rasterio.open(output_raster_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, cmap='viridis', title='Natural Resource Planning Map', ax=ax)\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reengineering modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"input_data.shp\")\n\n# Reproject to a suitable coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create new geometries or modify existing ones\ndata['new_geometry'] = data.apply(lambda row: Point(row.geometry.centroid.x + 1000, row.geometry.centroid.y + 1000), axis=1)\ndata = data.set_geometry('new_geometry')\n\n# Save the reengineered spatial data\ndata.to_file(\"reengineered_data.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(distance_matrix, flow_matrix):\n    n = distance_matrix.shape[0]\n    capacity_index = 0\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                capacity_index += flow_matrix[i, j] / distance_matrix[i, j]\n    \n    return capacity_index\n\n# Example usage\ndistance_matrix = np.array([[0, 10, 15], [10, 0, 20], [15, 20, 0]])\nflow_matrix = np.array([[0, 5, 3], [5, 0, 4], [3, 4, 0]])\n\nresult = calculate_spatial_organizational_capacity(distance_matrix, flow_matrix)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex advancement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    return combined_geom.convex_hull\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0, 0), (1, -1), (1, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reallocation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the source and target geometries\nsource_data = gpd.read_file(\"source_data.geojson\")\ntarget_data = gpd.read_file(\"target_data.geojson\")\n\n# Ensure both GeoDataFrames have the same CRS\nsource_data = source_data.to_crs(target_data.crs)\n\n# Spatial join to reallocate based on intersection\njoined_data = gpd.sjoin(source_data, target_data, how=\"inner\", predicate=\"intersects\")\n\n# Calculate area of intersection for proportional reallocation\njoined_data[\"intersection_area\"] = joined_data.geometry.intersection(joined_data.geometry_right).area\n\n# Aggregate values proportionally based on intersection area\nreallocation_results = (\n    joined_data.groupby(\"index_right\")\n    .apply(lambda x: (x[\"value_column\"] * x[\"intersection_area\"] / x[\"intersection_area\"].sum()).sum())\n    .reset_index(name=\"reallocated_value\")\n)\n\n# Merge results back to target geometries\ntarget_data = target_data.merge(reallocation_results, left_index=True, right_on=\"index_right\")\n\n# Save the output\ntarget_data.to_file(\"reallocation_output.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_scores = normalized_data.mul(spatial_weights, axis=0)\n    spatial_institutional_capacity_index = weighted_scores.sum(axis=1)\n    return spatial_institutional_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'institution_1': [5, 10, 15], 'institution_2': [20, 30, 40]})\n# capacity_columns = ['institution_1', 'institution_2']\n# spatial_weights = [0.6, 0.4]\n# index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial augmentations using buffers.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Example: Create a GeoDataFrame with sample points\ndata = {'name': ['Point A', 'Point B', 'Point C'],\n        'geometry': [Point(0, 0), Point(3, 3), Point(7, 7)]}\ngdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\")\n\n# Define buffer distance (e.g., in degrees for EPSG:4326)\nbuffer_distance = 1.0\n\n# Create buffers around geometries\ngdf['buffer'] = gdf.geometry.buffer(buffer_distance)\n\n# Check spatial augmentations by intersections\naugmented = gdf[gdf.intersects(gdf.unary_union)]\nprint(augmented)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial redistribution modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef spatial_redistribution_model(source_points, target_points, source_weights):\n    dist_matrix = distance_matrix(source_points, target_points)\n    dist_matrix[dist_matrix == 0] = 1e-10\n    inverse_dist = 1 / dist_matrix\n    redistribution_weights = inverse_dist / inverse_dist.sum(axis=0)\n    redistributed_values = np.dot(source_weights, redistribution_weights)\n    return redistributed_values\n\n# Example usage:\nsource_points = np.array([[0, 0], [1, 1], [2, 2]])\ntarget_points = np.array([[1, 0], [2, 1]])\nsource_weights = np.array([10, 20, 30])\n\nresult = spatial_redistribution_model(source_points, target_points, source_weights)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(density, connectivity, accessibility):\n    density_weight = 0.4\n    connectivity_weight = 0.3\n    accessibility_weight = 0.3\n\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_connectivity = (connectivity - np.min(connectivity)) / (np.max(connectivity) - np.min(connectivity))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n\n    spatial_systemic_capacity_index = (\n        density_weight * normalized_density +\n        connectivity_weight * normalized_connectivity +\n        accessibility_weight * normalized_accessibility\n    )\n\n    return spatial_systemic_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster water resource management map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample raster data for water resource management\ndata = np.random.rand(500, 500) * 100  # Random values representing water resources\ntransform = rasterio.transform.from_origin(west=0, south=0, xsize=10, ysize=10)\n\n# Define the metadata for the raster\nmeta = {\n    'driver': 'GTiff',\n    'height': data.shape[0],\n    'width': data.shape[1],\n    'count': 1,\n    'dtype': data.dtype,\n    'crs': 'EPSG:4326',\n    'transform': transform\n}\n\n# Save the raster to a file\noutput_raster_path = 'water_resource_map.tif'\nwith rasterio.open(output_raster_path, 'w', **meta) as dst:\n    dst.write(data, 1)\n\n# Plot the generated raster map\nwith rasterio.open(output_raster_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, cmap='Blues', title='Water Resource Management Map', ax=ax)\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reconfiguration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom libpysal.weights import Queen\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system for accurate analysis\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform spatial reconfiguration analysis (e.g., spatial lag calculation)\ndata['spatial_lag'] = weights.lag_spatial(data['attribute_column'])\n\n# Save results to a new shapefile\ndata.to_file(\"spatial_reconfiguration_analysis_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    \n    spatial_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex refinement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef convex_refinement(geometries):\n    if isinstance(geometries, (Polygon, MultiPolygon)):\n        geometries = [geometries]\n    convex_parts = []\n    for geom in geometries:\n        if isinstance(geom, Polygon):\n            convex_parts.append(geom.convex_hull)\n        elif isinstance(geom, MultiPolygon):\n            for polygon in geom.geoms:\n                convex_parts.append(polygon.convex_hull)\n    return unary_union(convex_parts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial relocation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef spatial_relocation_model(initial_locations, attraction_factors, distance_matrix, alpha=1.0, beta=1.0):\n    num_locations = len(initial_locations)\n    def objective_function(new_locations_flat):\n        new_locations = new_locations_flat.reshape((num_locations, 2))\n        total_cost = 0.0\n        for i in range(num_locations):\n            for j in range(num_locations):\n                if i != j:\n                    dist = np.linalg.norm(new_locations[i] - new_locations[j])\n                    total_cost += attraction_factors[i][j] * (distance_matrix[i][j] - dist)**2\n        return total_cost\n\n    constraints = []\n    for i in range(num_locations):\n        constraints.append({'type': 'ineq', 'fun': lambda x, idx=i: x[idx*2]**2 + x[idx*2+1]**2 - 1e-6})\n    \n    initial_guess = initial_locations.flatten()\n    result = minimize(objective_function, initial_guess, method='SLSQP', constraints=constraints)\n    optimized_locations = result.x.reshape((num_locations, 2))\n    return optimized_locations\n\n# Example usage\ninitial_locations = np.array([[0, 0], [1, 1], [2, 2]])\nattraction_factors = np.array([[0, 2, 3], [2, 0, 4], [3, 4, 0]])\ndistance_matrix = np.array([[0, 1.414, 2.828], [1.414, 0, 1.414], [2.828, 1.414, 0]])\n\noptimized_locations = spatial_relocation_model(initial_locations, attraction_factors, distance_matrix)\nprint(optimized_locations)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n\n# Example usage:\ndata = np.array([[5, 10], [2, 8], [7, 12]])\nweights = np.array([0.6, 0.4])\nsmci_values = calculate_spatial_methodological_capacity_index(data, weights)\nprint(smci_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial additions using offsets.",
        "output": "```python\nimport geopandas as gpd\n\ndef detect_spatial_additions(original_gdf, updated_gdf, offset_tolerance):\n    original_buffered = original_gdf.buffer(offset_tolerance)\n    additions = updated_gdf[~updated_gdf.intersects(original_buffered.unary_union)]\n    return additions\n\n# Example usage:\n# original_data = gpd.read_file(\"original.shp\")\n# updated_data = gpd.read_file(\"updated.shp\")\n# offset_tolerance = 10  # in the units of the CRS\n# new_additions = detect_spatial_additions(original_data, updated_data, offset_tolerance)\n# print(new_additions)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial replacement analysis.",
        "output": "```python\nimport geopandas as gpd\n\n# Load the spatial data\ntarget_area = gpd.read_file('target_area.shp')\nreplacement_areas = gpd.read_file('replacement_areas.shp')\n\n# Ensure the coordinate reference systems (CRS) match\ntarget_area = target_area.to_crs(replacement_areas.crs)\n\n# Perform spatial overlay to find replacement areas within the target area\noverlay_result = gpd.overlay(target_area, replacement_areas, how='intersection')\n\n# Calculate the area of intersection\noverlay_result['intersection_area'] = overlay_result.geometry.area\n\n# Summarize total intersection area per replacement area\nsummary = overlay_result.groupby('replacement_id')['intersection_area'].sum().reset_index()\n\n# Identify fully replaced areas\nfully_replaced = summary[summary['intersection_area'] >= target_area.geometry.area.values[0]]\n\n# Save results to a new shapefile\nfully_replaced.to_file('fully_replaced_areas.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial technical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_technical_capacity_index(density, accessibility, efficiency):\n    weights = np.array([0.4, 0.3, 0.3])\n    normalized_density = density / np.max(density)\n    normalized_accessibility = accessibility / np.max(accessibility)\n    normalized_efficiency = efficiency / np.max(efficiency)\n    normalized_matrix = np.array([normalized_density, normalized_accessibility, normalized_efficiency])\n    spatial_tech_capacity_index = np.dot(weights, normalized_matrix)\n    return spatial_tech_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster agricultural planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define raster dimensions and geotransform\nrows, cols = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create an empty raster array with random values for agricultural suitability\ndata = np.random.randint(1, 6, size=(rows, cols))\n\n# Create a new raster file\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"agricultural_planning_map.tif\", cols, rows, 1, gdal.GDT_Byte)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set projection to WGS84\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to the raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(data)\nband.SetNoDataValue(0)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial renovation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Load spatial data\noriginal_data = gpd.read_file(\"original_data.shp\")\nrenovation_data = gpd.read_file(\"renovation_data.shp\")\n\n# Ensure both datasets are in the same CRS\noriginal_data = original_data.to_crs(epsg=4326)\nrenovation_data = renovation_data.to_crs(epsg=4326)\n\n# Perform spatial join to identify overlaps\njoined_data = gpd.sjoin(original_data, renovation_data, how=\"inner\", predicate=\"intersects\")\n\n# Calculate renovation impact area\njoined_data[\"impact_area\"] = joined_data.geometry.area\n\n# Summarize total renovation impact\ntotal_impact = joined_data[\"impact_area\"].sum()\n\n# Export results to a new shapefile\njoined_data.to_file(\"renovation_impact.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial analytical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_analytical_capacity(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    capacity_index = np.sum(weighted_data, axis=1)\n    return capacity_index\n\n# Example usage\ndata = np.array([[5, 10, 3], [8, 7, 6], [9, 4, 2]])\nweights = np.array([0.5, 0.3, 0.2])\nresult = calculate_spatial_analytical_capacity(data, weights)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex sophistication of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_sophistication(geometries):\n    if isinstance(geometries, (Polygon, MultiPolygon)):\n        convex_hull = geometries.convex_hull\n        return convex_hull\n    else:\n        raise TypeError(\"Input must be a Shapely Polygon or MultiPolygon.\")\n\n# Example usage\npolygon = Polygon([(0, 0), (1, 1), (1, 0)])\nconvex_result = extract_convex_sophistication(polygon)\nprint(convex_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial resettlement analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data for analysis\nsettlements = gpd.read_file(\"settlements.shp\")\nconstraints = gpd.read_file(\"constraints.shp\")\n\n# Ensure both datasets are in the same CRS\nsettlements = settlements.to_crs(constraints.crs)\n\n# Perform spatial join to identify resettlement areas\nresettlement_areas = gpd.sjoin(settlements, constraints, how=\"inner\", predicate=\"intersects\")\n\n# Filter out invalid resettlement options based on specific criteria\nvalid_resettlement = resettlement_areas[resettlement_areas['suitability_score'] > 50]\n\n# Save the results to a new shapefile\nvalid_resettlement.to_file(\"valid_resettlement_areas.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial diagnostic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_diagnostic_capacity(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    diagnostic_index = np.sum(weighted_data, axis=1)\n    return diagnostic_index\n\n# Example usage:\ndata = np.array([[5, 3, 8], [7, 6, 9], [2, 4, 5]])\nweights = np.array([0.5, 0.3, 0.2])\nspatial_diagnostic_index = calculate_spatial_diagnostic_capacity(data, weights)\nprint(spatial_diagnostic_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial increments using margins.",
        "output": "```python\nimport numpy as np\n\ndef detect_spatial_increments(margins):\n    increments = np.diff(margins)\n    return increments\n\nmargins = [0, 10, 25, 50, 75, 100]\nspatial_increments = detect_spatial_increments(margins)\nprint(spatial_increments)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial redevelopment modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nimport pandas as pd\n\n# Load spatial data\nexisting_land_use = gpd.read_file(\"existing_land_use.shp\")\nproposed_development = gpd.read_file(\"proposed_development.shp\")\n\n# Ensure both datasets are in the same CRS\nexisting_land_use = existing_land_use.to_crs(epsg=4326)\nproposed_development = proposed_development.to_crs(epsg=4326)\n\n# Perform spatial join to identify overlaps\noverlap_analysis = gpd.overlay(existing_land_use, proposed_development, how='intersection')\n\n# Calculate area of overlap\noverlap_analysis['overlap_area'] = overlap_analysis.geometry.area\n\n# Identify non-overlapping areas for redevelopment\nnon_overlap = gpd.overlay(existing_land_use, proposed_development, how='difference')\n\n# Export results to new shapefiles\noverlap_analysis.to_file(\"overlap_analysis_result.shp\")\nnon_overlap.to_file(\"redevelopment_opportunities.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial evaluative capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_evaluative_capacity_index(weights, values):\n    normalized_weights = weights / np.sum(weights)\n    normalized_values = values / np.max(values)\n    spatial_index = np.dot(normalized_weights, normalized_values)\n    return spatial_index\n\nweights = np.array([0.2, 0.3, 0.5])\nvalues = np.array([10, 20, 30])\n\nspatial_index = calculate_spatial_evaluative_capacity_index(weights, values)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster urban planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\ndef create_urban_planning_raster(output_path, width, height, geotransform, projection, urban_data):\n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, width, height, 1, gdal.GDT_Byte)\n    dataset.SetGeoTransform(geotransform)\n    dataset.SetProjection(projection)\n    band = dataset.GetRasterBand(1)\n    band.WriteArray(urban_data)\n    band.FlushCache()\n    dataset = None\n\nwidth = 500\nheight = 500\ngeotransform = (300000.0, 10.0, 0.0, 4200000.0, 0.0, -10.0)\nprojection = osr.SpatialReference()\nprojection.ImportFromEPSG(32633)\nurban_data = np.random.randint(0, 2, (height, width), dtype=np.uint8)\n\ncreate_urban_planning_raster(\"urban_planning_map.tif\", width, height, geotransform, projection.ExportToWkt(), urban_data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reconstruction analysis.",
        "output": "```python\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom scipy.spatial.distance import cdist\n\ndef spatial_reconstruction_analysis(data, n_components=2):\n    pca = PCA(n_components=n_components)\n    reduced_data = pca.fit_transform(data)\n    reconstructed_data = pca.inverse_transform(reduced_data)\n    reconstruction_error = np.mean(cdist(data, reconstructed_data, metric='euclidean'))\n    return reduced_data, reconstructed_data, reconstruction_error\n\n# Example usage\ndata = np.random.rand(100, 5)  # Replace with your spatial data\nreduced, reconstructed, error = spatial_reconstruction_analysis(data)\nprint(\"Reconstruction Error:\", error)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial predictive capacity index.",
        "output": "```python\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef calculate_spatial_predictive_capacity(y_true, y_pred):\n    auc = roc_auc_score(y_true, y_pred)\n    return auc\n\n# Example usage:\ny_true = np.array([0, 1, 1, 0, 1])\ny_pred = np.array([0.1, 0.9, 0.8, 0.3, 0.7])\nspatial_predictive_capacity = calculate_spatial_predictive_capacity(y_true, y_pred)\nprint(spatial_predictive_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex elaboration of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geometry = unary_union(geometries)\n    convex_hull = combined_geometry.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull_result = extract_convex_hull(geometries)\nprint(convex_hull_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial rehabilitation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n\n# Load spatial data\ninput_data = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a valid CRS\ninput_data = input_data.to_crs(epsg=4326)\n\n# Create geometries if necessary\ninput_data['geometry'] = input_data.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n\n# Define features and target variable\nfeatures = ['elevation', 'slope', 'aspect', 'land_cover']\nX = input_data[features]\ny = input_data['rehab_potential']\n\n# Handle missing values if any\nX = X.fillna(0)\n\n# Train a Random Forest model for spatial rehabilitation modeling\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X, y)\n\n# Predict rehabilitation potential\ninput_data['predicted_rehab'] = model.predict(X)\n\n# Save results to a new shapefile\ninput_data.to_file(\"rehabilitation_model_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial prescriptive capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_prescriptive_capacity_index(demand, capacity, weights=None):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    \n    if weights is None:\n        weights = np.ones_like(demand)\n    else:\n        weights = np.array(weights)\n    \n    weighted_demand = demand * weights\n    total_weighted_demand = np.sum(weighted_demand)\n    total_capacity = np.sum(capacity)\n    \n    if total_capacity == 0:\n        return 0\n    \n    spatial_prescriptive_capacity_index = total_weighted_demand / total_capacity\n    return spatial_prescriptive_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial expansions using perimeters.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\n\ndef detect_spatial_expansions(initial_geometry, expanded_geometry):\n    initial_perimeter = initial_geometry.length\n    expanded_perimeter = expanded_geometry.length\n    perimeter_change = expanded_perimeter - initial_perimeter\n    return perimeter_change\n\n# Example usage\ninitial_polygon = Polygon([(0, 0), (0, 1), (1, 1), (1, 0)])\nexpanded_polygon = Polygon([(0, 0), (0, 2), (2, 2), (2, 0)])\n\ninitial_gdf = gpd.GeoDataFrame(index=[0], crs=\"EPSG:4326\", geometry=[initial_polygon])\nexpanded_gdf = gpd.GeoDataFrame(index=[0], crs=\"EPSG:4326\", geometry=[expanded_polygon])\n\nperimeter_change = detect_spatial_expansions(initial_gdf.geometry[0], expanded_gdf.geometry[0])\nprint(perimeter_change)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial repurposing analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\nexisting_land_use = gpd.read_file(\"existing_land_use.shp\")\npotential_sites = gpd.read_file(\"potential_sites.shp\")\n\n# Ensure both datasets are in the same CRS\npotential_sites = potential_sites.to_crs(existing_land_use.crs)\n\n# Define a buffer radius for proximity analysis (e.g., 1000 meters)\nbuffer_radius = 1000\n\n# Perform spatial overlay to find suitable areas\nsuitable_areas = gpd.overlay(existing_land_use, potential_sites, how=\"intersection\")\n\n# Add a buffer around existing land use to exclude nearby areas\nbuffered_existing = existing_land_use.copy()\nbuffered_existing[\"geometry\"] = existing_land_use.buffer(buffer_radius)\n\n# Exclude buffered areas from potential sites\nexcluded_areas = gpd.overlay(potential_sites, buffered_existing, how=\"difference\")\n\n# Calculate area of each remaining potential site\nexcluded_areas[\"area\"] = excluded_areas.geometry.area\n\n# Filter sites based on minimum area requirement (e.g., 5000 square meters)\nmin_area = 5000\nfiltered_sites = excluded_areas[excluded_areas[\"area\"] >= min_area]\n\n# Save results to a new shapefile\nfiltered_sites.to_file(\"repurposed_sites.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial descriptive capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_descriptive_capacity(data, weights=None):\n    data = np.array(data)\n    if weights is None:\n        weights = np.ones_like(data)\n    else:\n        weights = np.array(weights)\n    weighted_sum = np.sum(data * weights)\n    total_weight = np.sum(weights)\n    return weighted_sum / total_weight if total_weight != 0 else 0\n\n# Example usage:\ndata_values = [10, 20, 30, 40]\nweights = [1, 2, 3, 4]\nspatial_index = calculate_spatial_descriptive_capacity(data_values, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster transportation planning map.",
        "output": "```python\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import rasterize\nimport matplotlib.pyplot as plt\n\n# Load vector data for transportation planning (e.g., roads, railways)\ntransport_data = gpd.read_file(\"transportation_data.shp\")\n\n# Define the raster dimensions and resolution\nraster_width = 1000\nraster_height = 1000\ntransform = rasterio.transform.from_bounds(west=0, south=0, east=100, north=100, width=raster_width, height=raster_height)\n\n# Rasterize the vector data\nshapes = ((geom, value) for geom, value in zip(transport_data.geometry, transport_data['value']))\nraster = rasterize(shapes, out_shape=(raster_height, raster_width), transform=transform)\n\n# Plot the resulting raster map\nplt.imshow(raster, cmap='viridis')\nplt.colorbar(label='Transportation Value')\nplt.title('Transportation Planning Map')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial retrofitting modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom scipy.spatial import Voronoi\nimport numpy as np\n\n# Load spatial data\ninput_data = gpd.read_file(\"input_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\nif input_data.crs.is_geographic:\n    input_data = input_data.to_crs(epsg=3857)\n\n# Extract geometries and convert to centroids if polygons\ncentroids = input_data.geometry.centroid\ncoords = np.array([(pt.x, pt.y) for pt in centroids])\n\n# Compute Voronoi diagram\nvor = Voronoi(coords)\n\n# Convert Voronoi regions to Polygons\nregions = []\nfor region in vor.regions:\n    if not -1 in region and len(region) > 0:\n        polygon = Polygon([vor.vertices[i] for i in region])\n        regions.append(polygon)\n\n# Create GeoDataFrame for Voronoi polygons\nvoronoi_gdf = gpd.GeoDataFrame(geometry=regions, crs=input_data.crs)\n\n# Perform intersection with original data boundaries\nclipped_voronoi = gpd.overlay(voronoi_gdf, input_data, how='intersection')\n\n# Save output\nclipped_voronoi.to_file(\"retrofitted_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial explanatory capacity index.",
        "output": "```python\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef calculate_spatial_explanatory_capacity(X, y):\n    model = LinearRegression()\n    model.fit(X, y)\n    r_squared = model.score(X, y)\n    return r_squared\n\n# Example usage:\n# X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n# y = np.array([2, 3, 4, 5])\n# sec_index = calculate_spatial_explanatory_capacity(X, y)\n# print(sec_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex enrichment of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef convex_enrichment(geometries):\n    if not geometries:\n        return None\n    union_geom = unary_union(geometries)\n    return union_geom.convex_hull\n\n# Example usage\ngeometries = [\n    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n    Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\n]\n\nresult = convex_enrichment(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reclamation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the input data (replace 'input_data.shp' with your file path)\ninput_data = gpd.read_file('input_data.shp')\n\n# Define a function for spatial reclamation analysis\ndef perform_spatial_reclamation(data, threshold_area):\n    # Calculate the area of each polygon\n    data['area'] = data.geometry.area\n    \n    # Identify polygons below the threshold area\n    reclaimed = data[data['area'] < threshold_area]\n    \n    # Create centroids for reclaimed areas\n    reclaimed_centroids = reclaimed.geometry.centroid\n    \n    # Convert centroids to GeoDataFrame\n    reclaimed_points = gpd.GeoDataFrame(geometry=reclaimed_centroids, crs=data.crs)\n    \n    return reclaimed_points\n\n# Perform spatial reclamation analysis (set your threshold area here)\nthreshold = 1000  # Example threshold in square meters\nreclaimed_areas = perform_spatial_reclamation(input_data, threshold)\n\n# Save the result to a new shapefile (replace 'output.shp' with your desired output path)\nreclaimed_areas.to_file('output.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial interpretive capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_interpretive_capacity(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    sic_index = np.sum(weighted_data, axis=1)\n    return sic_index\n\n# Example usage\ndata = np.array([[5, 3, 8], [7, 6, 9], [2, 4, 5]])\nweights = np.array([0.5, 0.3, 0.2])\nsic_values = calculate_spatial_interpretive_capacity(data, weights)\nprint(sic_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial augmentations using areas.",
        "output": "```python\nimport geopandas as gpd\n\ndef detect_spatial_augmentations(primary_area, augmented_area):\n    primary_gdf = gpd.GeoDataFrame([primary_area], columns=['geometry'])\n    augmented_gdf = gpd.GeoDataFrame([augmented_area], columns=['geometry'])\n    \n    intersection = gpd.overlay(primary_gdf, augmented_gdf, how='intersection')\n    difference = gpd.overlay(augmented_gdf, primary_gdf, how='difference')\n    \n    return intersection, difference\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial revitalization modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\nfrom pysal.viz.splot.esda import plot_moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform spatial autocorrelation analysis (Moran's I)\nattribute = \"your_target_column\"\nmoran = Moran(data[attribute], w)\n\n# Plot Moran's I\nplot_moran(moran, zstandard=True)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial inferential capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_spatial_inferential_capacity(data_points, k=5):\n    distances = cdist(data_points, data_points, metric='euclidean')\n    nearest_neighbors = np.argsort(distances, axis=1)[:, 1:k+1]\n    avg_distances = np.mean(distances[np.arange(len(data_points))[:, None], nearest_neighbors], axis=1)\n    sic_index = np.mean(avg_distances)\n    return sic_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster energy planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\ndef generate_energy_planning_map(output_path, x_size, y_size, geotransform, projection):\n    data = np.random.rand(y_size, x_size) * 100\n    \n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, x_size, y_size, 1, gdal.GDT_Float32)\n    \n    dataset.SetGeoTransform(geotransform)\n    dataset.SetProjection(projection)\n    \n    band = dataset.GetRasterBand(1)\n    band.WriteArray(data)\n    band.FlushCache()\n    \n    dataset = None\n\noutput_path = \"energy_planning_map.tif\"\nx_size = 500\ny_size = 500\ngeotransform = (0, 0.001, 0, 0, 0, -0.001)\nprojection = osr.SpatialReference()\nprojection.ImportFromEPSG(4326)\nprojection = projection.ExportToWkt()\n\ngenerate_energy_planning_map(output_path, x_size, y_size, geotransform, projection)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reintegration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial reintegration analysis\ndef spatial_reintegration_analysis(data, threshold_distance):\n    data['reintegrated'] = False\n    for idx, row in data.iterrows():\n        if not row['reintegrated']:\n            # Buffer around the current geometry\n            buffer_region = row['geometry'].buffer(threshold_distance)\n            # Find all features within the buffer\n            within_buffer = data[data.geometry.within(buffer_region)]\n            # Mark them as reintegrated\n            data.loc[within_buffer.index, 'reintegrated'] = True\n    return data\n\n# Perform the analysis with a specified threshold distance (e.g., 1000 meters)\nthreshold = 1000\nresult = spatial_reintegration_analysis(data, threshold)\n\n# Save the results to a new shapefile\nresult.to_file(\"reintegrated_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial exploratory capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_exploratory_capacity(distances, decay_factor):\n    weights = np.exp(-decay_factor * distances)\n    normalized_weights = weights / np.sum(weights)\n    exploratory_capacity_index = np.sum(normalized_weights * distances)\n    return exploratory_capacity_index\n\n# Example usage\ndistances = np.array([1.0, 2.0, 3.0, 4.0])\ndecay_factor = 0.5\nsec_index = calculate_spatial_exploratory_capacity(distances, decay_factor)\nprint(sec_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex augmentation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_augmentation(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage\ngeometries = [\n    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n    Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\n]\n\nresult = extract_convex_augmentation(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reinvigoration modeling.",
        "output": "Performing spatial reinvigoration modeling typically involves geospatial analysis and may include tasks like spatial interpolation, clustering, or simulating spatial processes. Below is an example of Python code that demonstrates a basic spatial reinvigoration model using geospatial data and common libraries such as `geopandas`, `rasterio`, and `scipy`. This example assumes you want to simulate a process where certain areas are \"reinvigorated\" based on proximity to specific points (e.g., urban centers or resource locations).\n\n```python\nimport geopandas as gpd\nimport numpy as np\nfrom scipy.spatial import cKDTree\nfrom shapely.geometry import Point\n\n# Load geospatial data (e.g., shapefile with regions)\nregions = gpd.read_file(\"regions.shp\")\n\n# Define points of interest (e.g., urban centers or resource locations)\npoints_of_interest = gpd.GeoDataFrame({\n    \"geometry\": [Point(10, 20), Point(30, 40), Point(50, 60)]\n}, crs=\"EPSG:4326\")\n\n# Reproject data to a suitable CRS for distance calculations\nregions = regions.to_crs(\"EPSG:3857\")\npoints_of_interest = points_of_interest.to_crs(\"EPSG:3857\")\n\n# Extract coordinates for KDTree\npoi_coords = np.array([(geom.x, geom.y) for geom in points_of_interest.geometry])\nregion_coords = np.array([(geom.centroid.x, geom.centroid.y) for geom in regions.geometry])\n\n# Build KDTree for efficient nearest neighbor search\ntree = cKDTree(poi_coords)\n\n# Find the nearest point of interest for each region\ndistances, indices = tree.query(region_coords)\n\n# Add distance and nearest point information to the regions GeoDataFrame\nregions[\"nearest_poi_distance\"] = distances\nregions[\"nearest_poi_index\"] = indices\n\n# Define a reinvigoration function (e.g., inverse distance weighting)\ndef reinvigoration_score(distance, max_distance=100000):\n    return max(0, 1 - distance / max_distance)\n\n# Apply the reinvigoration function\nregions[\"reinvigoration_score\"] = regions[\"nearest_poi_distance\"].apply(reinvigoration_score)\n\n# Save the results to a new shapefile\nregions.to_file(\"reinvigorated_regions.shp\")\n```\n\nThis code performs the following"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial confirmatory capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_confirmatory_capacity(data, weights):\n    normalized_data = data / np.sum(data, axis=0)\n    weighted_data = normalized_data * weights\n    spatial_index = np.sum(weighted_data, axis=1)\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial enhancements using volumes.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef detect_spatial_enhancements(volume, kernel_size=3):\n    kernel = np.ones((kernel_size, kernel_size, kernel_size)) / (kernel_size ** 3)\n    smoothed_volume = convolve(volume, kernel, mode='reflect')\n    enhancement_map = np.abs(volume - smoothed_volume)\n    return enhancement_map\n\n# Example usage\nvolume_data = np.random.rand(64, 64, 64)  # Replace with actual volume data\nenhancements = detect_spatial_enhancements(volume_data)\nprint(enhancements.shape)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial rejuvenation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial rejuvenation analysis\ndef spatial_rejuvenation_analysis(data, threshold_distance):\n    data['rejuvenated'] = False\n    for idx, row in data.iterrows():\n        point = row.geometry\n        neighbors = data[data.geometry.distance(point) <= threshold_distance]\n        if len(neighbors) > 1:\n            data.at[idx, 'rejuvenated'] = True\n    return data\n\n# Perform the analysis with a specified threshold distance\nthreshold = 500  # Example threshold in meters\nresult = spatial_rejuvenation_analysis(data, threshold)\n\n# Save the results to a new shapefile\nresult.to_file(\"rejuvenated_data.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial validation capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_validation_capacity(weights, values):\n    normalized_weights = weights / np.sum(weights)\n    capacity_index = np.sum(normalized_weights * values)\n    return capacity_index\n\nweights = np.array([0.1, 0.2, 0.3, 0.4])\nvalues = np.array([10, 20, 30, 40])\n\nspatial_validation_capacity_index = calculate_spatial_validation_capacity(weights, values)\nprint(spatial_validation_capacity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster disaster management map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a sample raster data for disaster management\ndata = np.random.randint(1, 6, size=(500, 500), dtype=np.uint8)\n\n# Define disaster categories (1: Low Risk, 2: Moderate Risk, 3: High Risk, 4: Very High Risk, 5: Extreme Risk)\ndisaster_risk_levels = {\n    1: \"Low Risk\",\n    2: \"Moderate Risk\",\n    3: \"High Risk\",\n    4: \"Very High Risk\",\n    5: \"Extreme Risk\"\n}\n\n# Save the raster file\nwith rasterio.open(\n    \"disaster_map.tif\",\n    'w',\n    driver='GTiff',\n    height=data.shape[0],\n    width=data.shape[1],\n    count=1,\n    dtype=data.dtype,\n    crs='+proj=latlong',\n    transform=rasterio.transform.from_origin(72.0, 24.0, 0.001, 0.001)  # Example geotransform\n) as dst:\n    dst.write(data, 1)\n\n# Plot the disaster management map\nwith rasterio.open(\"disaster_map.tif\") as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, ax=ax, title=\"Disaster Management Map\", cmap='viridis')\n    plt.colorbar(plt.cm.ScalarMappable(cmap='viridis'), ax=ax, label=\"Risk Levels\")\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reinforcement modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom scipy.spatial import Voronoi\nimport numpy as np\n\n# Load spatial data\npoints = gpd.read_file('points.shp')\npolygons = gpd.read_file('polygons.shp')\n\n# Extract coordinates for Voronoi\ncoords = points.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n\n# Compute Voronoi diagram\nvor = Voronoi(coords)\n\n# Convert Voronoi regions to polygons\nvoronoi_polygons = []\nfor region in vor.regions:\n    if not -1 in region and len(region) > 0:\n        polygon = Polygon([vor.vertices[i] for i in region])\n        voronoi_polygons.append(polygon)\n\n# Create GeoDataFrame for Voronoi polygons\nvoronoi_gdf = gpd.GeoDataFrame(geometry=voronoi_polygons, crs=points.crs)\n\n# Perform spatial join between Voronoi polygons and original polygons\nreinforced_model = gpd.sjoin(voronoi_gdf, polygons, how='inner', predicate='intersects')\n\n# Save the result\nreinforced_model.to_file('reinforced_model.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial verification capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_verification_capacity_index(observed, predicted, threshold):\n    observed = np.array(observed)\n    predicted = np.array(predicted)\n    \n    hits = np.sum((observed >= threshold) & (predicted >= threshold))\n    misses = np.sum((observed >= threshold) & (predicted < threshold))\n    false_alarms = np.sum((observed < threshold) & (predicted >= threshold))\n    correct_negatives = np.sum((observed < threshold) & (predicted < threshold))\n    \n    total = hits + misses + false_alarms + correct_negatives\n    accuracy = (hits + correct_negatives) / total if total > 0 else 0\n    return accuracy\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex amplification of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_amplification(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n              Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])]\n\nresult = extract_convex_amplification(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reactivation analysis.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef spatial_reactivation_analysis(reference_positions, test_positions, reference_activity, test_activity, distance_threshold):\n    # Compute pairwise distances between reference and test positions\n    distances = cdist(reference_positions, test_positions, metric='euclidean')\n    \n    # Find indices where distances are below the threshold\n    close_pairs = np.where(distances < distance_threshold)\n    \n    # Extract corresponding activities for close pairs\n    ref_activities = reference_activity[close_pairs[0]]\n    test_activities = test_activity[close_pairs[1]]\n    \n    # Compute correlation between reference and test activities\n    correlation_matrix = np.corrcoef(ref_activities, test_activities)\n    correlation_score = correlation_matrix[0, 1]\n    \n    return correlation_score\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial calibration capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_calibration_capacity(predictions, observations, weights=None):\n    if len(predictions) != len(observations):\n        raise ValueError(\"Predictions and observations must have the same length.\")\n    \n    if weights is None:\n        weights = np.ones_like(predictions)\n    else:\n        weights = np.array(weights)\n        if len(weights) != len(predictions):\n            raise ValueError(\"Weights must have the same length as predictions and observations.\")\n    \n    weighted_predictions = predictions * weights\n    weighted_observations = observations * weights\n    \n    total_weight = np.sum(weights)\n    weighted_mean_prediction = np.sum(weighted_predictions) / total_weight\n    weighted_mean_observation = np.sum(weighted_observations) / total_weight\n    \n    numerator = np.sum(weights * (predictions - weighted_mean_prediction) * (observations - weighted_mean_observation))\n    denominator_pred = np.sqrt(np.sum(weights * (predictions - weighted_mean_prediction)**2))\n    denominator_obs = np.sqrt(np.sum(weights * (observations - weighted_mean_observation)**2))\n    \n    calibration_capacity_index = numerator / (denominator_pred * denominator_obs)\n    return calibration_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial intensifications using densities.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef detect_spatial_intensifications(points, radius):\n    tree = cKDTree(points)\n    counts = tree.query_ball_point(points, r=radius, return_length=True)\n    density = counts / (np.pi * radius**2)\n    return density\n\n# Example usage\npoints = np.random.rand(100, 2)  # Replace with actual point data\nradius = 0.1\ndensities = detect_spatial_intensifications(points, radius)\nprint(densities)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial reestablishment modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef objective_function(params, observed_data, model_function):\n    predicted_data = model_function(params)\n    residuals = observed_data - predicted_data\n    return np.sum(residuals**2)\n\ndef spatial_reestablishment_model(observed_data, initial_params, model_function):\n    result = minimize(objective_function, initial_params, args=(observed_data, model_function), method='BFGS')\n    return result.x\n\n# Example usage:\n# Define your model function, observed data, and initial parameters here\n# model_function = lambda params: params[0] * np.exp(-params[1] * x_data)\n# observed_data = np.array([...])\n# initial_params = np.array([1.0, 0.1])\n\n# optimal_params = spatial_reestablishment_model(observed_data, initial_params, model_function)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial standardization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_standardization_capacity(data, weights):\n    weighted_data = data * weights\n    weighted_mean = np.sum(weighted_data) / np.sum(weights)\n    weighted_variance = np.sum(weights * (data - weighted_mean) ** 2) / np.sum(weights)\n    standardized_capacity_index = np.sqrt(weighted_variance)\n    return standardized_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster public health planning map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample raster data for public health planning\ndata = np.random.randint(1, 10, size=(500, 500))\n\n# Define the transform (top-left x, pixel width, rotation, top-left y, rotation, pixel height)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=1, ysize=1)\n\n# Define the CRS (Coordinate Reference System) - WGS84\ncrs = \"EPSG:4326\"\n\n# Write the raster to a file\nwith rasterio.open(\n    \"public_health_map.tif\",\n    \"w\",\n    driver=\"GTiff\",\n    height=data.shape[0],\n    width=data.shape[1],\n    count=1,\n    dtype=data.dtype,\n    crs=crs,\n    transform=transform,\n) as dst:\n    dst.write(data, 1)\n\n# Read and display the generated raster map\nwith rasterio.open(\"public_health_map.tif\") as src:\n    show(src, cmap=\"viridis\")\nplt.title(\"Public Health Planning Map\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial normalization analysis.",
        "output": "```python\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef spatial_normalization(data):\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    pca = PCA(n_components=2)\n    normalized_data = pca.fit_transform(scaled_data)\n    return normalized_data\n\n# Example usage\ndata = np.random.rand(100, 5)  # Replace with your spatial data\nnormalized_result = spatial_normalization(data)\nprint(normalized_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial harmonization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_harmonization_capacity(data, weights=None):\n    data = np.array(data)\n    if weights is None:\n        weights = np.ones_like(data)\n    else:\n        weights = np.array(weights)\n    weighted_sum = np.sum(data * weights)\n    total_weight = np.sum(weights)\n    return weighted_sum / total_weight if total_weight != 0 else 0\n\n# Example usage\ndata = [10, 20, 30, 40]\nweights = [1, 2, 3, 4]\nindex = calculate_spatial_harmonization_capacity(data, weights)\nprint(index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex escalation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined = unary_union(geometries)\n    return combined.convex_hull\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial stabilization modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef spatial_stabilization_model(data, initial_params):\n    def objective_function(params):\n        alpha, beta = params\n        residuals = data[:, 1] - (alpha * data[:, 0] + beta)\n        return np.sum(residuals**2)\n\n    result = minimize(objective_function, initial_params, method='BFGS')\n    return result.x\n\n# Example usage\ndata = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\ninitial_params = [1.0, 1.0]\noptimal_params = spatial_stabilization_model(data, initial_params)\nprint(optimal_params)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial synchronization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_synchronization_capacity(data, weights=None):\n    data = np.array(data)\n    if weights is None:\n        weights = np.ones_like(data)\n    else:\n        weights = np.array(weights)\n    weighted_data = data * weights\n    total_weight = np.sum(weights)\n    synchronization_index = np.sum(weighted_data) / total_weight\n    return synchronization_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial accelerations using rates.",
        "output": "```python\nimport numpy as np\n\ndef detect_spatial_accelerations(velocities, time_steps):\n    accelerations = np.diff(velocities, axis=0) / np.diff(time_steps)\n    return accelerations\n\n# Example usage\nvelocities = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\ntime_steps = np.array([0, 1, 2])\naccelerations = detect_spatial_accelerations(velocities, time_steps)\nprint(accelerations)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial regularization analysis.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom sklearn.linear_model import Ridge\n\ndef spatial_regularization_analysis(data, target, alpha=1.0, gamma=0.1):\n    n_samples = data.shape[0]\n    distance_matrix = cdist(data, data, metric='euclidean')\n    spatial_weights = np.exp(-gamma * distance_matrix)\n    np.fill_diagonal(spatial_weights, 0)\n    \n    W = spatial_weights / spatial_weights.sum(axis=1, keepdims=True)\n    X_reg = np.hstack([data, W.dot(data)])\n    model = Ridge(alpha=alpha)\n    model.fit(X_reg, target)\n    return model.coef_, model.intercept_\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial optimization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_optimization_capacity_index(demand, supply, distance_matrix):\n    total_demand = np.sum(demand)\n    total_supply = np.sum(supply)\n    \n    if total_supply == 0:\n        return 0\n    \n    weighted_distances = np.dot(distance_matrix, demand)\n    capacity_index = total_supply / (total_demand * weighted_distances.sum())\n    return capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster education planning map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample raster data for education planning\ndata = np.random.randint(1, 10, size=(500, 500))\n\n# Define the transform (top-left corner, resolution, etc.)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=10, ysize=10)\n\n# Define the CRS (Coordinate Reference System) - WGS84\ncrs = {'init': 'epsg:4326'}\n\n# Write the raster to a file\nwith rasterio.open('education_planning_map.tif', 'w', driver='GTiff',\n                   height=data.shape[0], width=data.shape[1],\n                   count=1, dtype=data.dtype,\n                   crs=crs, transform=transform) as dst:\n    dst.write(data, 1)\n\n# Read and display the generated raster map\nwith rasterio.open('education_planning_map.tif') as src:\n    show(src, cmap='viridis')\n\nplt.title(\"Education Planning Map\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial rationalization modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data is in a projected coordinate system\nif data.crs.is_geographic:\n    data = data.to_crs(epsg=3857)\n\n# Create a buffer around geometries\nbuffer_distance = 1000  # in meters\ndata[\"buffer\"] = data.geometry.buffer(buffer_distance)\n\n# Perform spatial join to find overlaps\nspatial_join = gpd.sjoin(data, data, how=\"inner\", predicate=\"intersects\")\n\n# Filter out self-intersections\nrationalized_data = spatial_join[spatial_join.index_left != spatial_join.index_right]\n\n# Export the rationalized data\nrationalized_data.to_file(\"rationalized_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial maximization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_maximization_capacity(density, accessibility, weights):\n    weighted_density = density * weights[0]\n    weighted_accessibility = accessibility * weights[1]\n    smci = np.maximum(weighted_density, weighted_accessibility)\n    return smci\n\ndensity = np.array([50, 30, 20, 10])\naccessibility = np.array([10, 25, 35, 40])\nweights = [0.6, 0.4]\n\nspatial_maximization_capacity_index = calculate_spatial_maximization_capacity(density, accessibility, weights)\nprint(spatial_maximization_capacity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex multiplication of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon\nfrom shapely.ops import unary_union\n\ndef convex_multiplication(geometries):\n    if not geometries:\n        return None\n    union_geom = unary_union(geometries)\n    return union_geom.convex_hull\n\n# Example usage\npoly1 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\npoly2 = Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\nresult = convex_multiplication([poly1, poly2])\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial economization analysis.",
        "output": "```python\nimport geopandas as gpd\nimport libpysal\nfrom esda.moran import Moran\nfrom pysal.explore import esda\nfrom pysal.lib import weights\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system for accurate distance-based analysis\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix (e.g., Queen contiguity)\nw = libpysal.weights.Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Define the variable of interest\nvariable = \"your_column_name\"\n\n# Perform Moran's I test for spatial autocorrelation\nmoran = Moran(data[variable], w)\n\n# Print results\nprint(f\"Moran's I: {moran.I}\")\nprint(f\"p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial minimization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_minimization_capacity(density, distance_matrix):\n    total_density = np.sum(density)\n    weighted_distances = np.dot(distance_matrix, density)\n    smci = np.sum(weighted_distances) / total_density\n    return smci\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial expansions using scales.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter\n\ndef detect_spatial_expansions(data, scales):\n    filtered_data = [gaussian_filter(data, sigma=scale) for scale in scales]\n    expansion_maps = [filtered_data[i+1] - filtered_data[i] for i in range(len(scales)-1)]\n    return expansion_maps\n\n# Example usage\ndata = np.random.rand(100, 100)\nscales = [1, 2, 4, 8]\nexpansion_maps = detect_spatial_expansions(data, scales)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial streamlining modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString\n\ndef spatial_streamline_modeling(input_data, tolerance=0.01):\n    gdf = gpd.GeoDataFrame(input_data)\n    simplified_geometries = gdf.geometry.simplify(tolerance)\n    streamlined_gdf = gpd.GeoDataFrame(geometry=simplified_geometries, crs=gdf.crs)\n    return streamlined_gdf\n\n# Example usage:\ndata = {'geometry': [LineString([(0, 0), (1, 1), (2, 2)]), LineString([(0, 0), (1, 0), (2, 0)])]}\ninput_gdf = gpd.GeoDataFrame(data)\nresult = spatial_streamline_modeling(input_gdf, tolerance=0.5)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial prioritization capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_prioritization_capacity(density, accessibility, vulnerability):\n    normalized_density = density / np.max(density)\n    normalized_accessibility = accessibility / np.max(accessibility)\n    normalized_vulnerability = vulnerability / np.max(vulnerability)\n    \n    spatial_prioritization_index = (0.4 * normalized_density +\n                                    0.3 * normalized_accessibility +\n                                    0.3 * normalized_vulnerability)\n    \n    return spatial_prioritization_index\n\n# Example usage\ndensity = np.array([10, 20, 30, 40])\naccessibility = np.array([5, 15, 25, 35])\nvulnerability = np.array([8, 16, 24, 32])\n\nspi = calculate_spatial_prioritization_capacity(density, accessibility, vulnerability)\nprint(spi)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster housing planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\ndef create_housing_planning_raster(output_path, width, height, geotransform, projection, data):\n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, width, height, 1, gdal.GDT_Byte)\n    dataset.SetGeoTransform(geotransform)\n    dataset.SetProjection(projection)\n    dataset.GetRasterBand(1).WriteArray(data)\n    dataset.FlushCache()\n    dataset = None\n\nwidth = 500\nheight = 500\ndata = np.random.randint(0, 2, (height, width), dtype=np.uint8)\ngeotransform = (100000, 10, 0, 500000, 0, -10)\nprojection = osr.SpatialReference()\nprojection.ImportFromEPSG(32633)\nprojection = projection.ExportToWkt()\n\ncreate_housing_planning_raster(\"housing_plan.tif\", width, height, geotransform, projection, data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial sequencing analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create spatial weights matrix\nweights = Queen.from_dataframe(data)\n\n# Perform Local Moran's I analysis\nattribute = \"your_target_column\"\nmoran_local = Moran_Local(data[attribute], weights)\n\n# Add results to GeoDataFrame\ndata['Isignificance'] = moran_local.p_sim\ndata['Ivalue'] = moran_local.Is\n\n# Filter significant clusters\nsignificant_clusters = data[data['Isignificance'] < 0.05]\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial scheduling capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_scheduling_capacity_index(demand_matrix, supply_matrix):\n    demand = np.array(demand_matrix)\n    supply = np.array(supply_matrix)\n    if demand.shape != supply.shape:\n        raise ValueError(\"Demand and supply matrices must have the same shape.\")\n    capacity_index = np.divide(supply, demand, out=np.zeros_like(supply, dtype=float), where=demand!=0)\n    return capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex expansion of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef convex_expansion(geometries):\n    merged = unary_union(geometries)\n    if isinstance(merged, (Polygon, MultiPolygon)):\n        return merged.convex_hull\n    else:\n        raise ValueError(\"Input geometries must be Polygon or MultiPolygon types.\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial phasing modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Delaunay\nfrom sklearn.neighbors import NearestNeighbors\n\ndef spatial_phasing_modeling(points, values, k_neighbors=5):\n    tri = Delaunay(points)\n    nbrs = NearestNeighbors(n_neighbors=k_neighbors, algorithm='ball_tree').fit(points)\n    distances, indices = nbrs.kneighbors(points)\n    \n    phased_values = np.zeros(len(values))\n    for i in range(len(points)):\n        local_points = points[indices[i]]\n        local_values = values[indices[i]]\n        weights = 1 / (distances[i] + 1e-8)\n        weights /= weights.sum()\n        phased_values[i] = np.dot(weights, local_values)\n    \n    return phased_values\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial timing capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_timing_capacity(events, time_intervals):\n    event_counts = np.histogram(events, bins=time_intervals)[0]\n    total_events = np.sum(event_counts)\n    probabilities = event_counts / total_events\n    capacity_index = -np.sum(probabilities * np.log2(probabilities + 1e-10))\n    return capacity_index\n\n# Example usage\nevents = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\ntime_intervals = [0, 3, 6, 9, 12]\nspatial_timing_capacity = calculate_spatial_timing_capacity(events, time_intervals)\nprint(spatial_timing_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial developments using trends.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\nfrom scipy.stats import linregress\n\n# Example: Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a time component and geometry\ndata['time'] = pd.to_datetime(data['time'])\ndata = data.sort_values(by='time')\n\n# Group by unique spatial identifiers (e.g., location ID)\ngrouped = data.groupby('location_id')\n\n# Function to calculate trends for each group\ndef calculate_trend(group):\n    if len(group) < 2:\n        return None\n    slope, intercept, r_value, p_value, std_err = linregress(range(len(group)), group['value'])\n    return pd.Series({'slope': slope, 'p_value': p_value})\n\n# Apply trend analysis\ntrends = grouped.apply(calculate_trend).reset_index()\n\n# Merge trends back to original GeoDataFrame\nresult = data.merge(trends, on='location_id', how='left')\n\n# Filter significant trends (e.g., p-value < 0.05)\nsignificant_trends = result[result['p_value'] < 0.05]\n\n# Save results to a new shapefile\nsignificant_trends.to_file(\"significant_trends.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial staging analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial staging analysis\ndef spatial_staging_analysis(data, stage_column, geometry_column):\n    stages = data[stage_column].unique()\n    results = {}\n    \n    for stage in stages:\n        subset = data[data[stage_column] == stage]\n        union_geom = subset[geometry_column].unary_union\n        results[stage] = union_geom\n    \n    return results\n\n# Perform spatial staging analysis\nstages_result = spatial_staging_analysis(data, \"stage\", \"geometry\")\n\n# Save results to individual shapefiles\nfor stage, geometry in stages_result.items():\n    gdf = gpd.GeoDataFrame(geometry=[geometry], crs=data.crs)\n    gdf.to_file(f\"stage_{stage}.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial pacing capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_pacing_capacity(distances, time_intervals):\n    if len(distances) != len(time_intervals):\n        raise ValueError(\"Distances and time intervals must have the same length.\")\n    \n    pacing_capacities = []\n    for i in range(len(distances)):\n        if time_intervals[i] <= 0:\n            raise ValueError(\"Time intervals must be greater than zero.\")\n        pacing_capacity = distances[i] / time_intervals[i]\n        pacing_capacities.append(pacing_capacity)\n    \n    spatial_pacing_capacity_index = np.mean(pacing_capacities)\n    return spatial_pacing_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster tourism planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\n# Define raster dimensions and geotransform\ncols, rows = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create a random tourism score array\ntourism_score = np.random.uniform(low=0.0, high=100.0, size=(rows, cols))\n\n# Create output raster\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"tourism_map.tif\", cols, rows, 1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set projection (WGS84)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(tourism_score)\nband.SetNoDataValue(-9999)\nband.FlushCache()\n\n# Cleanup\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial progression modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom sklearn.cluster import KMeans\n\ndef spatial_progression_modeling(data, n_clusters=5, max_iterations=100):\n    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iterations)\n    labels = kmeans.fit_predict(data)\n    centroids = kmeans.cluster_centers_\n    \n    dist_mat = distance_matrix(data, centroids)\n    progression_scores = np.min(dist_mat, axis=1)\n    \n    return labels, progression_scores, centroids\n\n# Example usage:\nif __name__ == \"__main__\":\n    sample_data = np.random.rand(100, 2)  # Replace with actual spatial data\n    labels, scores, centroids = spatial_progression_modeling(sample_data)\n    print(\"Cluster Labels:\", labels)\n    print(\"Progression Scores:\", scores)\n    print(\"Centroids:\", centroids)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial sequencing capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_sequencing_capacity(locations, distances):\n    n = len(locations)\n    capacity_matrix = np.zeros((n, n))\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                capacity_matrix[i][j] = 1 / (distances[i][j] ** 2)\n    \n    sequencing_capacity_index = np.sum(capacity_matrix, axis=1)\n    return sequencing_capacity_index\n\n# Example usage\nlocations = ['Loc1', 'Loc2', 'Loc3']\ndistances = [\n    [0, 2, 5],\n    [2, 0, 3],\n    [5, 3, 0]\n]\n\nresult = calculate_spatial_sequencing_capacity(locations, distances)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex evolution of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef convex_evolution(geometries):\n    convex_hulls = [geom.convex_hull for geom in geometries]\n    unioned = unary_union(convex_hulls)\n    return unioned.convex_hull\n\n# Example usage\ngeometries = [\n    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n    Polygon([(0.5, 0.5), (1.5, 0.5), (1.5, 1.5), (0.5, 1.5)])\n]\n\nresult = convex_evolution(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial maturation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis\nattribute = \"maturation_rate\"\nmoran_loc = Moran_Local(data[attribute], w)\n\n# Add results to GeoDataFrame\ndata['Isign'] = moran_loc.p_sim\ndata['Ivalue'] = moran_loc.Is\n\n# Save results to a new shapefile\ndata.to_file(\"spatial_maturation_analysis_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial lifecycle capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_lifecycle_capacity_index(capacity_matrix, demand_matrix):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    normalized_demand = demand_matrix / np.max(demand_matrix)\n    lifecycle_capacity_index = np.sum(normalized_capacity - normalized_demand, axis=0) / normalized_capacity.shape[0]\n    return lifecycle_capacity_index\n\n# Example usage:\ncapacity_matrix = np.array([[10, 20, 30], [15, 25, 35], [20, 30, 40]])\ndemand_matrix = np.array([[5, 10, 15], [10, 20, 25], [15, 25, 35]])\n\nresult = calculate_spatial_lifecycle_capacity_index(capacity_matrix, demand_matrix)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial transformations using dynamics.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef detect_spatial_transformations(points_before, points_after):\n    centroid_before = np.mean(points_before, axis=0)\n    centroid_after = np.mean(points_after, axis=0)\n    \n    centered_before = points_before - centroid_before\n    centered_after = points_after - centroid_after\n    \n    H = np.dot(centered_before.T, centered_after)\n    U, _, Vt = np.linalg.svd(H)\n    rotation_matrix = np.dot(Vt.T, U.T)\n    \n    if np.linalg.det(rotation_matrix) < 0:\n        Vt[-1, :] *= -1\n        rotation_matrix = np.dot(Vt.T, U.T)\n    \n    translation_vector = centroid_after - np.dot(rotation_matrix, centroid_before)\n    \n    return rotation_matrix, translation_vector\n\n# Example usage\npoints_before = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\npoints_after = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10]])\n\nrotation, translation = detect_spatial_transformations(points_before, points_after)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial transition modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef spatial_transition_modeling(initial_state, transition_rules, iterations):\n    kernel = np.array([[1, 1, 1],\n                       [1, 0, 1],\n                       [1, 1, 1]])\n    \n    current_state = initial_state.copy()\n    \n    for _ in range(iterations):\n        neighbor_sum = convolve(current_state, kernel, mode='constant', cval=0)\n        next_state = transition_rules(current_state, neighbor_sum)\n        current_state = next_state\n    \n    return current_state\n\n# Example usage:\ninitial_state = np.random.choice([0, 1], size=(10, 10))\ntransition_rules = lambda state, neighbors: (neighbors == 3) | (state & (neighbors == 2))\nresult = spatial_transition_modeling(initial_state, transition_rules, 5)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial trajectory capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_trajectory_capacity(trajectory_points, area_size):\n    num_points = len(trajectory_points)\n    if num_points < 2:\n        return 0.0\n    \n    total_distance = 0.0\n    for i in range(1, num_points):\n        dx = trajectory_points[i][0] - trajectory_points[i-1][0]\n        dy = trajectory_points[i][1] - trajectory_points[i-1][1]\n        total_distance += np.sqrt(dx**2 + dy**2)\n    \n    capacity_index = total_distance / (area_size * np.sqrt(num_points))\n    return capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster cultural heritage map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample raster data for cultural heritage map\nrows, cols = 500, 500\ncultural_heritage_data = np.random.randint(0, 100, size=(rows, cols), dtype=np.uint8)\n\n# Define the transform (top-left corner, pixel size, etc.)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=10, ysize=10)\n\n# Define the CRS (Coordinate Reference System) - WGS84 in this case\ncrs = 'EPSG:4326'\n\n# Write the raster to a file\noutput_file = 'cultural_heritage_map.tif'\nwith rasterio.open(output_file, 'w', driver='GTiff', \n                   height=rows, width=cols, count=1, \n                   dtype=cultural_heritage_data.dtype, \n                   crs=crs, transform=transform) as dst:\n    dst.write(cultural_heritage_data, 1)\n\n# Read and display the generated raster\nwith rasterio.open(output_file) as src:\n    show(src, cmap='viridis')\nplt.title('Cultural Heritage Map')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial evolution analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport pandas as pd\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a time-based column if not present\ndata['time_index'] = pd.to_datetime(data['timestamp'])\n\n# Sort by time\ndata = data.sort_values(by='time_index')\n\n# Perform spatial evolution analysis\ndef spatial_evolution_analysis(df):\n    results = []\n    for i in range(1, len(df)):\n        prev_geom = df.geometry.iloc[i - 1]\n        curr_geom = df.geometry.iloc[i]\n        change_area = prev_geom.symmetric_difference(curr_geom).area\n        results.append({'time': df.time_index.iloc[i], 'change_area': change_area})\n    return pd.DataFrame(results)\n\nevolution_results = spatial_evolution_analysis(data)\n\n# Save results to a CSV file\nevolution_results.to_csv(\"spatial_evolution_results.csv\", index=False)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial pathway capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_pathway_capacity(density, velocity, width):\n    capacity = density * velocity * width\n    return capacity\n\ndensity = np.array([50, 60, 70])\nvelocity = np.array([1.5, 2.0, 1.8])\nwidth = np.array([3.0, 2.5, 3.2])\n\nspatial_capacity = calculate_spatial_pathway_capacity(density, velocity, width)\nprint(spatial_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex movement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\npoly1 = Polygon([(0, 0), (1, 1), (1, 0)])\npoly2 = Polygon([(2, 2), (3, 3), (3, 2)])\ngeometries = [poly1, poly2]\nconvex_result = extract_convex_hull(geometries)\nprint(convex_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial migration modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\ndef spatial_migration_model(locations, migration_rates, time_steps):\n    num_locations = len(locations)\n    population = np.ones(num_locations)\n    \n    for _ in range(time_steps):\n        new_population = np.zeros(num_locations)\n        \n        for i in range(num_locations):\n            total_migrants = 0\n            \n            for j in range(num_locations):\n                if i != j:\n                    dist = distance.euclidean(locations[i], locations[j])\n                    migration_flow = migration_rates[i][j] * population[j] / (1 + dist)\n                    total_migrants += migration_flow\n            \n            new_population[i] = population[i] + total_migrants\n        \n        population = new_population\n    \n    return population\n\nlocations = np.array([[0, 0], [1, 1], [2, 2]])\nmigration_rates = np.array([[0, 0.1, 0.2], [0.1, 0, 0.15], [0.2, 0.15, 0]])\ntime_steps = 10\n\nresult = spatial_migration_model(locations, migration_rates, time_steps)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial flow capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_flow_capacity(flow_matrix, distance_matrix, decay_factor):\n    normalized_distance = 1 / (distance_matrix ** decay_factor)\n    flow_capacity_index = np.sum(flow_matrix * normalized_distance) / np.sum(normalized_distance)\n    return flow_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial shifts using gradients.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import gaussian_gradient_magnitude\n\ndef detect_spatial_shifts(data, sigma=1.0):\n    gradient_magnitude = gaussian_gradient_magnitude(data, sigma=sigma)\n    shifts = np.where(gradient_magnitude > np.mean(gradient_magnitude) + np.std(gradient_magnitude))\n    return shifts\n\n# Example usage\ndata = np.random.rand(100, 100)\nspatial_shifts = detect_spatial_shifts(data, sigma=2.0)\nprint(spatial_shifts)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial diffusion analysis.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef spatial_diffusion(matrix, iterations, diffusion_rate):\n    kernel = np.array([[0.1, 0.1, 0.1],\n                       [0.1, 0.2, 0.1],\n                       [0.1, 0.1, 0.1]])\n    for _ in range(iterations):\n        matrix = matrix * (1 - diffusion_rate) + diffusion_rate * convolve(matrix, kernel, mode='constant')\n    return matrix\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial spread capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_spread_capacity(distances, opportunities):\n    total_opportunities = np.sum(opportunities)\n    weighted_distances = np.sum(distances * opportunities)\n    spread_capacity_index = weighted_distances / total_opportunities if total_opportunities > 0 else 0\n    return spread_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster social infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example data creation (replace with actual social infrastructure data)\nwidth, height = 500, 500\nsocial_infra_data = np.random.rand(height, width) * 100\n\n# Define the transform (example values, replace with real-world coordinates if needed)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=10, ysize=10)\n\n# Write the data to a raster file\noutput_raster_path = \"social_infrastructure_map.tif\"\nwith rasterio.open(\n    output_raster_path,\n    'w',\n    driver='GTiff',\n    height=social_infra_data.shape[0],\n    width=social_infra_data.shape[1],\n    count=1,\n    dtype=social_infra_data.dtype,\n    crs='+proj=latlong',\n    transform=transform,\n) as dst:\n    dst.write(social_infra_data, 1)\n\n# Plot the generated raster\nwith rasterio.open(output_raster_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, ax=ax, cmap='viridis', title=\"Social Infrastructure Map\")\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial propagation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef spatial_propagation_model(initial_state, kernel, iterations):\n    state = initial_state.copy()\n    for _ in range(iterations):\n        state = convolve(state, kernel, mode='constant', cval=0.0)\n    return state\n\n# Example usage\ninitial_state = np.random.rand(100, 100)\nkernel = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / 4.0\niterations = 50\nresult = spatial_propagation_model(initial_state, kernel, iterations)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial dissemination capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_dissemination_capacity(distances, flows):\n    total_flow = np.sum(flows)\n    weighted_distances = np.sum(distances * flows)\n    return weighted_distances / total_flow if total_flow != 0 else 0\n\n# Example usage:\ndistances = np.array([10, 20, 30])\nflows = np.array([5, 15, 10])\nindex = calculate_spatial_dissemination_capacity(distances, flows)\nprint(index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex transfer of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    points = unary_union(geometries)\n    return points.convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial transmission analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ntransmission_data = gpd.read_file(\"transmission_data.geojson\")\nregion_data = gpd.read_file(\"regions.geojson\")\n\n# Ensure both datasets are in the same CRS\ntransmission_data = transmission_data.to_crs(region_data.crs)\n\n# Perform spatial join to find intersections\nspatial_join = gpd.sjoin(transmission_data, region_data, how=\"inner\", predicate=\"intersects\")\n\n# Group by region and count transmission occurrences\ntransmission_counts = spatial_join.groupby(\"region_id\").size().reset_index(name=\"transmission_count\")\n\n# Merge counts back to the original region data\nregion_data_with_counts = region_data.merge(transmission_counts, on=\"region_id\", how=\"left\")\n\n# Fill NaN values for regions with no transmissions\nregion_data_with_counts[\"transmission_count\"] = region_data_with_counts[\"transmission_count\"].fillna(0)\n\n# Save results to a new file\nregion_data_with_counts.to_file(\"transmission_analysis_result.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial exchange capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_exchange_capacity(matrix):\n    row_sums = np.sum(matrix, axis=1)\n    col_sums = np.sum(matrix, axis=0)\n    total_sum = np.sum(matrix)\n    \n    exchange_index = 0\n    n = matrix.shape[0]\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                exchange_index += (matrix[i, j] * total_sum) / (row_sums[i] * col_sums[j])\n    \n    return exchange_index / (n * (n - 1))\n\n# Example usage:\nflow_matrix = np.array([[0, 5, 10], [5, 0, 15], [10, 15, 0]])\nresult = calculate_spatial_exchange_capacity(flow_matrix)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial flows using networks.",
        "output": "```python\nimport networkx as nx\n\ndef detect_spatial_flows(edges, nodes):\n    G = nx.DiGraph()\n    G.add_nodes_from(nodes)\n    G.add_weighted_edges_from(edges)\n    \n    flows = []\n    for source in G.nodes:\n        for target in G.nodes:\n            if source != target and nx.has_path(G, source, target):\n                shortest_path = nx.shortest_path(G, source=source, target=target, weight='weight')\n                total_weight = sum(G[u][v]['weight'] for u, v in zip(shortest_path[:-1], shortest_path[1:]))\n                flows.append((source, target, total_weight))\n    return flows\n\n# Example usage\nnodes = ['A', 'B', 'C', 'D']\nedges = [('A', 'B', 2), ('B', 'C', 3), ('C', 'D', 1), ('A', 'D', 10)]\nflows = detect_spatial_flows(edges, nodes)\nprint(flows)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial circulation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef spatial_circulation_model(flow_field, boundary_conditions, iterations=100):\n    kernel = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n    for _ in range(iterations):\n        flow_field = convolve(flow_field, kernel, mode='constant', cval=boundary_conditions)\n    return flow_field\n\nflow_field = np.random.rand(100, 100)\nboundary_conditions = 0.0\nresult = spatial_circulation_model(flow_field, boundary_conditions)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial connectivity capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_connectivity(matrix):\n    n = matrix.shape[0]\n    connectivity_index = np.sum(matrix) / (n * (n - 1))\n    return connectivity_index\n\n# Example usage:\nadjacency_matrix = np.array([[0, 1, 1], [1, 0, 0], [1, 0, 0]])\nsci = calculate_spatial_connectivity(adjacency_matrix)\nprint(sci)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster economic infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the dimensions and resolution of the raster\nwidth, height = 500, 500\nresolution = 0.001\n\n# Create a grid of coordinates\nx = np.linspace(-180, 180, width)\ny = np.linspace(-90, 90, height)\nxx, yy = np.meshgrid(x, y)\n\n# Generate synthetic economic infrastructure data (example: GDP density)\neconomic_data = np.exp(-((xx / 50) ** 2 + (yy / 30) ** 2)) * 1000\n\n# Define the transform for georeferencing\ntransform = rasterio.transform.from_origin(west=-180, north=90, xsize=resolution, ysize=resolution)\n\n# Write the data to a GeoTIFF file\nwith rasterio.open(\n    \"economic_infrastructure_map.tif\",\n    \"w\",\n    driver=\"GTiff\",\n    height=height,\n    width=width,\n    count=1,\n    dtype=economic_data.dtype,\n    crs=\"EPSG:4326\",\n    transform=transform,\n) as dst:\n    dst.write(economic_data, 1)\n\n# Plot the generated raster map\nwith rasterio.open(\"economic_infrastructure_map.tif\") as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, cmap=\"viridis\", title=\"Economic Infrastructure Map\", ax=ax)\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial interaction analysis.",
        "output": "```python\nimport geopandas as gpd\nimport libpysal\nfrom pointpats import distance_statistics\n\n# Load spatial data\norigins = gpd.read_file(\"origins.shp\")\ndestinations = gpd.read_file(\"destinations.shp\")\n\n# Ensure both datasets are in the same CRS\norigins = origins.to_crs(destinations.crs)\n\n# Create a spatial weights matrix based on distance\ndist_threshold = 5000  # Example threshold in meters\nweights = libpysal.weights.DistanceBand.from_dataframe(origins, threshold=dist_threshold)\n\n# Perform spatial interaction analysis using Nearest Neighbor Distance\nnnd = distance_statistics.NearestNeighborDistance(origins.geometry)\nnn_result = nnd.test()\n\n# Output results\nprint(f\"Nearest Neighbor Ratio: {nn_result['nnr']}\")\nprint(f\"Z-Score: {nn_result['z']}\")\nprint(f\"P-Value: {nn_result['pvalue']}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial linkage capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_linkage_capacity(distances, flows):\n    normalized_distances = distances / np.max(distances)\n    normalized_flows = flows / np.max(flows)\n    linkage_capacity = np.sum(normalized_flows * (1 - normalized_distances))\n    return linkage_capacity\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex communication of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [\n    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n    Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\n]\n\nconvex_hull_result = extract_convex_hull(geometries)\nprint(convex_hull_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial networking modeling.",
        "output": "```python\nimport networkx as nx\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString\n\n# Create a sample GeoDataFrame for nodes\nnodes_data = {\n    'node_id': [1, 2, 3, 4],\n    'geometry': [Point(0, 0), Point(1, 1), Point(2, 2), Point(3, 3)]\n}\nnodes_gdf = gpd.GeoDataFrame(nodes_data, crs=\"EPSG:4326\")\n\n# Create a sample GeoDataFrame for edges\nedges_data = {\n    'edge_id': [101, 102, 103],\n    'start_node': [1, 2, 3],\n    'end_node': [2, 3, 4],\n    'geometry': [\n        LineString([(0, 0), (1, 1)]),\n        LineString([(1, 1), (2, 2)]),\n        LineString([(2, 2), (3, 3)])\n    ]\n}\nedges_gdf = gpd.GeoDataFrame(edges_data, crs=\"EPSG:4326\")\n\n# Initialize a graph\nG = nx.Graph()\n\n# Add nodes to the graph\nfor _, row in nodes_gdf.iterrows():\n    G.add_node(row['node_id'], pos=(row.geometry.x, row.geometry.y))\n\n# Add edges to the graph\nfor _, row in edges_gdf.iterrows():\n    G.add_edge(row['start_node'], row['end_node'], geometry=row['geometry'])\n\n# Perform spatial networking analysis (e.g., shortest path)\nshortest_path = nx.shortest_path(G, source=1, target=4)\n\nprint(shortest_path)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial integration capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_integration_capacity(distances, flows):\n    total_flow = np.sum(flows)\n    weighted_distances = np.sum(distances * flows)\n    sic_index = weighted_distances / total_flow if total_flow != 0 else 0\n    return sic_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial relationships using graphs.",
        "output": "```python\nimport networkx as nx\nfrom shapely.geometry import Point, Polygon\n\n# Create a graph\nG = nx.Graph()\n\n# Add nodes with spatial geometries\nG.add_node(1, geom=Point(0, 0))\nG.add_node(2, geom=Point(1, 1))\nG.add_node(3, geom=Polygon([(2, 2), (3, 3), (4, 2)]))\n\n# Add edges based on spatial relationships\nfor node1, node2 in [(1, 2), (2, 3)]:\n    geom1 = G.nodes[node1]['geom']\n    geom2 = G.nodes[node2]['geom']\n    if geom1.distance(geom2) < 2:\n        G.add_edge(node1, node2)\n\n# Detect spatial relationships\nfor node in G.nodes:\n    neighbors = list(G.neighbors(node))\n    print(f\"Node {node} is spatially related to: {neighbors}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial association analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load shapefile data\ndata = gpd.read_file(\"path_to_shapefile.shp\")\n\n# Ensure the geometry column is valid and set the CRS if necessary\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\n\n# Calculate spatial lag for a specific attribute (e.g., 'attribute_column')\nattribute_values = data['attribute_column']\n\n# Perform Moran's I analysis\nmoran = Moran(attribute_values, w)\n\n# Output Moran's I statistic, p-value, and other details\nprint(f\"Moran's I: {moran.I}\")\nprint(f\"P-Value: {moran.p_sim}\")\nprint(f\"Expected I: {moran.EI}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial correlation capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef spatial_correlation_capacity(data, coordinates, distance_threshold):\n    distances = cdist(coordinates, coordinates, metric='euclidean')\n    weights = np.exp(-distances / distance_threshold)\n    np.fill_diagonal(weights, 0)\n    weighted_values = weights.dot(data)\n    total_weights = weights.sum(axis=1)\n    weighted_values /= total_weights\n    correlation = np.corrcoef(data, weighted_values)[0, 1]\n    return correlation\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster political infrastructure map.",
        "output": "```python\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import rasterize\nimport matplotlib.pyplot as plt\n\n# Load political infrastructure data (e.g., roads, buildings, etc.)\npolitical_infra_data = gpd.read_file(\"political_infrastructure.shp\")\n\n# Define the raster dimensions and resolution\nraster_width = 1000\nraster_height = 1000\ntransform = rasterio.transform.from_bounds(*political_infra_data.total_bounds, raster_width, raster_height)\n\n# Rasterize the vector data\nrasterized = rasterize(\n    [(geom, 1) for geom in political_infra_data.geometry],\n    out_shape=(raster_height, raster_width),\n    transform=transform,\n    fill=0,\n    dtype='uint8'\n)\n\n# Plot the rasterized map\nplt.imshow(rasterized, cmap='viridis')\nplt.colorbar(label=\"Infrastructure Presence\")\nplt.title(\"Political Infrastructure Map\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial affiliation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\n\n# Calculate spatial lag for a specific variable (e.g., 'your_column')\ndata['spatial_lag'] = w.lag_spatial(data['your_column'])\n\n# Perform Moran's I test for spatial autocorrelation\nmoran = Moran(data['your_column'], w)\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial alliance capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_alliance_capacity_index(weights, distances):\n    normalized_weights = weights / np.sum(weights)\n    inverse_distances = 1 / distances\n    capacity_index = np.sum(normalized_weights * inverse_distances)\n    return capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex cooperation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    return combined_geom.convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial partnership analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Local Moran's I analysis\nattribute = \"target_attribute\"\nmoran_loc = Moran_Local(data[attribute], w)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = moran_loc.p_sim\ndata['Ivalue'] = moran_loc.Is\n\n# Classify spatial partnerships (e.g., High-High, Low-Low)\ndata['Cluster_Type'] = None\ndata.loc[(moran_loc.q == 1) & (moran_loc.p_sim < 0.05), 'Cluster_Type'] = 'High-High'\ndata.loc[(moran_loc.q == 2) & (moran_loc.p_sim < 0.05), 'Cluster_Type'] = 'Low-High'\ndata.loc[(moran_loc.q == 3) & (moran_loc.p_sim < 0.05), 'Cluster_Type'] = 'Low-Low'\ndata.loc[(moran_loc.q == 4) & (moran_loc.p_sim < 0.05), 'Cluster_Type'] = 'High-Low'\n\n# Save results to a new shapefile\ndata.to_file(\"spatial_partnership_analysis_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial coalition capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_coalition_capacity_index(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    coalition_capacity_index = np.sum(weighted_data, axis=1)\n    return coalition_capacity_index\n\n# Example usage:\ndata = np.array([[5, 10, 3], [8, 7, 6], [9, 5, 2]])\nweights = np.array([0.4, 0.3, 0.3])\nspatial_coalition_capacity_index = calculate_spatial_coalition_capacity_index(data, weights)\nprint(spatial_coalition_capacity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial collaborations using clusters.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.cluster import DBSCAN\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.geojson\")\n\n# Ensure the data has a geometry column\nif not data.geometry.name == 'geometry':\n    data = data.set_geometry('geometry')\n\n# Extract coordinates for clustering\ncoords = data.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n\n# Apply DBSCAN clustering algorithm\nepsilon = 0.5  # Define the maximum distance between points\nmin_samples = 5  # Minimum number of points to form a cluster\ndb = DBSCAN(eps=epsilon, min_samples=min_samples).fit(coords)\n\n# Add cluster labels to the original dataset\ndata['cluster'] = db.labels_\n\n# Filter out noise points (label -1 indicates noise)\nclusters = data[data['cluster'] != -1]\n\n# Save clusters to a new file\nclusters.to_file(\"spatial_clusters.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial grouping modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform Local Moran's I analysis for spatial grouping\nattribute = \"your_target_column\"\nmoran_loc = Moran_Local(data[attribute], weights)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = moran_loc.p_sim\ndata['Ivalue'] = moran_loc.Is\n\n# Filter significant clusters (e.g., p-value < 0.05)\nsignificant_clusters = data[data['Isign'] < 0.05]\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial community capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef calculate_spatial_community_capacity(features, weights=None):\n    if weights is None:\n        weights = np.ones(features.shape[1])\n    \n    normalized_features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n    weighted_features = normalized_features * weights\n    distances = cdist(weighted_features, weighted_features, metric='euclidean')\n    capacity_index = np.sum(np.exp(-distances), axis=1) - 1\n    return capacity_index\n\n# Example usage\nfeatures_matrix = np.random.rand(10, 5)  # Replace with actual data\nweights_vector = np.array([0.5, 1.0, 1.5, 0.8, 1.2])  # Replace with actual weights\nspatial_capacity = calculate_spatial_community_capacity(features_matrix, weights_vector)\nprint(spatial_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster environmental infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample environmental infrastructure raster\nrows, cols = 500, 500\ndata = np.random.randint(1, 6, size=(rows, cols), dtype=np.uint8)\n\n# Define the transform (top-left corner, pixel size, etc.)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=10, ysize=10)\n\n# Define the metadata for the raster\nmeta = {\n    'driver': 'GTiff',\n    'height': rows,\n    'width': cols,\n    'count': 1,\n    'dtype': data.dtype,\n    'crs': 'EPSG:4326',\n    'transform': transform\n}\n\n# Write the raster to a file\noutput_path = 'environmental_infrastructure_map.tif'\nwith rasterio.open(output_path, 'w', **meta) as dst:\n    dst.write(data, 1)\n\n# Plot the generated raster\nwith rasterio.open(output_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, ax=ax, cmap='viridis')\n    plt.title('Environmental Infrastructure Map')\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial clustering analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.cluster import DBSCAN\nfrom shapely.geometry import Point\nimport numpy as np\n\n# Load spatial data\ngdf = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Extract coordinates\ncoords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n\n# Perform DBSCAN clustering\nepsilon = 0.5  # Define the maximum distance between points\nmin_samples = 5  # Define the minimum number of points to form a cluster\ndb = DBSCAN(eps=epsilon, min_samples=min_samples).fit(coords)\n\n# Add cluster labels to GeoDataFrame\ngdf['cluster'] = db.labels_\n\n# Save results to a new shapefile\ngdf.to_file(\"spatial_clusters_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial collective capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_collective_capacity_index(data, weights):\n    normalized_data = data / np.max(data, axis=0)\n    weighted_data = normalized_data * weights\n    spatial_collective_capacity_index = np.sum(weighted_data, axis=1)\n    return spatial_collective_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex coordination of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull_coordinates(geometries):\n    combined_geometry = unary_union(geometries)\n    convex_hull = combined_geometry.convex_hull\n    if isinstance(convex_hull, Polygon):\n        return list(convex_hull.exterior.coords)\n    elif isinstance(convex_hull, MultiPolygon):\n        return [list(polygon.exterior.coords) for polygon in convex_hull.geoms]\n    else:\n        return []\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial organization modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Example: Create a GeoDataFrame with sample geometries\ndata = {\n    \"name\": [\"Area1\", \"Area2\", \"Area3\"],\n    \"geometry\": [\n        Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),\n        Polygon([(1, 1), (2, 1), (2, 2), (1, 2)]),\n        Polygon([(2, 2), (3, 2), (3, 3), (2, 3)])\n    ]\n}\ngdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\")\n\n# Perform spatial organization modeling by calculating centroids\ngdf[\"centroid\"] = gdf.geometry.centroid\n\n# Spatial join to find relationships between areas\nspatial_join = gpd.sjoin(gdf, gdf, how=\"inner\", predicate=\"intersects\")\n\n# Save results to a new shapefile\ngdf.to_file(\"spatial_organization_model.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_scores = normalized_data.mul(spatial_weights, axis=0)\n    spatial_capacity_index = weighted_scores.sum(axis=1)\n    return spatial_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'institution_1': [5, 10, 15], 'institution_2': [20, 30, 40]})\n# capacity_columns = ['institution_1', 'institution_2']\n# spatial_weights = [0.6, 0.4]\n# sci = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(sci)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial structures using hierarchies.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.cluster import AgglomerativeClustering\n\n# Load spatial data\ngdf = gpd.read_file(\"spatial_data.shp\")\n\n# Extract coordinates for clustering\ncoords = gdf.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n\n# Perform hierarchical clustering\ncluster_model = AgglomerativeClustering(n_clusters=5, linkage='ward')\ngdf['cluster'] = cluster_model.fit_predict(coords)\n\n# Save the result to a new shapefile\ngdf.to_file(\"clustered_data.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial arrangement analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen, Rook\nfrom esda.moran import Moran\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix (Queen contiguity)\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Moran's I analysis for spatial autocorrelation\nattribute = \"your_column_name\"\nmoran = Moran(data[attribute], w)\n\n# Print Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n\n# Plot the spatial arrangement\nfig, ax = plt.subplots(1, figsize=(10, 10))\ndata.plot(column=attribute, cmap='coolwarm', scheme='quantiles', k=5, edgecolor='black', ax=ax, legend=True)\nplt.title(\"Spatial Arrangement Analysis\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha=1.0):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    weighted_distances = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * weighted_distances) / np.sum(weighted_distances)\n    return systemic_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster technological infrastructure map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\n# Define raster dimensions and geotransform\ncols, rows = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create an empty array for the raster data\ndata = np.zeros((rows, cols))\n\n# Populate the array with infrastructure values (example: random values)\ndata[100:200, 100:200] = 1  # Example infrastructure zone\ndata[300:400, 300:400] = 2  # Another infrastructure zone\n\n# Create a new raster file\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"infrastructure_map.tif\", cols, rows, 1, gdal.GDT_Float32)\n\n# Set the geotransform and projection\noutput_raster.SetGeoTransform(geotransform)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(3857)  # Example: WGS 84 / Pseudo-Mercator\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to the raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(data)\nband.FlushCache()\n\n# Clean up\nband = None\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial configuration modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom sklearn.cluster import KMeans\n\ndef spatial_configuration_modeling(points, num_clusters):\n    dist_matrix = distance_matrix(points, points)\n    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(points)\n    labels = kmeans.labels_\n    cluster_centers = kmeans.cluster_centers_\n    return dist_matrix, labels, cluster_centers\n\npoints = np.random.rand(100, 2)\nnum_clusters = 5\ndist_matrix, labels, cluster_centers = spatial_configuration_modeling(points, num_clusters)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    density_weight = 0.4\n    accessibility_weight = 0.35\n    land_use_mix_weight = 0.25\n\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n\n    spatial_capacity_index = (\n        density_weight * normalized_density +\n        accessibility_weight * normalized_accessibility +\n        land_use_mix_weight * normalized_land_use_mix\n    )\n\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex alignment of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(1, 1), (2, 2), (2, 1)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial design analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Define a custom area of interest as a polygon\narea_of_interest = Polygon([(min_x, min_y), (max_x, min_y), (max_x, max_y), (min_x, max_y)])\n\n# Perform spatial intersection analysis\ndata['intersects'] = data.intersects(area_of_interest)\nintersected_data = data[data['intersects']]\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(10, 10))\ndata.plot(ax=ax, color='lightgrey', edgecolor='black')\nintersected_data.plot(ax=ax, color='red', edgecolor='black')\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n\n# Example usage\ndata = np.array([[5, 10], [2, 8], [7, 12]])\nweights = np.array([0.6, 0.4])\nsmci_values = calculate_spatial_methodological_capacity_index(data, weights)\nprint(smci_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial patterns using layouts.",
        "output": "```python\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Plot spatial patterns using layouts\nfig, axes = plt.subplots(1, 2, figsize=(15, 7))\n\n# Plot 1: Basic map\ndata.plot(ax=axes[0], color='lightblue', edgecolor='black')\naxes[0].set_title('Basic Map')\n\n# Plot 2: Choropleth map\ndata.plot(ax=axes[1], column='your_attribute_column', cmap='YlOrRd', legend=True)\naxes[1].set_title('Choropleth Map')\n\nplt.tight_layout()\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial planning modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nimport matplotlib.pyplot as plt\n\n# Load spatial data\nregion_boundaries = gpd.read_file(\"region_boundaries.shp\")\nland_use_data = gpd.read_file(\"land_use_data.shp\")\n\n# Ensure both datasets have the same CRS\nland_use_data = land_use_data.to_crs(region_boundaries.crs)\n\n# Perform a spatial join to associate land use with regions\nspatial_join = gpd.sjoin(land_use_data, region_boundaries, how=\"inner\", op=\"within\")\n\n# Aggregate land use by region\naggregated_data = spatial_join.groupby(\"region_id\").agg({\"land_use_area\": \"sum\"}).reset_index()\n\n# Merge aggregated data back to region boundaries\nregion_boundaries = region_boundaries.merge(aggregated_data, on=\"region_id\", how=\"left\")\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(10, 10))\nregion_boundaries.plot(column=\"land_use_area\", ax=ax, legend=True, cmap=\"viridis\", edgecolor=\"black\")\nplt.title(\"Spatial Planning Model: Land Use Distribution\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights=None):\n    n = len(points)\n    if weights is None:\n        weights = np.ones(n)\n    dist_matrix = distance_matrix(points, points)\n    np.fill_diagonal(dist_matrix, 1e-10)\n    inverse_dist = 1 / dist_matrix\n    strategic_capacity = np.dot(inverse_dist, weights) / np.sum(inverse_dist, axis=1)\n    return strategic_capacity\n\n# Example usage\npoints = np.array([[0, 0], [1, 2], [3, 1], [5, 4]])\nweights = np.array([1.0, 1.5, 0.8, 1.2])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster information infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport matplotlib.pyplot as plt\n\nwith rasterio.open('raster_file.tif') as src:\n    raster_data = src.read(1)\n    show(raster_data, cmap='viridis')\n    plt.title('Raster Information Infrastructure Map')\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial programming analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load shapefile data\nshapefile_path = \"path_to_shapefile.shp\"\ndata = gpd.read_file(shapefile_path)\n\n# Create a GeoDataFrame with sample points\npoints = [Point(10, 20), Point(30, 40), Point(50, 60)]\npoint_gdf = gpd.GeoDataFrame(geometry=points, crs=\"EPSG:4326\")\n\n# Perform spatial join\njoined_data = gpd.sjoin(point_gdf, data, how=\"inner\", predicate=\"intersects\")\n\n# Calculate area for polygons\ndata['area'] = data.geometry.area\n\n# Save results to a new shapefile\noutput_path = \"output_analysis.shp\"\njoined_data.to_file(output_path)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity_index(density, accessibility, vulnerability):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"vulnerability\": 0.25\n    }\n    \n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_vulnerability = (vulnerability - np.min(vulnerability)) / (np.max(vulnerability) - np.min(vulnerability))\n\n    spatial_tactical_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"vulnerability\"] * normalized_vulnerability\n    )\n    \n    return spatial_tactical_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex positioning of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_positioning(geometries):\n    points = [point for geom in geometries for point in geom.exterior.coords]\n    multipoint = MultiPoint(points)\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(1, 1), (2, 2), (2, 1)])]\nconvex_result = extract_convex_positioning(geometries)\nprint(convex_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial mapping modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Prepare features and target variable\nX = data.drop(columns=[\"target_column\", \"geometry\"])\ny = data[\"target_column\"]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\npredictions = model.predict(X_test)\n\n# Evaluate the model (example: R-squared score)\nscore = model.score(X_test, y_test)\nprint(f\"Model R-squared score: {score}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, capacity):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    if demand.shape != capacity.shape:\n        raise ValueError(\"Demand and capacity arrays must have the same shape.\")\n    soc_index = np.divide(capacity, demand, out=np.zeros_like(capacity, dtype=float), where=demand!=0)\n    return np.nan_to_num(soc_index, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Example usage:\ndemand_values = [100, 200, 0, 150]\ncapacity_values = [80, 250, 0, 300]\nsoc_index = calculate_spatial_operational_capacity_index(demand_values, capacity_values)\nprint(soc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial distributions using grids.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nfrom shapely.geometry import Point\nfrom libpysal.cg import voronoi_frames\n\n# Load point data\npoints = [Point(xy) for xy in zip(np.random.rand(100), np.random.rand(100))]\ngdf_points = gpd.GeoDataFrame(geometry=points)\n\n# Define grid size and create grid cells\ngrid_size = 0.1\nxmin, ymin, xmax, ymax = gdf_points.total_bounds\ngrid_x = np.arange(xmin, xmax + grid_size, grid_size)\ngrid_y = np.arange(ymin, ymax + grid_size, grid_size)\ngrid_polygons = []\nfor x in grid_x:\n    for y in grid_y:\n        grid_polygons.append(Point(x, y).buffer(grid_size / 2, cap_style=3))\n\ngrid_gdf = gpd.GeoDataFrame(geometry=grid_polygons)\n\n# Spatial join points to grid cells\njoined = gpd.sjoin(gdf_points, grid_gdf, how=\"inner\", predicate=\"within\")\n\n# Count points per grid cell\ngrid_counts = joined.groupby(joined.index_right).size().reset_index(name='point_count')\ngrid_gdf = grid_gdf.merge(grid_counts, how=\"left\", left_index=True, right_on=\"index_right\").fillna(0)\n\n# Plot the result\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(10, 10))\ngrid_gdf.plot(column='point_count', ax=ax, cmap='Blues', legend=True, edgecolor='grey')\ngdf_points.plot(ax=ax, color='red', markersize=10)\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial zoning analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran_Local\n\n# Load the spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform Local Moran's I analysis for spatial clustering\nattribute = \"your_attribute_column\"\nmoran_loc = Moran_Local(data[attribute], weights)\n\n# Add results to the GeoDataFrame\ndata['Isign'] = moran_loc.q\ndata['pvalue'] = moran_loc.p_sim\n\n# Filter significant clusters (e.g., p-value < 0.05)\nsignificant_clusters = data[data['pvalue'] < 0.05]\n\n# Save the results to a new shapefile\nsignificant_clusters.to_file(\"spatial_zoning_analysis_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    functional_capacity_index = np.sum(weighted_features, axis=1)\n    return functional_capacity_index\n\n# Example usage\nfeatures = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights = np.array([0.4, 0.3, 0.3])\nspatial_functional_capacity = calculate_spatial_functional_capacity(features, weights)\nprint(spatial_functional_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster communication infrastructure map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define the raster dimensions and resolution\ncols, rows = 500, 500\ncell_size = 30\nx_min, y_max = 0, 0\nx_max = x_min + cols * cell_size\ny_min = y_max - rows * cell_size\n\n# Create an empty raster array\ndata = np.zeros((rows, cols))\n\n# Populate the raster with some example infrastructure data (e.g., signal strength)\nfor i in range(rows):\n    for j in range(cols):\n        data[i, j] = np.sin(i / 50) * np.cos(j / 50) * 100\n\n# Create a GeoTIFF file\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"communication_infrastructure_map.tif\", cols, rows, 1, gdal.GDT_Float32)\n\n# Set the geotransform\ngeotransform = (x_min, cell_size, 0, y_max, 0, -cell_size)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set the spatial reference\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)  # WGS84 coordinate system\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write the data to the raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(data)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial partitioning modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Extract coordinates for clustering\ncoords = np.array([[geom.x, geom.y] for geom in data.geometry])\n\n# Perform KMeans clustering for spatial partitioning\nnum_partitions = 5\nkmeans = KMeans(n_clusters=num_partitions, random_state=42).fit(coords)\n\n# Assign cluster labels to the original data\ndata['cluster'] = kmeans.labels_\n\n# Create polygons around clusters using convex hull\npartitioned_geoms = []\nfor cluster_id in range(num_partitions):\n    cluster_points = coords[kmeans.labels_ == cluster_id]\n    if len(cluster_points) > 2:\n        cluster_polygon = Polygon(cluster_points).convex_hull\n        partitioned_geoms.append(cluster_polygon)\n\n# Save partitioned geometries to a new GeoDataFrame\npartitioned_gdf = gpd.GeoDataFrame(geometry=partitioned_geoms, crs=data.crs)\npartitioned_gdf.to_file(\"partitioned_output.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, spatial_weights):\n    structural_data = np.array(structural_data)\n    spatial_weights = np.array(spatial_weights)\n    \n    if structural_data.shape != spatial_weights.shape:\n        raise ValueError(\"Structural data and spatial weights must have the same shape.\")\n    \n    weighted_values = structural_data * spatial_weights\n    total_weight = np.sum(spatial_weights)\n    structural_capacity_index = np.sum(weighted_values) / total_weight\n    \n    return structural_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex placement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_placement(geometries):\n    points = [point for geom in geometries for point in geom.exterior.coords]\n    multipoint = MultiPoint(points)\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]), Polygon([(2, 2), (3, 2), (3, 3), (2, 3)])]\nconvex_placement = extract_convex_placement(geometries)\nprint(convex_placement)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial allocation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data layers\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform a spatial join to allocate points to regions\nallocated = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Save the result to a new shapefile\nallocated.to_file(\"allocated_points.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    spatial_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial arrangements using matrices.",
        "output": "```python\nimport numpy as np\n\ndef detect_spatial_arrangements(matrix):\n    rows, cols = matrix.shape\n    arrangements = []\n\n    for i in range(rows):\n        for j in range(cols):\n            if i > 0 and matrix[i, j] == matrix[i-1, j]:\n                arrangements.append(((i, j), (i-1, j)))\n            if i < rows-1 and matrix[i, j] == matrix[i+1, j]:\n                arrangements.append(((i, j), (i+1, j)))\n            if j > 0 and matrix[i, j] == matrix[i, j-1]:\n                arrangements.append(((i, j), (i, j-1)))\n            if j < cols-1 and matrix[i, j] == matrix[i, j+1]:\n                arrangements.append(((i, j), (i, j+1)))\n\n    return arrangements\n\n# Example usage\nmatrix = np.array([[1, 2, 2], [1, 3, 4], [1, 3, 3]])\nresult = detect_spatial_arrangements(matrix)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial assignment modeling.",
        "output": "```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\n\n# Load spatial data (example: zones and points)\nzones = gpd.read_file(\"zones.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(zones.crs)\n\n# Perform spatial join to assign points to zones\npoints_in_zones = gpd.sjoin(points, zones, how=\"inner\", predicate=\"within\")\n\n# Aggregate results (e.g., count points in each zone)\nzone_summary = points_in_zones.groupby(\"zone_id\").size().reset_index(name=\"point_count\")\n\n# Save results to a new file\nzone_summary.to_csv(\"zone_point_assignment.csv\", index=False)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_scores = normalized_data.mul(spatial_weights, axis=0)\n    spatial_capacity_index = weighted_scores.sum(axis=1)\n    return spatial_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'institution_1': [5, 10, 15], 'institution_2': [20, 30, 40]})\n# capacity_columns = ['institution_1', 'institution_2']\n# spatial_weights = [0.6, 0.4]\n# sci_index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(sci_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster transportation infrastructure map.",
        "output": "```python\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import rasterize\nimport numpy as np\n\n# Load transportation infrastructure vector data (e.g., roads, railways)\nvector_data = gpd.read_file(\"transportation_infrastructure.shp\")\n\n# Define the raster output dimensions and transform\nxmin, ymin, xmax, ymax = vector_data.total_bounds\nresolution = 10  # Pixel resolution\nwidth = int((xmax - xmin) / resolution)\nheight = int((ymax - ymin) / resolution)\ntransform = rasterio.transform.from_origin(xmin, ymax, resolution, resolution)\n\n# Rasterize the vector data\nraster = rasterize(\n    [(geom, 1) for geom in vector_data.geometry],\n    out_shape=(height, width),\n    transform=transform,\n    fill=0,\n    dtype=np.uint8\n)\n\n# Save the resulting raster to a file\nwith rasterio.open(\n    \"transportation_infrastructure_map.tif\",\n    \"w\",\n    driver=\"GTiff\",\n    height=height,\n    width=width,\n    count=1,\n    dtype=raster.dtype,\n    crs=vector_data.crs,\n    transform=transform,\n) as dst:\n    dst.write(raster, 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial distribution analysis.",
        "output": "```python\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\nimport numpy as np\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in the correct CRS for analysis\ndata = data.to_crs(epsg=4326)\n\n# Plot spatial distribution\ndata.plot(column='attribute_of_interest', cmap='viridis', legend=True, markersize=10)\nplt.title(\"Spatial Distribution Analysis\")\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.show()\n\n# Perform spatial autocorrelation (Moran's I)\nfrom esda.moran import Moran\nfrom libpysal.weights import Queen\n\nw = Queen.from_dataframe(data)\nmoran = Moran(data['attribute_of_interest'], w)\nprint(f\"Moran's I: {moran.I}\")\n\n# Kernel Density Estimation\nfrom sklearn.neighbors import KernelDensity\nimport numpy as np\n\ncoords = np.array([(geom.x, geom.y) for geom in data.geometry])\nkde = KernelDensity(bandwidth=0.5).fit(coords)\ndensity = np.exp(kde.score_samples(coords))\n\n# Add density values to GeoDataFrame and plot\ndata['density'] = density\ndata.plot(column='density', cmap='plasma', legend=True)\nplt.title(\"Kernel Density Estimation\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    weighted_distances = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * weighted_distances, axis=1)\n    return systemic_capacity_index\n\n# Example usage:\ncapacity_matrix = np.array([[10, 20, 30], [15, 25, 35], [5, 10, 15]])\ndistance_matrix = np.array([[0, 2, 5], [2, 0, 3], [5, 3, 0]])\nalpha = 0.5\nresult = calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex location of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_location(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_location = extract_convex_location(geometries)\nprint(convex_location)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial deployment modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport numpy as np\n\n# Load spatial data\nregion_data = gpd.read_file('region.shp')\npoints_data = gpd.read_file('points.shp')\n\n# Define deployment function\ndef deploy_spatially(region, points, target_count):\n    region_geom = region.geometry.iloc[0]\n    min_x, min_y, max_x, max_y = region_geom.bounds\n    deployed_points = []\n\n    while len(deployed_points) < target_count:\n        random_point = Point(np.random.uniform(min_x, max_x), np.random.uniform(min_y, max_y))\n        if random_point.within(region_geom):\n            deployed_points.append(random_point)\n\n    return gpd.GeoDataFrame({'geometry': deployed_points}, crs=region.crs)\n\n# Perform deployment\ntarget_count = 100\ndeployed = deploy_spatially(region_data, points_data, target_count)\n\n# Save results\ndeployed.to_file('deployed_points.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    density_weight = 0.4\n    accessibility_weight = 0.35\n    land_use_mix_weight = 0.25\n\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n\n    spatial_procedural_capacity_index = (\n        density_weight * normalized_density +\n        accessibility_weight * normalized_accessibility +\n        land_use_mix_weight * normalized_land_use_mix\n    )\n\n    return spatial_procedural_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial placements using coordinates.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Example coordinates\ncoordinates = [(12.9716, 77.5946), (19.0760, 72.8777), (28.7041, 77.1025)]\n\n# Create a GeoDataFrame\ngeometry = [Point(xy) for xy in coordinates]\ngdf = gpd.GeoDataFrame(geometry=geometry, crs=\"EPSG:4326\")\n\n# Detect spatial placements\ngdf['placement'] = gdf.within(gpd.read_file(\"boundary.shp\").unary_union)\n\nprint(gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial positioning analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Example: Load a shapefile containing spatial data\nshapefile_path = \"path_to_your_shapefile.shp\"\nspatial_data = gpd.read_file(shapefile_path)\n\n# Example: Define points for spatial positioning analysis\npoints = [Point(12.34, 56.78), Point(10.00, 20.00), Point(-30.5, 100.25)]\npoints_gdf = gpd.GeoDataFrame(geometry=points, crs=spatial_data.crs)\n\n# Perform spatial join to analyze positioning\nspatial_join_result = gpd.sjoin(points_gdf, spatial_data, predicate=\"within\")\n\n# Output the results of the spatial positioning analysis\nprint(spatial_join_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n\n# Example usage\ndata = np.array([[5, 10], [2, 8], [7, 12]])\nweights = np.array([0.6, 0.4])\nsmci_values = calculate_spatial_methodological_capacity_index(data, weights)\nprint(smci_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster energy infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the grid size and resolution\ngrid_size = (500, 500)\nresolution = 0.001\n\n# Create a random energy infrastructure data array\nnp.random.seed(42)\nenergy_data = np.random.uniform(low=0, high=100, size=grid_size).astype(np.float32)\n\n# Define the spatial extent (left, bottom, right, top)\ntransform = rasterio.transform.from_origin(west=0.0, north=0.0, xsize=resolution, ysize=resolution)\n\n# Write the data to a temporary in-memory raster file\nwith rasterio.MemoryFile() as memfile:\n    with memfile.open(driver='GTiff', height=grid_size[0], width=grid_size[1], count=1, dtype='float32', crs='EPSG:4326', transform=transform) as dataset:\n        dataset.write(energy_data, 1)\n    \n    # Open the in-memory file for visualization\n    with memfile.open() as dataset:\n        show(dataset, cmap='viridis')\n        plt.title(\"Energy Infrastructure Map\")\n        plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial siting modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport pandas as pd\n\n# Load the datasets\nsites = gpd.read_file('sites.shp')\nconstraints = gpd.read_file('constraints.shp')\n\n# Ensure both GeoDataFrames have the same CRS\nsites = sites.to_crs(constraints.crs)\n\n# Buffer constraints to create restricted zones\nrestricted_zones = constraints.buffer(500)\n\n# Perform spatial overlay to exclude restricted areas\nvalid_areas = gpd.overlay(sites, gpd.GeoDataFrame(geometry=restricted_zones), how='difference')\n\n# Generate candidate points within valid areas\ncandidate_points = valid_areas.sample_points(size=1000)\n\n# Convert candidate points to GeoDataFrame\ncandidate_gdf = gpd.GeoDataFrame(geometry=[Point(xy) for xy in zip(candidate_points.x, candidate_points.y)], crs=valid_areas.crs)\n\n# Save results to a shapefile\ncandidate_gdf.to_file('candidate_sites.shp')\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights, decay_factor=0.5):\n    dist_matrix = distance_matrix(points, points)\n    decay_matrix = np.exp(-decay_factor * dist_matrix)\n    strategic_capacity = np.dot(decay_matrix, weights)\n    return strategic_capacity\n\n# Example usage\npoints = np.array([[0, 0], [1, 2], [3, 1]])\nweights = np.array([10, 20, 30])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex arrangement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_arrangement(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 0), (1, 1)]), Polygon([(0.5, 0.5), (1.5, 0.5), (1.5, 1.5)])]\nresult = extract_convex_arrangement(geometries)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial layout analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\nimport matplotlib.pyplot as plt\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in a projected coordinate system\ndata = data.to_crs(epsg=3857)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform Moran's I analysis for spatial autocorrelation\nattribute = \"your_column_name\"\nmoran = Moran(data[attribute], w)\n\n# Plot the results\nfig, ax = plt.subplots(1, figsize=(10, 6))\ndata.plot(column=attribute, cmap='coolwarm', scheme='quantiles', k=5, edgecolor='k', ax=ax)\nax.set_title(f\"Moran's I: {moran.I:.4f}, p-value: {moran.p_sim:.4f}\")\nplt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    tactical_capacity_index = np.sum(weighted_features, axis=1)\n    return tactical_capacity_index\n\n# Example usage\nfeatures = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights = np.array([0.5, 0.3, 0.2])\nresult = calculate_spatial_tactical_capacity(features, weights)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial alignments using vectors.",
        "output": "```python\nimport numpy as np\n\ndef detect_spatial_alignments(vectors):\n    alignments = []\n    for i in range(len(vectors)):\n        for j in range(i + 1, len(vectors)):\n            cosine_similarity = np.dot(vectors[i], vectors[j]) / (np.linalg.norm(vectors[i]) * np.linalg.norm(vectors[j]))\n            if np.isclose(cosine_similarity, 1.0) or np.isclose(cosine_similarity, -1.0):\n                alignments.append((i, j))\n    return alignments\n\nvectors = [np.array([1, 2, 3]), np.array([-2, -4, -6]), np.array([3, 0, 1])]\nresult = detect_spatial_alignments(vectors)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial orientation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef spatial_orientation_modeling(vectors, angles):\n    rotation = R.from_euler('xyz', angles, degrees=True)\n    rotated_vectors = rotation.apply(vectors)\n    return rotated_vectors\n\nvectors = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\nangles = [30, 45, 60]\nresult = spatial_orientation_modeling(vectors, angles)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, supply, distance_matrix, threshold_distance):\n    normalized_demand = demand / np.sum(demand)\n    normalized_supply = supply / np.sum(supply)\n    accessibility = np.exp(-distance_matrix / threshold_distance)\n    weighted_accessibility = accessibility * normalized_supply[:, np.newaxis]\n    spatial_capacity_index = np.dot(normalized_demand, weighted_accessibility)\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster water infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.features import rasterize\nimport geopandas as gpd\nimport numpy as np\n\n# Load water infrastructure vector data (e.g., shapefile)\nvector_data = gpd.read_file(\"water_infrastructure.shp\")\n\n# Define the output raster resolution and bounds\nresolution = 10\nxmin, ymin, xmax, ymax = vector_data.total_bounds\n\n# Create a grid for the raster\nwidth = int((xmax - xmin) / resolution)\nheight = int((ymax - ymin) / resolution)\ntransform = rasterio.transform.from_origin(xmin, ymax, resolution, resolution)\n\n# Rasterize the vector data\nshapes = ((geom, 1) for geom in vector_data.geometry)\nraster = rasterize(shapes, out_shape=(height, width), transform=transform, fill=0, dtype=np.uint8)\n\n# Save the output raster\nwith rasterio.open(\n    \"water_infrastructure_map.tif\",\n    \"w\",\n    driver=\"GTiff\",\n    height=raster.shape[0],\n    width=raster.shape[1],\n    count=1,\n    dtype=raster.dtype,\n    crs=vector_data.crs,\n    transform=transform,\n) as dst:\n    dst.write(raster, 1)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial direction analysis.",
        "output": "```python\nimport numpy as np\n\ndef calculate_direction_angle(x1, y1, x2, y2):\n    angle = np.arctan2(y2 - y1, x2 - x1)\n    return np.degrees(angle) % 360\n\ndef analyze_spatial_direction(points):\n    directions = []\n    for i in range(len(points) - 1):\n        x1, y1 = points[i]\n        x2, y2 = points[i + 1]\n        direction = calculate_direction_angle(x1, y1, x2, y2)\n        directions.append(direction)\n    return directions\n\n# Example usage\npoints = [(0, 0), (1, 1), (2, 0), (1, -1)]\ndirections = analyze_spatial_direction(points)\nprint(directions)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    functional_capacity_index = np.sum(weighted_features, axis=1)\n    return functional_capacity_index\n\n# Example usage:\nfeatures_matrix = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweight_vector = np.array([0.4, 0.5, 0.1])\nspatial_functional_capacity = calculate_spatial_functional_capacity(features_matrix, weight_vector)\nprint(spatial_functional_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex alignment of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(1, 1), (2, 2), (2, 1)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial navigation modeling.",
        "output": "```python\nimport networkx as nx\n\ndef perform_spatial_navigation_modeling(graph, start_node, end_node):\n    shortest_path = nx.shortest_path(graph, source=start_node, target=end_node, weight='distance')\n    return shortest_path\n\n# Example usage\nG = nx.Graph()\nG.add_edge('A', 'B', distance=5)\nG.add_edge('B', 'C', distance=3)\nG.add_edge('A', 'C', distance=10)\n\nstart = 'A'\nend = 'C'\nresult = perform_spatial_navigation_modeling(G, start, end)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, weights):\n    normalized_data = (structural_data - np.min(structural_data, axis=0)) / (np.max(structural_data, axis=0) - np.min(structural_data, axis=0))\n    weighted_data = normalized_data * weights\n    spatial_capacity_index = np.sum(weighted_data, axis=1)\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial directions using bearings.",
        "output": "```python\nimport math\n\ndef calculate_bearing(lat1, lon1, lat2, lon2):\n    lat1_rad = math.radians(lat1)\n    lon1_rad = math.radians(lon1)\n    lat2_rad = math.radians(lat2)\n    lon2_rad = math.radians(lon2)\n\n    d_lon = lon2_rad - lon1_rad\n\n    x = math.cos(lat2_rad) * math.sin(d_lon)\n    y = math.cos(lat1_rad) * math.sin(lat2_rad) - math.sin(lat1_rad) * math.cos(lat2_rad) * math.cos(d_lon)\n\n    bearing = math.atan2(x, y)\n    bearing = math.degrees(bearing)\n    bearing = (bearing + 360) % 360\n\n    return bearing\n\ndef detect_direction(bearing):\n    directions = [\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\", \"N\"]\n    index = round(bearing / 45)\n    return directions[index]\n\nlat1, lon1 = 52.5200, 13.4050\nlat2, lon2 = 48.8566, 2.3522\n\nbearing = calculate_bearing(lat1, lon1, lat2, lon2)\ndirection = detect_direction(bearing)\nprint(direction)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial guidance analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\narea_of_interest = gpd.read_file('path_to_area_of_interest.shp')\nguidance_layer = gpd.read_file('path_to_guidance_layer.shp')\n\n# Ensure both GeoDataFrames have the same CRS\narea_of_interest = area_of_interest.to_crs(guidance_layer.crs)\n\n# Perform spatial join to analyze guidance\nspatial_join = gpd.sjoin(area_of_interest, guidance_layer, how=\"inner\", predicate=\"intersects\")\n\n# Save results to a new shapefile\nspatial_join.to_file(\"spatial_guidance_analysis_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    spatial_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster sanitation infrastructure map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample sanitation infrastructure data array\ndata = np.random.randint(1, 6, size=(500, 500), dtype=np.uint8)\n\n# Define the metadata for the raster\nmeta = {\n    'driver': 'GTiff',\n    'height': data.shape[0],\n    'width': data.shape[1],\n    'count': 1,\n    'dtype': data.dtype,\n    'crs': 'EPSG:4326',\n    'transform': rasterio.transform.from_origin(-180, 90, 0.072, 0.072)\n}\n\n# Write the data to a new GeoTIFF file\noutput_path = 'sanitation_infrastructure_map.tif'\nwith rasterio.open(output_path, 'w', **meta) as dst:\n    dst.write(data, 1)\n\n# Plot the generated raster map\nwith rasterio.open(output_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, ax=ax, cmap='viridis')\n    plt.title('Sanitation Infrastructure Map')\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial routing modeling.",
        "output": "```python\nimport networkx as nx\nimport geopandas as gpd\nfrom shapely.geometry import LineString\n\n# Load road network data\nroads = gpd.read_file(\"roads.shp\")\n\n# Create a graph\nG = nx.Graph()\n\n# Add edges to the graph\nfor idx, row in roads.iterrows():\n    geom = row['geometry']\n    start, end = geom.coords[0], geom.coords[-1]\n    G.add_edge(start, end, weight=geom.length, geometry=geom)\n\n# Define source and target points\nsource = (roads.geometry.iloc[0].coords[0])\ntarget = (roads.geometry.iloc[-1].coords[-1])\n\n# Perform shortest path analysis\nshortest_path = nx.shortest_path(G, source=source, target=target, weight='weight')\n\n# Extract route geometry\nroute_geom = LineString([node for node in shortest_path])\n\n# Save result to a GeoDataFrame\nroute_gdf = gpd.GeoDataFrame(geometry=[route_geom], crs=roads.crs)\nroute_gdf.to_file(\"shortest_path.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_scores = normalized_data.mul(spatial_weights, axis=0)\n    spatial_institutional_capacity_index = weighted_scores.sum(axis=1)\n    return spatial_institutional_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'infrastructure': [5, 3, 8], 'education': [7, 6, 4], 'healthcare': [2, 9, 5]})\n# capacity_columns = ['infrastructure', 'education', 'healthcare']\n# spatial_weights = [0.4, 0.3, 0.3]\n# index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex orientation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon\n\ndef extract_convex_orientation(geometry):\n    if isinstance(geometry, Polygon):\n        coords = list(geometry.exterior.coords)\n        return coords\n    return None\n\npolygon = Polygon([(0, 0), (1, 1), (2, 0), (1, -1)])\nconvex_orientation = extract_convex_orientation(polygon)\nprint(convex_orientation)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial wayfinding analysis.",
        "output": "```python\nimport networkx as nx\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString\n\n# Load the road network data\nroad_network = gpd.read_file(\"roads.shp\")\n\n# Create a graph from the road network\nG = nx.Graph()\n\nfor idx, row in road_network.iterrows():\n    geom = row.geometry\n    if isinstance(geom, LineString):\n        start, end = geom.coords[0], geom.coords[-1]\n        G.add_edge(start, end, weight=geom.length)\n\n# Define origin and destination points\norigin = (x1, y1)  # Replace with actual coordinates\ndestination = (x2, y2)  # Replace with actual coordinates\n\n# Find nearest nodes in the graph\norigin_node = min(G.nodes, key=lambda n: Point(n).distance(Point(origin)))\ndestination_node = min(G.nodes, key=lambda n: Point(n).distance(Point(destination)))\n\n# Perform shortest path analysis\nshortest_path = nx.shortest_path(G, source=origin_node, target=destination_node, weight=\"weight\")\n\n# Convert the result into a GeoDataFrame for visualization or further processing\npath_geom = LineString(shortest_path)\nresult = gpd.GeoDataFrame(geometry=[path_geom], crs=road_network.crs)\n\n# Save or visualize the result\nresult.to_file(\"shortest_path.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    weighted_distances = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * weighted_distances, axis=1)\n    return systemic_capacity_index\n\n# Example usage:\ncapacity_matrix = np.array([[10, 20, 30], [15, 25, 35], [5, 10, 15]])\ndistance_matrix = np.array([[0, 2, 5], [2, 0, 3], [5, 3, 0]])\nalpha = 0.5\nresult = calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial pathways using trajectories.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import LineString\n\ndef detect_spatial_pathways(trajectories):\n    pathways = []\n    for trajectory in trajectories:\n        if len(trajectory) > 1:\n            pathway = LineString(trajectory)\n            pathways.append(pathway)\n    return gpd.GeoDataFrame(geometry=pathways)\n\n# Example usage\ntrajectories = [\n    [(0, 0), (1, 1), (2, 2)],\n    [(3, 3), (4, 4)],\n    [(5, 5), (6, 6), (7, 7), (8, 8)]\n]\n\npathways_gdf = detect_spatial_pathways(trajectories)\nprint(pathways_gdf)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial tracking modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial tracking\ndef spatial_tracking_model(data, target_geometry):\n    data['distance'] = data.geometry.distance(target_geometry)\n    tracked_data = data.sort_values(by='distance').head(1)\n    return tracked_data\n\n# Example usage\ntarget_point = Point(-73.994454, 40.750042)\ntracked_result = spatial_tracking_model(data, target_point)\n\nprint(tracked_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    \n    spatial_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster waste management map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create a sample waste management raster data\nrows, cols = 500, 500\nwaste_data = np.random.randint(1, 6, size=(rows, cols))\n\n# Define the transform (top-left corner, pixel size, etc.)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=10, ysize=10)\n\n# Define the CRS (Coordinate Reference System)\ncrs = \"EPSG:4326\"\n\n# Write the raster to a file\noutput_raster_path = \"waste_management_map.tif\"\nwith rasterio.open(output_raster_path, 'w', driver='GTiff', \n                   height=rows, width=cols, count=1, dtype=waste_data.dtype,\n                   crs=crs, transform=transform) as dst:\n    dst.write(waste_data, 1)\n\n# Plot the generated raster\nwith rasterio.open(output_raster_path) as src:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    show(src, ax=ax, title=\"Waste Management Map\", cmap='viridis')\n    plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial tracing analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(data)\n\n# Perform spatial autocorrelation analysis (Moran's I)\nattribute = \"your_attribute_column\"\nmoran = Moran(data[attribute], weights)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n\n# Example usage\ndata = np.array([[5, 3, 8], [7, 6, 9], [2, 4, 5]])\nweights = np.array([0.5, 0.3, 0.2])\nsmci_values = calculate_spatial_methodological_capacity_index(data, weights)\nprint(smci_values)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex movement of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    multipoint = MultiPoint([point for geom in geometries for point in geom.exterior.coords])\n    convex_hull = multipoint.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull_result = extract_convex_hull(geometries)\nprint(convex_hull_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial monitoring modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create new features if necessary\ndata['area'] = data.geometry.area\ndata['centroid'] = data.geometry.centroid\n\n# Prepare features and target variable\nX = data[['area', 'centroid_x', 'centroid_y']]\ny = data['target_column']\n\n# Train a spatial monitoring model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X, y)\n\n# Predict using the trained model\ndata['prediction'] = model.predict(X)\n\n# Save results to a new shapefile\ndata.to_file(\"spatial_monitoring_results.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights, decay_factor=0.5):\n    dist_matrix = distance_matrix(points, points)\n    np.fill_diagonal(dist_matrix, 1e-10)\n    influence_matrix = weights[:, np.newaxis] * np.exp(-decay_factor * dist_matrix)\n    strategic_capacity = np.sum(influence_matrix, axis=0)\n    return strategic_capacity\n\n# Example usage:\npoints = np.array([[0, 0], [1, 2], [3, 3]])\nweights = np.array([1.0, 2.0, 1.5])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial flows using streams.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom pysal.explore.spaghetti import Network\n\n# Load spatial data\nflows = gpd.read_file(\"flows.geojson\")\npoints = gpd.read_file(\"points.geojson\")\n\n# Create a spatial weights matrix\nweights = Queen.from_dataframe(points)\n\n# Initialize the network\nnetwork = Network(in_data=flows, w=weights)\n\n# Compute the streams\nstreams = network.compute_stream(flows, points)\nstreams.to_file(\"spatial_streams.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial surveillance analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom splot.esda import plot_moran\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the geometry column is valid and set the coordinate reference system (CRS)\ndata = data.set_crs(\"EPSG:4326\", allow_override=True)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\n\n# Calculate spatial lag for a specific attribute of interest\nattribute = \"your_attribute_column\"\ndata['lag'] = gpd.GeoSeries(data[attribute]).apply(lambda x: w.neighbors[x])\n\n# Perform Moran's I analysis for spatial autocorrelation\nmoran = Moran(data[attribute], w)\n\n# Plot Moran's I scatterplot\nplot_moran(moran, zstandard=True)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity_index(density, accessibility, vulnerability):\n    weights = {\n        'density': 0.4,\n        'accessibility': 0.35,\n        'vulnerability': 0.25\n    }\n    \n    normalized_density = density / np.max(density)\n    normalized_accessibility = accessibility / np.max(accessibility)\n    normalized_vulnerability = vulnerability / np.max(vulnerability)\n    \n    spatial_tactical_capacity_index = (\n        weights['density'] * normalized_density +\n        weights['accessibility'] * normalized_accessibility -\n        weights['vulnerability'] * normalized_vulnerability\n    )\n    \n    return spatial_tactical_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster disaster response map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define raster dimensions and geotransform\nrows, cols = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create a random disaster intensity grid\nnp.random.seed(42)\ndisaster_intensity = np.random.uniform(0, 1, (rows, cols))\n\n# Create output raster\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"disaster_response_map.tif\", cols, rows, 1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set spatial reference\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(disaster_intensity)\nband.SetNoDataValue(-9999)\nband.FlushCache()\n\n# Cleanup\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial observation modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef spatial_observation_model(true_state, observation_matrix, noise_covariance):\n    observation_mean = np.dot(observation_matrix, true_state)\n    observation_noise = np.random.multivariate_normal(np.zeros_like(observation_mean), noise_covariance)\n    observed_value = observation_mean + observation_noise\n    return observed_value\n\ntrue_state = np.array([1.0, 2.0, 3.0])\nobservation_matrix = np.array([[1, 0, 0], [0, 1, 0]])\nnoise_covariance = np.array([[0.1, 0], [0, 0.1]])\n\nobserved_data = spatial_observation_model(true_state, observation_matrix, noise_covariance)\nprint(observed_data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, supply, distance_matrix, threshold_distance):\n    normalized_demand = demand / np.sum(demand)\n    normalized_supply = supply / np.sum(supply)\n    accessibility = np.exp(-distance_matrix / threshold_distance)\n    weighted_accessibility = accessibility * normalized_supply[:, np.newaxis]\n    soc_index = np.dot(normalized_demand, weighted_accessibility)\n    return soc_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex transfer of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    points = unary_union(geometries)\n    return points.convex_hull\n\n# Example usage\npoly1 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\npoly2 = Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\ngeometries = [poly1, poly2]\n\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial inspection analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load shapefile or geojson for spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Create a sample point geometry for inspection\npoint = Point(-73.994454, 40.750042)\n\n# Convert the point to a GeoDataFrame\npoint_gdf = gpd.GeoDataFrame(geometry=[point], crs=data.crs)\n\n# Perform spatial join or intersection analysis\nresult = gpd.sjoin(point_gdf, data, predicate=\"within\")\n\n# Display the result\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    functional_capacity_index = np.sum(weighted_features, axis=1)\n    return functional_capacity_index\n\n# Example usage:\nfeatures_matrix = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights_vector = np.array([0.5, 0.3, 0.2])\nspatial_functional_capacity = calculate_spatial_functional_capacity(features_matrix, weights_vector)\nprint(spatial_functional_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial exchanges using transactions.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Example: Detect spatial exchanges using transactions\ntransactions = [\n    {\"id\": 1, \"from_loc\": (10, 20), \"to_loc\": (15, 25)},\n    {\"id\": 2, \"from_loc\": (30, 40), \"to_loc\": (35, 45)},\n    {\"id\": 3, \"from_loc\": (50, 60), \"to_loc\": (55, 65)}\n]\n\ndef detect_spatial_exchanges(transactions):\n    exchanges = []\n    for t in transactions:\n        from_point = Point(t[\"from_loc\"])\n        to_point = Point(t[\"to_loc\"])\n        if from_point.distance(to_point) > 0:\n            exchanges.append({\n                \"id\": t[\"id\"],\n                \"from_loc\": from_point,\n                \"to_loc\": to_point,\n                \"distance\": from_point.distance(to_point)\n            })\n    return exchanges\n\nspatial_exchanges = detect_spatial_exchanges(transactions)\nfor exchange in spatial_exchanges:\n    print(exchange)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial auditing modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the data has a target column 'target' and feature columns\nX = data.drop(columns=['target', 'geometry'])\ny = data['target']\n\n# Split into training and testing datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train a Random Forest Classifier\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nprint(classification_report(y_test, y_pred))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, spatial_weights):\n    structural_data = np.array(structural_data)\n    spatial_weights = np.array(spatial_weights)\n    \n    if structural_data.shape != spatial_weights.shape:\n        raise ValueError(\"Structural data and spatial weights must have the same shape.\")\n    \n    weighted_data = structural_data * spatial_weights\n    total_weight = np.sum(spatial_weights)\n    capacity_index = np.sum(weighted_data) / total_weight if total_weight != 0 else 0\n    \n    return capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster emergency management map.",
        "output": "```python\nimport rasterio\nfrom rasterio.plot import show\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a sample raster data\ndata = np.random.randint(1, 10, size=(500, 500), dtype=np.uint8)\n\n# Define the transform (top-left x, pixel width, rotation, top-left y, rotation, pixel height)\ntransform = rasterio.transform.from_origin(west=0, north=0, xsize=1, ysize=1)\n\n# Define the CRS (Coordinate Reference System) - WGS84\ncrs = \"EPSG:4326\"\n\n# Write the raster to a temporary in-memory file\nwith rasterio.io.MemoryFile() as memfile:\n    with memfile.open(driver='GTiff', height=data.shape[0], width=data.shape[1],\n                      count=1, dtype=data.dtype, crs=crs, transform=transform) as dataset:\n        dataset.write(data, 1)\n    \n    # Open and visualize the generated raster map\n    with memfile.open() as dataset:\n        show(dataset, cmap='viridis')\n        plt.title(\"Emergency Management Map\")\n        plt.show()\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial assessment analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load shapefile or geojson for spatial data\nregions = gpd.read_file(\"regions.shp\")\npoints = gpd.read_file(\"points.shp\")\n\n# Ensure both GeoDataFrames have the same CRS\npoints = points.to_crs(regions.crs)\n\n# Perform spatial join to assess which region each point falls into\nspatial_join = gpd.sjoin(points, regions, how=\"inner\", predicate=\"within\")\n\n# Save the result to a new file\nspatial_join.to_file(\"spatial_assessment_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(distances, flows, decay_factor):\n    normalized_distances = distances / np.max(distances)\n    decay_weights = np.exp(-decay_factor * normalized_distances)\n    weighted_flows = flows * decay_weights\n    spatial_index = np.sum(weighted_flows) / np.sum(flows)\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex communication of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage:\ngeoms = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(1, 1), (2, 2), (2, 1)])]\nresult = extract_convex_hull(geoms)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial evaluation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.geojson\")\n\n# Prepare features and target variable\nX = data.drop(columns=[\"target_column\", \"geometry\"])\ny = data[\"target_column\"]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_data = normalized_data.multiply(spatial_weights, axis=0)\n    spatial_capacity_index = weighted_data.sum(axis=1)\n    return spatial_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'institution_1': [5, 10, 15], 'institution_2': [20, 30, 40]})\n# capacity_columns = ['institution_1', 'institution_2']\n# spatial_weights = [0.6, 0.4]\n# sci_index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(sci_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial interactions using engagements.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\n\n# Load spatial data\ngdf = gpd.read_file(\"spatial_data.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\nif not gdf.crs:\n    gdf.set_crs(\"EPSG:4326\", inplace=True)\n\n# Create a spatial weights matrix using Queen contiguity\nweights = Queen.from_dataframe(gdf)\n\n# Compute spatial engagement (e.g., number of neighbors for each feature)\ngdf['engagement'] = weights.cardinalities.values()\n\n# Save results to a new shapefile\ngdf.to_file(\"spatial_engagements.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial appraisal analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for appraisal analysis\ndef spatial_appraisal_analysis(data, target_column):\n    # Ensure the data is in the correct CRS\n    data = data.to_crs(epsg=4326)\n    \n    # Calculate spatial weights\n    weights = data.centroid.apply(lambda p: p.distance(data.unary_union.centroid))\n    \n    # Normalize weights\n    weights /= weights.sum()\n    \n    # Compute weighted appraisal score\n    appraisal_score = (data[target_column] * weights).sum()\n    \n    return appraisal_score\n\n# Perform the analysis on a specific column\ntarget_column = \"value\"\nscore = spatial_appraisal_analysis(data, target_column)\nprint(f\"Spatial Appraisal Score: {score}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha=1.0):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    decay_factor = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * decay_factor, axis=1)\n    return systemic_capacity_index\n\n# Example usage:\ncapacity_matrix = np.array([[10, 20, 30], [15, 25, 35], [5, 10, 15]])\ndistance_matrix = np.array([[0, 2, 5], [2, 0, 3], [5, 3, 0]])\nalpha = 0.5\n\nresult = calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha)\nprint(result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster public safety map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\n# Define raster dimensions and geotransform\nrows, cols = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create an empty raster array\nsafety_data = np.random.rand(rows, cols) * 100  # Random values for safety scores\n\n# Create a new raster file\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"public_safety_map.tif\", cols, rows, 1, gdal.GDT_Float32)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set projection (WGS84)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to the raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(safety_data)\nband.SetNoDataValue(-9999)\n\n# Close the dataset\nband.FlushCache()\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial review modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Define a function for spatial review modeling\ndef spatial_review_modeling(data, buffer_distance):\n    # Create a buffer around each geometry\n    buffered = data.buffer(buffer_distance)\n    \n    # Perform spatial join to find intersections\n    intersections = gpd.sjoin(data, data, how=\"inner\", predicate=\"intersects\")\n    \n    # Calculate areas of intersections\n    intersections['intersection_area'] = intersections.geometry.area\n    \n    return intersections\n\n# Example usage\nbuffer_distance = 1000  # in meters\nresult = spatial_review_modeling(data, buffer_distance)\n\n# Save the result to a new shapefile\nresult.to_file(\"spatial_review_result.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    spatial_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex connection of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined = unary_union(geometries)\n    return combined.convex_hull\n\n# Example usage:\npoly1 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\npoly2 = Polygon([(1, 1), (2, 1), (2, 2), (1, 2)])\ngeometries = [poly1, poly2]\n\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial examination analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load shapefile or GeoJSON data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Create a sample point geometry for analysis\npoint = Point(12.345, 67.890)\n\n# Set the coordinate reference system (CRS) for the point\npoint_geom = gpd.GeoSeries([point], crs=\"EPSG:4326\")\n\n# Ensure the data and point have the same CRS\nif data.crs != point_geom.crs:\n    data = data.to_crs(point_geom.crs)\n\n# Perform spatial join or examination\nwithin_data = data[data.contains(point_geom[0])]\n\n# Display results\nprint(within_data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial linkages using ties.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\n\n# Load spatial data\ngdf = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\nif not gdf.crs:\n    gdf.set_crs(\"EPSG:4326\", inplace=True)\n\n# Create spatial weights matrix using Queen contiguity\nqueen_weights = Queen.from_dataframe(gdf)\n\n# Convert the weights to a pandas DataFrame for inspection\nweights_df = queen_weights.to_adjlist()\n\n# Display the first few rows of the adjacency list\nprint(weights_df.head())\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial investigation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom pysal.explore import esda\nfrom pysal.lib import weights\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the geometry column is valid\ndata['geometry'] = data['geometry'].apply(lambda geom: geom if geom.is_valid else geom.buffer(0))\n\n# Create a spatial weights matrix\nw = weights.Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform spatial autocorrelation analysis (Moran's I)\nattribute = 'your_target_column'\nmoran = esda.Moran(data[attribute], w)\n\n# Print Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n\n# Spatial Lag Model (SLM) using statsmodels\nimport statsmodels.api as sm\n\nX = data[['independent_var1', 'independent_var2']]\ny = data[attribute]\nX = sm.add_constant(X)\n\nlag_model = sm.GLS(y, X, weights=w).fit()\nprint(lag_model.summary())\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights, decay_factor=0.5):\n    dist_matrix = distance_matrix(points, points)\n    decay_matrix = np.exp(-decay_factor * dist_matrix)\n    interaction_matrix = decay_matrix * weights[:, np.newaxis]\n    strategic_capacity = np.sum(interaction_matrix, axis=1)\n    return strategic_capacity\n\n# Example usage:\npoints = np.array([[0, 0], [1, 2], [3, 3]])\nweights = np.array([1.0, 2.0, 1.5])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster law enforcement map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\n# Define raster dimensions and geotransform\ncols, rows = 500, 500\ngeotransform = (0, 10, 0, 0, 0, -10)\n\n# Create a random enforcement intensity grid\ndata = np.random.randint(0, 100, size=(rows, cols))\n\n# Create output raster\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"law_enforcement_map.tif\", cols, rows, 1, gdal.GDT_Byte)\noutput_raster.SetGeoTransform(geotransform)\n\n# Set spatial reference\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(data)\nband.SetNoDataValue(255)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial exploration analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport matplotlib.pyplot as plt\n\n# Load a shapefile or GeoJSON file\ndata = gpd.read_file(\"path_to_your_file.shp\")\n\n# Print the first few records\nprint(data.head())\n\n# Plot the spatial data\ndata.plot()\nplt.show()\n\n# Check the Coordinate Reference System (CRS)\nprint(data.crs)\n\n# Convert CRS if necessary\ndata = data.to_crs(epsg=4326)\n\n# Perform basic spatial operations\ncentroid = data.geometry.centroid\nbuffered = data.geometry.buffer(0.1)\n\n# Calculate area and length\ndata['area'] = data.geometry.area\ndata['length'] = data.geometry.length\n\n# Spatial join between two GeoDataFrames\nother_data = gpd.read_file(\"path_to_other_file.shp\")\njoined_data = gpd.sjoin(data, other_data, how=\"inner\", op='intersects')\n\n# Save results to a new file\njoined_data.to_file(\"output_file.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity_index(density, accessibility, vulnerability):\n    weights = {\n        'density': 0.4,\n        'accessibility': 0.35,\n        'vulnerability': 0.25\n    }\n    \n    normalized_density = density / np.max(density)\n    normalized_accessibility = accessibility / np.max(accessibility)\n    normalized_vulnerability = vulnerability / np.max(vulnerability)\n    \n    spatial_tactical_capacity_index = (\n        weights['density'] * normalized_density +\n        weights['accessibility'] * normalized_accessibility -\n        weights['vulnerability'] * normalized_vulnerability\n    )\n    \n    return spatial_tactical_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex relationship of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_relationship(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_result = extract_convex_relationship(geometries)\nprint(convex_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial discovery modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Prepare features and target variable\nX = data.drop(columns=[\"target\"])\ny = data[\"target\"]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and train the model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, capacity):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    if demand.shape != capacity.shape:\n        raise ValueError(\"Demand and capacity arrays must have the same shape.\")\n    soc_index = np.divide(capacity, demand, out=np.zeros_like(capacity, dtype=float), where=demand!=0)\n    return np.nan_to_num(soc_index, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Example usage\ndemand = [100, 200, 0, 150]\ncapacity = [80, 250, 0, 300]\nsoc_index = calculate_spatial_operational_capacity_index(demand, capacity)\nprint(soc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial associations using bonds.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Delaunay\n\ndef detect_spatial_associations(points):\n    tri = Delaunay(points)\n    bonds = set()\n    for simplex in tri.simplices:\n        for i in range(len(simplex)):\n            edge = tuple(sorted([simplex[i], simplex[(i + 1) % len(simplex)]]))\n            bonds.add(edge)\n    return list(bonds)\n\n# Example usage\npoints = np.random.rand(10, 2)\nbonds = detect_spatial_associations(points)\nprint(bonds)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial inquiry analysis.",
        "output": "```python\nfrom shapely.geometry import Point, Polygon\nimport geopandas as gpd\n\n# Example: Create a GeoDataFrame with a polygon and a point\npolygon = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\npoint = Point(0.5, 0.5)\ngdf_poly = gpd.GeoDataFrame(index=[0], geometry=[polygon])\ngdf_point = gpd.GeoDataFrame(index=[0], geometry=[point])\n\n# Perform spatial inquiry: Check if the point is within the polygon\nis_within = gdf_point.within(gdf_poly.loc[0, 'geometry'])\nprint(is_within)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    spatial_functional_capacity = np.sum(weighted_features, axis=1)\n    return spatial_functional_capacity\n\n# Example usage:\nfeatures = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights = np.array([0.5, 0.3, 0.2])\nsfc_index = calculate_spatial_functional_capacity(features, weights)\nprint(sfc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster national security map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\n# Define raster dimensions and geotransform\nrows, cols = 1000, 1000\ngeotransform = (-180.0, 0.36, 0, 90.0, 0, -0.18)\n\n# Create random data for the security map (example values)\nsecurity_data = np.random.randint(1, 10, size=(rows, cols))\n\n# Create a new raster file\ndriver = gdal.GetDriverByName(\"GTiff\")\noutput_raster = driver.Create(\"national_security_map.tif\", cols, rows, 1, gdal.GDT_Byte)\n\n# Set geotransform and projection\noutput_raster.SetGeoTransform(geotransform)\nsrs = osr.SpatialReference()\nsrs.ImportFromEPSG(4326)  # WGS84 coordinate system\noutput_raster.SetProjection(srs.ExportToWkt())\n\n# Write data to the raster band\nband = output_raster.GetRasterBand(1)\nband.WriteArray(security_data)\nband.SetNoDataValue(0)\nband.FlushCache()\n\n# Clean up\noutput_raster = None\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial research modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom sklearn.neighbors import BallTree\nimport numpy as np\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\ndata_points = [(geom.x, geom.y) for geom in data.geometry]\n\n# Create a BallTree for spatial indexing\ntree = BallTree(np.radians(data_points), metric='haversine')\n\n# Define query points (example coordinates)\nquery_points = [(40.7128, -74.0060), (34.0522, -118.2437)]\nquery_points_rad = np.radians(query_points)\n\n# Perform spatial search (e.g., find 5 nearest neighbors)\ndistances, indices = tree.query(query_points_rad, k=5)\n\n# Map results back to original data\nnearest_neighbors = data.iloc[indices.flatten()]\nprint(nearest_neighbors)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, weights):\n    normalized_data = (structural_data - np.min(structural_data, axis=0)) / (np.max(structural_data, axis=0) - np.min(structural_data, axis=0))\n    weighted_data = normalized_data * weights\n    spatial_capacity_index = np.sum(weighted_data, axis=1)\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex affiliation of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_affiliation(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n\n# Example usage:\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_result = extract_convex_affiliation(geometries)\nprint(convex_result)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial study analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport matplotlib.pyplot as plt\n\n# Load a shapefile or GeoJSON for spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the data is in the correct CRS (e.g., EPSG:4326 for WGS84)\ndata = data.to_crs(epsg=4326)\n\n# Create a sample point geometry for analysis\nsample_point = Point(-73.994454, 40.750042)  # Example: Longitude, Latitude\nsample_gdf = gpd.GeoDataFrame(index=[0], crs=\"EPSG:4326\", geometry=[sample_point])\n\n# Perform a spatial join to find features within a certain distance\nbuffer_distance = 0.01  # Approximate distance in degrees\nbuffered_area = sample_gdf.buffer(buffer_distance)\nintersected_data = gpd.overlay(data, gpd.GeoDataFrame(geometry=buffered_area, crs=\"EPSG:4326\"), how='intersection')\n\n# Plot the results\nfig, ax = plt.subplots(figsize=(10, 10))\ndata.plot(ax=ax, color='lightgray', edgecolor='black')\nsample_gdf.plot(ax=ax, color='red', markersize=100, label='Sample Point')\nintersected_data.plot(ax=ax, color='blue', alpha=0.5, label='Intersected Features')\nplt.legend()\nplt.show()\n\n# Export results if needed\nintersected_data.to_file(\"spatial_study_results.geojson\", driver=\"GeoJSON\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    \n    spatial_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial partnerships using alliances.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import shape\n\ndef detect_spatial_partnerships(alliances, regions):\n    alliances_gdf = gpd.GeoDataFrame(alliances)\n    regions_gdf = gpd.GeoDataFrame(regions)\n\n    spatial_partnerships = []\n    for idx, alliance in alliances_gdf.iterrows():\n        alliance_geom = shape(alliance['geometry'])\n        partners = regions_gdf[regions_gdf.intersects(alliance_geom)]\n        partnership = {\n            'alliance_id': alliance['id'],\n            'partner_ids': list(partners['id']),\n            'intersection_geoms': [shape(partner_geom).intersection(alliance_geom) for partner_geom in partners['geometry']]\n        }\n        spatial_partnerships.append(partnership)\n\n    return spatial_partnerships\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial analysis modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom pysal.lib import weights\nfrom pysal.model import spreg\n\n# Load shapefile data\ndata = gpd.read_file(\"path_to_shapefile.shp\")\n\n# Ensure the geometry column is valid\ndata = data.set_geometry('geometry')\n\n# Create a spatial weights matrix\nw = weights.Queen.from_dataframe(data)\nw.transform = 'r'\n\n# Define dependent and independent variables\ny = data['dependent_variable'].values.reshape(-1, 1)\nX = data[['independent_var1', 'independent_var2']].values\n\n# Perform spatial regression (Spatial Lag Model)\nmodel = spreg.ML_Lag(y, X, w=w, name_y='Dependent Variable', name_x=['Independent Var1', 'Independent Var2'])\n\n# Print model summary\nprint(model.summary)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_data = normalized_data.multiply(spatial_weights, axis=0)\n    spatial_capacity_index = weighted_data.sum(axis=1)\n    return spatial_capacity_index\n\n# Example usage:\n# Assuming `data` is a DataFrame containing institutional capacity indicators,\n# `capacity_columns` is a list of relevant column names, and `spatial_weights` is a Series of spatial weights.\n# spatial_index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster defense planning map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, osr\n\ndef create_raster_defense_map(output_path, width, height, geotransform, projection, defense_data):\n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, width, height, 1, gdal.GDT_Float32)\n    dataset.SetGeoTransform(geotransform)\n    dataset.SetProjection(projection)\n    band = dataset.GetRasterBand(1)\n    band.WriteArray(defense_data)\n    band.FlushCache()\n    dataset = None\n\nwidth = 500\nheight = 500\ngeotransform = (440720, 30, 0, 3751320, 0, -30)\nprojection = osr.SpatialReference()\nprojection.ImportFromEPSG(32611)\ndefense_data = np.random.rand(height, width) * 100\n\ncreate_raster_defense_map(\"defense_map.tif\", width, height, geotransform, projection.ExportToWkt(), defense_data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial synthesis modeling.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import Delaunay\nfrom sklearn.cluster import KMeans\n\ndef spatial_synthesis_modeling(points, num_clusters):\n    tri = Delaunay(points)\n    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(points)\n    labels = kmeans.labels_\n    synthesized_points = []\n    \n    for i in range(num_clusters):\n        cluster_points = points[labels == i]\n        if len(cluster_points) > 0:\n            centroid = cluster_points.mean(axis=0)\n            synthesized_points.append(centroid)\n    \n    return np.array(synthesized_points)\n\n# Example usage\npoints = np.random.rand(100, 2)\nnum_clusters = 5\nsynthesized = spatial_synthesis_modeling(points, num_clusters)\nprint(synthesized)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha=1.0):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    weighted_distances = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * weighted_distances) / np.sum(weighted_distances)\n    return systemic_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex collaboration of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_collaboration(geometries):\n    combined_geom = unary_union(geometries)\n    if isinstance(combined_geom, (Polygon, MultiPolygon)):\n        return combined_geom.convex_hull\n    else:\n        raise ValueError(\"Input geometries must be valid Shapely Polygon or MultiPolygon objects.\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial interpretation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Create a sample point geometry for analysis\npoint = Point(12.345, 67.890)\n\n# Perform spatial join to find features intersecting with the point\nintersection = gpd.sjoin(data, gpd.GeoDataFrame(geometry=[point], crs=data.crs), how=\"inner\", op=\"intersects\")\n\n# Display results\nprint(intersection)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial procedural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_procedural_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    \n    spatial_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial groupings using clusters.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.cluster import DBSCAN\nfrom shapely.geometry import Point\n\n# Load spatial data\ngdf = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the geometry is in a projected coordinate system (e.g., meters)\ngdf = gdf.to_crs(epsg=3857)\n\n# Extract coordinates for clustering\ncoords = gdf.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n\n# Perform DBSCAN clustering\nepsilon = 1000  # Define max distance between points in cluster (in meters)\nmin_samples = 5  # Minimum number of points to form a cluster\ndb = DBSCAN(eps=epsilon, min_samples=min_samples).fit(coords)\n\n# Add cluster labels to GeoDataFrame\ngdf['cluster'] = db.labels_\n\n# Filter out noise points (label -1 indicates noise)\nclusters_gdf = gdf[gdf['cluster'] != -1]\n\n# Save clusters to a new shapefile\nclusters_gdf.to_file(\"spatial_clusters.shp\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial explanation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Prepare features and target variable\nX = data.drop(columns=[\"target_column\", \"geometry\"])\ny = data[\"target_column\"]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\nscore = model.score(X_test, y_test)\nprint(f\"Model R^2 Score: {score}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial methodological capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_methodological_capacity_index(data, weights):\n    normalized_data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n    weighted_data = normalized_data * weights\n    smci = np.sum(weighted_data, axis=1)\n    return smci\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster intelligence map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\ndef generate_raster_intelligence_map(output_path, width, height, geotransform, data):\n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, width, height, 1, gdal.GDT_Float32)\n    dataset.SetGeoTransform(geotransform)\n    \n    srs = osr.SpatialReference()\n    srs.ImportFromEPSG(4326)\n    dataset.SetProjection(srs.ExportToWkt())\n    \n    band = dataset.GetRasterBand(1)\n    band.WriteArray(data)\n    band.FlushCache()\n\n# Example usage\noutput_path = \"intelligence_map.tif\"\nwidth, height = 512, 512\ngeotransform = (0, 0.001, 0, 0, 0, -0.001)\ndata = np.random.rand(height, width)\n\ngenerate_raster_intelligence_map(output_path, width, height, geotransform, data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial clarification analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the geometry column is correctly set\ndata = data.set_geometry('geometry')\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\nw.transform = 'R'\n\n# Perform spatial autocorrelation analysis (Moran's I)\nattribute = \"your_column_name\"\nmoran = Moran(data[attribute], w)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial strategic capacity index.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\ndef calculate_spatial_strategic_capacity(points, weights=None):\n    n = len(points)\n    if weights is None:\n        weights = np.ones(n)\n    dist_matrix = distance_matrix(points, points)\n    np.fill_diagonal(dist_matrix, 1e-10)\n    inverse_dist = 1 / dist_matrix\n    strategic_capacity = np.dot(inverse_dist, weights) / np.sum(inverse_dist, axis=1)\n    return strategic_capacity\n\n# Example usage:\npoints = np.array([[0, 0], [1, 2], [3, 1], [5, 4]])\nweights = np.array([1.0, 1.5, 0.8, 1.2])\nspatial_index = calculate_spatial_strategic_capacity(points, weights)\nprint(spatial_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex coalition of geometries.",
        "output": "```python\nfrom shapely.geometry import shape, mapping\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union([shape(geom) for geom in geometries])\n    convex_hull = combined_geom.convex_hull\n    return mapping(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial elucidation modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.geojson\")\n\n# Prepare features and target\nX = data.drop(columns=[\"target_column\", \"geometry\"])\ny = data[\"target_column\"]\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train a Random Forest model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial tactical capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_tactical_capacity_index(density, accessibility, vulnerability):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"vulnerability\": 0.25\n    }\n    \n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_vulnerability = (vulnerability - np.min(vulnerability)) / (np.max(vulnerability) - np.min(vulnerability))\n\n    spatial_tactical_capacity_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"vulnerability\"] * normalized_vulnerability\n    )\n    \n    return spatial_tactical_capacity_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial communities using networks.",
        "output": "```python\nimport networkx as nx\nfrom community import community_louvain\n\n# Create a spatial network graph\nG = nx.Graph()\n\n# Add nodes with spatial coordinates (example)\nG.add_node(1, pos=(0, 0))\nG.add_node(2, pos=(1, 1))\nG.add_node(3, pos=(2, 2))\nG.add_node(4, pos=(3, 3))\n\n# Add edges between nodes (example)\nG.add_edge(1, 2, weight=1.0)\nG.add_edge(2, 3, weight=1.5)\nG.add_edge(3, 4, weight=1.2)\n\n# Detect communities using the Louvain method\npartition = community_louvain.best_partition(G)\n\n# Print detected communities\nprint(partition)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial illumination analysis.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\n\ndef calculate_illumination(dem_path, sun_azimuth, sun_elevation):\n    dataset = gdal.Open(dem_path)\n    band = dataset.GetRasterBand(1)\n    dem = band.ReadAsArray().astype(np.float32)\n    \n    cell_size_x = dataset.GetGeoTransform()[1]\n    cell_size_y = -dataset.GetGeoTransform()[5]\n    \n    slope, aspect = calculate_slope_and_aspect(dem, cell_size_x, cell_size_y)\n    \n    sun_azimuth_rad = np.radians(sun_azimuth)\n    sun_elevation_rad = np.radians(sun_elevation)\n    \n    aspect_rad = np.radians(aspect)\n    slope_rad = np.radians(slope)\n    \n    cos_incidence = np.sin(sun_elevation_rad) * np.cos(slope_rad) + \\\n                    np.cos(sun_elevation_rad) * np.sin(slope_rad) * \\\n                    np.cos(sun_azimuth_rad - aspect_rad)\n    \n    illumination = np.maximum(cos_incidence, 0.0)\n    return illumination\n\ndef calculate_slope_and_aspect(dem, cell_size_x, cell_size_y):\n    dz_dx = (np.roll(dem, 1, axis=1) - np.roll(dem, -1, axis=1)) / (2 * cell_size_x)\n    dz_dy = (np.roll(dem, 1, axis=0) - np.roll(dem, -1, axis=0)) / (2 * cell_size_y)\n    \n    slope = np.arctan(np.sqrt(dz_dx**2 + dz_dy**2)) * (180 / np.pi)\n    aspect = np.arctan2(-dz_dy, dz_dx) * (180 / np.pi)\n    aspect[aspect < 0] += 360\n    \n    return slope, aspect\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial operational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_operational_capacity_index(demand, capacity):\n    demand = np.array(demand)\n    capacity = np.array(capacity)\n    if demand.shape != capacity.shape:\n        raise ValueError(\"Demand and capacity arrays must have the same shape.\")\n    soc_index = np.divide(capacity, demand, out=np.zeros_like(capacity, dtype=float), where=demand!=0)\n    return np.nan_to_num(soc_index, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Example usage\ndemand = [100, 200, 0, 150]\ncapacity = [80, 250, 0, 300]\nsoc_index = calculate_spatial_operational_capacity_index(demand, capacity)\nprint(soc_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster cybersecurity map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\n\ndef generate_cybersecurity_raster(output_path, width, height, geo_transform, projection, data):\n    driver = gdal.GetDriverByName(\"GTiff\")\n    dataset = driver.Create(output_path, width, height, 1, gdal.GDT_Float32)\n    dataset.SetGeoTransform(geo_transform)\n    dataset.SetProjection(projection)\n    dataset.GetRasterBand(1).WriteArray(data)\n    dataset.FlushCache()\n    dataset = None\n\n# Example usage\nwidth, height = 512, 512\ngeo_transform = (0, 0.001, 0, 0, 0, -0.001)\nprojection = osr.SpatialReference()\nprojection.ImportFromEPSG(4326)\nprojection = projection.ExportToWkt()\n\ndata = np.random.rand(height, width) * 100  # Random cybersecurity risk values\noutput_path = \"cybersecurity_map.tif\"\n\ngenerate_cybersecurity_raster(output_path, width, height, geo_transform, projection, data)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial enlightenment modeling.",
        "output": "```python\nimport numpy as np\nfrom sklearn.cluster import DBSCAN\nfrom shapely.geometry import Point\nimport geopandas as gpd\n\ndef perform_spatial_enlightenment_modeling(data, eps=0.5, min_samples=5):\n    coords = data[['latitude', 'longitude']].values\n    db = DBSCAN(eps=eps, min_samples=min_samples, metric='haversine').fit(np.radians(coords))\n    data['cluster'] = db.labels_\n    geometry = [Point(xy) for xy in zip(data['longitude'], data['latitude'])]\n    gdf = gpd.GeoDataFrame(data, geometry=geometry)\n    return gdf\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial functional capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_functional_capacity(features, weights):\n    normalized_features = features / np.max(features, axis=0)\n    weighted_features = normalized_features * weights\n    functional_capacity_index = np.sum(weighted_features, axis=1)\n    return functional_capacity_index\n\n# Example usage:\nfeatures = np.array([[5, 20, 3], [8, 15, 6], [7, 25, 4]])\nweights = np.array([0.4, 0.5, 0.1])\nspatial_functional_capacity = calculate_spatial_functional_capacity(features, weights)\nprint(spatial_functional_capacity)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex collective of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined_geom = unary_union(geometries)\n    convex_hull = combined_geom.convex_hull\n    return convex_hull\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial revelation analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load the spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix using Queen contiguity\nw = Queen.from_dataframe(data)\n\n# Calculate spatial lag for a specific attribute (e.g., 'attribute_column')\ndata['lag_attribute'] = gpd.GeoSeries(data['attribute_column']).apply(lambda x: w.neighbors[x])\n\n# Perform Moran's I analysis for spatial autocorrelation\nmoran = Moran(data['attribute_column'], w)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial structural capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_structural_capacity_index(structural_data, weights):\n    normalized_data = structural_data / np.max(structural_data, axis=0)\n    weighted_data = normalized_data * weights\n    spatial_capacity_index = np.sum(weighted_data, axis=1)\n    return spatial_capacity_index\n\n# Example usage\nstructural_data = np.array([[10, 20, 30], [15, 25, 35], [20, 30, 40]])\nweights = np.array([0.5, 0.3, 0.2])\nspatial_capacity_index = calculate_spatial_structural_capacity_index(structural_data, weights)\nprint(spatial_capacity_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Detect spatial organizations using systems.",
        "output": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom sklearn.cluster import DBSCAN\n\ndef detect_spatial_organizations(points, eps=0.5, min_samples=5):\n    dist_matrix = distance_matrix(points, points)\n    dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n    labels = dbscan.fit_predict(dist_matrix)\n    return labels\n\npoints = np.random.rand(100, 2)\nlabels = detect_spatial_organizations(points, eps=0.2, min_samples=3)\nprint(labels)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial disclosure modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load spatial data\ndata = gpd.read_file(\"spatial_data.shp\")\n\n# Prepare features and target variable\nX = data.drop(columns=[\"target_column\"])\ny = data[\"target_column\"]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and train the model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial organizational capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_organizational_capacity(density, accessibility, land_use_mix):\n    weights = {\n        \"density\": 0.4,\n        \"accessibility\": 0.35,\n        \"land_use_mix\": 0.25\n    }\n    normalized_density = (density - np.min(density)) / (np.max(density) - np.min(density))\n    normalized_accessibility = (accessibility - np.min(accessibility)) / (np.max(accessibility) - np.min(accessibility))\n    normalized_land_use_mix = (land_use_mix - np.min(land_use_mix)) / (np.max(land_use_mix) - np.min(land_use_mix))\n    \n    spatial_index = (\n        weights[\"density\"] * normalized_density +\n        weights[\"accessibility\"] * normalized_accessibility +\n        weights[\"land_use_mix\"] * normalized_land_use_mix\n    )\n    return spatial_index\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Generate a raster border security map.",
        "output": "```python\nimport numpy as np\nfrom osgeo import gdal, ogr, osr\n\ndef create_border_security_raster(output_path, vector_path, raster_size, border_buffer_distance):\n    # Open the vector file\n    vector_data = ogr.Open(vector_path)\n    layer = vector_data.GetLayer()\n    \n    # Get the extent of the vector layer\n    x_min, x_max, y_min, y_max = layer.GetExtent()\n    \n    # Define raster resolution and size\n    pixel_width = (x_max - x_min) / raster_size\n    pixel_height = (y_max - y_min) / raster_size\n    \n    # Create the raster dataset\n    driver = gdal.GetDriverByName('GTiff')\n    raster = driver.Create(output_path, raster_size, raster_size, 1, gdal.GDT_Byte)\n    raster.SetGeoTransform((x_min, pixel_width, 0, y_max, 0, -pixel_height))\n    \n    # Set projection\n    srs = osr.SpatialReference()\n    srs.ImportFromEPSG(4326)  # Assuming WGS84\n    raster.SetProjection(srs.ExportToWkt())\n    \n    # Rasterize the border with buffer\n    gdal.RasterizeLayer(raster, [1], layer, burn_values=[255], options=[f\"ATTRIBUTE=buffer({border_buffer_distance})\"])\n    \n    # Close datasets\n    raster = None\n    vector_data = None\n\n# Example usage\ncreate_border_security_raster(\"output_border_map.tif\", \"border.shp\", 1000, 1000)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial unveiling analysis.",
        "output": "```python\nimport geopandas as gpd\nfrom libpysal.weights import Queen\nfrom esda.moran import Moran\n\n# Load spatial data\ndata = gpd.read_file(\"path_to_your_shapefile.shp\")\n\n# Ensure the GeoDataFrame has a valid CRS\ndata = data.to_crs(epsg=4326)\n\n# Create a spatial weights matrix\nw = Queen.from_dataframe(data)\n\n# Perform spatial autocorrelation analysis using Moran's I\nattribute = \"your_column_name\"\nmoran = Moran(data[attribute], w)\n\n# Output Moran's I statistic and p-value\nprint(f\"Moran's I: {moran.I}, p-value: {moran.p_sim}\")\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial institutional capacity index.",
        "output": "```python\nimport numpy as np\nimport pandas as pd\n\ndef calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights):\n    normalized_data = data[capacity_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)\n    weighted_data = normalized_data.multiply(spatial_weights, axis=0)\n    spatial_capacity_index = weighted_data.sum(axis=1)\n    return spatial_capacity_index\n\n# Example usage:\n# data = pd.DataFrame({'institution_1': [5, 10, 15], 'institution_2': [20, 30, 40]})\n# capacity_columns = ['institution_1', 'institution_2']\n# spatial_weights = [0.6, 0.4]\n# sci_index = calculate_spatial_institutional_capacity(data, capacity_columns, spatial_weights)\n# print(sci_index)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Extract the convex institution of geometries.",
        "output": "```python\nfrom shapely.geometry import Polygon, MultiPoint\nfrom shapely.ops import unary_union\n\ndef extract_convex_hull(geometries):\n    combined = unary_union(geometries)\n    return combined.convex_hull\n\n# Example usage\ngeometries = [Polygon([(0, 0), (1, 1), (1, 0)]), Polygon([(0.5, 0.5), (2, 2), (2, 0)])]\nconvex_hull = extract_convex_hull(geometries)\nprint(convex_hull)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Perform spatial exposure modeling.",
        "output": "```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load exposure and hazard data\nexposure_data = gpd.read_file(\"exposure_data.geojson\")\nhazard_data = gpd.read_file(\"hazard_data.geojson\")\n\n# Ensure both datasets are in the same CRS\nexposure_data = exposure_data.to_crs(hazard_data.crs)\n\n# Perform spatial join to find exposure within hazard zones\nspatial_join = gpd.sjoin(exposure_data, hazard_data, how=\"inner\", predicate=\"intersects\")\n\n# Aggregate results (e.g., count of exposed features)\nexposure_summary = spatial_join.groupby(\"hazard_id\").size().reset_index(name=\"exposed_count\")\n\n# Save results to a new file\nexposure_summary.to_csv(\"exposure_summary.csv\", index=False)\n```"
    },
    {
        "instruction": "Generate a Python script for a GIS task.",
        "input": "Calculate the spatial systemic capacity index.",
        "output": "```python\nimport numpy as np\n\ndef calculate_spatial_systemic_capacity_index(capacity_matrix, distance_matrix, alpha=1.0):\n    normalized_capacity = capacity_matrix / np.max(capacity_matrix)\n    weighted_distances = np.exp(-alpha * distance_matrix)\n    systemic_capacity_index = np.sum(normalized_capacity * weighted_distances) / np.sum(weighted_distances)\n    return systemic_capacity_index\n```"
    }
]